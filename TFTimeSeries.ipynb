{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFTimeSeries.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmistroni/TensorFlowPlayground/blob/master/TFTimeSeries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "7j1C2K-pSCvo",
        "colab_type": "code",
        "outputId": "3fa632f2-10d5-4595-e167-3fabc6ece1fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install pandas_datareader"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas_datareader in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from pandas_datareader) (1.10.11)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from pandas_datareader) (4.2.6)\n",
            "Requirement already satisfied: pandas>=0.19.2 in /usr/local/lib/python3.6/dist-packages (from pandas_datareader) (0.23.4)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from pandas_datareader) (2.18.4)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->pandas_datareader) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->pandas_datareader) (2.5.3)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->pandas_datareader) (1.16.2)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas_datareader) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas_datareader) (2.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas_datareader) (2019.3.9)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas_datareader) (1.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas>=0.19.2->pandas_datareader) (1.11.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "03Y2LC7ZQtOu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import tensorflow as tf\n",
        "from datetime import date\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.contrib.learn import ModeKeys\n",
        "import tensorflow.contrib.rnn as rnn\n",
        "from datetime import datetime, date, timedelta\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l-Irklu5ENWm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from pandas.tseries.offsets import BDay\n",
        "TIMESERIES_COL = 'rawdata'\n",
        "N_OUTPUTS = 5 # in each sequence, 1-14 are features, and 14-20 is label \n",
        "SEQ_LEN = 20\n",
        "DEFAULTS = 0.0\n",
        "LSTM_SIZE = 4  # number of hidden layers in each of the LSTM cells\n",
        "N_INPUTS = SEQ_LEN - N_OUTPUTS\n",
        "BATCH_SIZE = 20\n",
        "ROOT_DIR = '/home/mmistroni/tf_logs/rnn-run-{}'\n",
        "\n",
        "\n",
        "def get_prices(startdate, enddate):\n",
        "  import pandas_datareader as pdr\n",
        "  from datetime import date, timedelta\n",
        "  print ('--Start:{%s}, end:{%s}', startdate, enddate)\n",
        "  \n",
        "  stock_data = pdr.get_data_yahoo('XOM', startdate, enddate)\n",
        "  adjClose = np.stack(stock_data['Close'])\n",
        "  return adjClose\n",
        "  \n",
        "def create_training_data2(inputData):\n",
        "  print ('Len of input dat ais {}', len(inputData))\n",
        "  return [np.array(inputData[i * SEQ_LEN: (i + 1) * SEQ_LEN]) \n",
        "       for i in range(len(inputData) // SEQ_LEN)]\n",
        "\n",
        "def create_training_data(inputData):\n",
        "  print ('AdjClose is of shape {}', inputData.shape)\n",
        "  return inputData.T.reshape(-1,SEQ_LEN)\n",
        "  \n",
        "  \n",
        "def create_time_series(numDays=200):\n",
        "  endDate = date.today() - BDay(15) # training from 20 days ago\n",
        "  startDate = endDate - BDay(220)\n",
        "  prices =  get_prices(startDate, endDate)\n",
        "  return create_training_data2(prices)\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "66a0d25b-69fe-4ed3-f902-5e247242937a",
        "id": "whdGmgDC4Fr2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "all_timeseries =  create_time_series() #[create_time_series() for i in range(0, SEQ_LEN * 4)]\n",
        "all_data = np.stack(all_timeseries)\n",
        "print('All data shape is{0} and type {1}'.format(all_data.shape,type(all_data)))\n",
        "X, y = all_data[...,0:-N_OUTPUTS], all_data[...,-N_OUTPUTS:]\n",
        "print ('X is fo type {0}, y  of type {1}'.format(type(X[0][0]), type(y)))\n",
        "print ('X.shape is {0}, y shap is {1}'.format(X.shape, y.shape))\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,\n",
        "                                                    y,\n",
        "                                                    test_size=0.1,\n",
        "                                                    random_state=1)\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--Start:{%s}, end:{%s} 2018-05-21 00:00:00 2019-03-25 00:00:00\n",
            "Len of input dat ais {} 212\n",
            "All data shape is(10, 20) and type <class 'numpy.ndarray'>\n",
            "X is fo type <class 'numpy.float64'>, y  of type <class 'numpy.ndarray'>\n",
            "X.shape is (10, 15), y shap is (10, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cennoUsA4jdI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h3> Creating RNN Model </h3>\n"
      ]
    },
    {
      "metadata": {
        "id": "PVMHd20H36gP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# create the inference model\n",
        "def simple_rnn(features, labels, mode, params):\n",
        "  # 0. Reformat input shape to become a sequence\n",
        "  print ('IN Features are:{0}'.format(features))\n",
        "  x = tf.split(features[TIMESERIES_COL], N_INPUTS, 1)\n",
        "  #print 'x={}'.format(x)\n",
        "    \n",
        "  # 1. configure the RNN\n",
        "  lstm_cell = rnn.BasicLSTMCell(LSTM_SIZE, forget_bias=1.0)\n",
        "  outputs, _ = tf.nn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
        "\n",
        "  # slice to keep only the last cell of the RNN\n",
        "  outputs = outputs[-1]\n",
        "  #print 'last outputs={}'.format(outputs)\n",
        "  \n",
        "  # output is result of linear activation of last layer of RNN\n",
        "  weight = tf.Variable(tf.random_normal([LSTM_SIZE, N_OUTPUTS]))\n",
        "  bias = tf.Variable(tf.random_normal([N_OUTPUTS]))\n",
        "  predictions = tf.matmul(outputs, weight) + bias\n",
        "    \n",
        "  # 2. loss function, training/eval ops\n",
        "  if mode == ModeKeys.TRAIN or mode == ModeKeys.EVAL:\n",
        "     loss = tf.losses.mean_squared_error(labels, predictions)\n",
        "     train_op = tf.contrib.layers.optimize_loss(\n",
        "         loss=loss,\n",
        "         global_step=tf.train.get_global_step(),\n",
        "         learning_rate=0.01,\n",
        "         optimizer=\"SGD\")\n",
        "     eval_metric_ops = {\n",
        "      \"rmse\": tf.metrics.root_mean_squared_error(labels, predictions)\n",
        "     }\n",
        "  else:\n",
        "     loss = None\n",
        "     train_op = None\n",
        "     eval_metric_ops = None\n",
        "  \n",
        "  # 3. Create predictions\n",
        "  predictions_dict = {\"predicted\": predictions}\n",
        "\n",
        "  # 4. Create export outputs  \n",
        "  export_outputs = {\"predicted\": tf.estimator.export.PredictOutput(predictions)}\n",
        "\n",
        "  # 5. return ModelFnOps\n",
        "  return tf.estimator.EstimatorSpec(\n",
        "      mode=mode,\n",
        "      predictions=predictions_dict,\n",
        "      loss=loss,\n",
        "      train_op=train_op,\n",
        "      eval_metric_ops=eval_metric_ops,\n",
        "      export_outputs=export_outputs)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6x2OM2cG4qpj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h3> Creating Serving Function , Train Function and Test Function </h3>"
      ]
    },
    {
      "metadata": {
        "id": "ka_U5ZvZ4W6W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def serving_input_receiver_fn():\n",
        "  feature_placeholders = {\n",
        "    TIMESERIES_COL: tf.placeholder(tf.float32, [None, N_INPUTS])\n",
        "  }\n",
        "\n",
        "  features = {\n",
        "    key: tf.expand_dims(tensor, -1)\n",
        "    for key, tensor in feature_placeholders.items()\n",
        "  }\n",
        "\n",
        "  features[TIMESERIES_COL] = tf.squeeze(features[TIMESERIES_COL], axis=[2], name='timeseries')\n",
        "  \n",
        "  print('serving: features={}'.format(features[TIMESERIES_COL]))\n",
        "\n",
        "  return tf.estimator.export.ServingInputReceiver(features, feature_placeholders)\n",
        "\n",
        "\n",
        "\n",
        "# Creating a TrainFn and a TestFn\n",
        "def _train_fn(X, y, batch_size):\n",
        "    \n",
        "    def _train():\n",
        "        \"\"\"An input function for training\"\"\"\n",
        "        # Convert the inputs to a Dataset.\n",
        "        # TODO need to be refactored according to https://medium.com/google-cloud/how-to-do-time-series-prediction-using-rnns-and-tensorflow-and-cloud-ml-engine-2ad2eeb189e8\n",
        "        # this is not good.\n",
        "        X_32 = tf.cast(X, tf.float32)\n",
        "        y_32 = tf.cast(y, tf.float32)\n",
        "        inputs = tf.concat(X_32, axis=1)\n",
        "        label = tf.concat(y_32, axis=1)\n",
        "        features, labels = {TIMESERIES_COL: inputs}, label\n",
        "        \n",
        "        return features, labels\n",
        "        dataset = tf.data.Dataset.from_tensor_slices(features, labels)\n",
        "        # Shuffle, repeat, and batch the examples.\n",
        "        dataset = dataset.repeat(None).batch(batch_size)\n",
        "        # This will now return batches of features, label\n",
        "        return dataset.make_one_shot_iterator().get_next()\n",
        "    return _train\n",
        "\n",
        "def _test_fn(X, y, batch_size):\n",
        "    def _test():\n",
        "        \"\"\"An input function for training\"\"\"\n",
        "        # Convert the inputs to a Dataset.\n",
        "        X_32 = tf.cast(X, tf.float32)\n",
        "        y_32 = tf.cast(y, tf.float32)\n",
        "        inputs = tf.concat(X_32, axis=1)\n",
        "        label = tf.concat(y_32, axis=1)\n",
        "        \n",
        "        features, labels = {TIMESERIES_COL: inputs}, label\n",
        "        \n",
        "        return features, labels\n",
        "        \n",
        "        dataset = tf.data.Dataset.from_tensor_slices(features, labels)\n",
        "        # Shuffle, repeat, and batch the examples.\n",
        "        dataset = dataset.repeat(1).batch(batch_size)\n",
        "        # This will now return batches of features, label\n",
        "        return dataset.make_one_shot_iterator().get_next()\n",
        "    return _test  \n",
        "\n",
        " \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ovYAxd_W4zc7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h3> Creating Experiment Function and running model </h3>"
      ]
    },
    {
      "metadata": {
        "id": "CByxDadW49FB",
        "colab_type": "code",
        "outputId": "58491018-274d-43b9-b885-99fc38f53bcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1822
        }
      },
      "cell_type": "code",
      "source": [
        "def experiment_fn(output_dir):\n",
        "    # run experiment\n",
        "    train_spec = tf.estimator.TrainSpec(\n",
        "          input_fn=_train_fn(X_train, y_train, BATCH_SIZE), max_steps=1500)\n",
        "    exporter = tf.estimator.FinalExporter('timeseries',\n",
        "    serving_input_receiver_fn)\n",
        "    eval_spec = tf.estimator.EvalSpec(\n",
        "            input_fn=_test_fn(X_test, y_test, BATCH_SIZE),\n",
        "            exporters=[exporter])\n",
        "    \n",
        "    estimator = tf.estimator.Estimator(model_fn=simple_rnn, model_dir=output_dir)\n",
        "\n",
        "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n",
        "    return estimator\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.INFO)    \n",
        "    \n",
        "output_dir = ROOT_DIR.format(datetime.utcnow().strftime('%Y%m%d%H%M%S'))  \n",
        "  \n",
        "estimator = experiment_fn(output_dir)\n",
        "\n",
        "\n",
        "print('Xtrain is:{} and of shape:{}', type(X_train), X_train.shape)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/home/mmistroni/tf_logs/rnn-run-20190415193613', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3d345a4a20>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function simple_rnn at 0x7f3d3448e378>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "IN Features are:{'rawdata': <tf.Tensor 'concat:0' shape=(9, 15) dtype=float32>}\n",
            "WARNING:tensorflow:From <ipython-input-5-3cacf26bf3f2>:8: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-5-3cacf26bf3f2>:9: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:667: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /home/mmistroni/tf_logs/rnn-run-20190415193613/model.ckpt.\n",
            "INFO:tensorflow:loss = 6447.763, step = 1\n",
            "INFO:tensorflow:global_step/sec: 213.55\n",
            "INFO:tensorflow:loss = 2006.5178, step = 101 (0.471 sec)\n",
            "INFO:tensorflow:global_step/sec: 688.858\n",
            "INFO:tensorflow:loss = 578.0292, step = 201 (0.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 737.552\n",
            "INFO:tensorflow:loss = 176.07391, step = 301 (0.136 sec)\n",
            "INFO:tensorflow:global_step/sec: 740.933\n",
            "INFO:tensorflow:loss = 62.96989, step = 401 (0.135 sec)\n",
            "INFO:tensorflow:global_step/sec: 737.367\n",
            "INFO:tensorflow:loss = 31.14401, step = 501 (0.136 sec)\n",
            "INFO:tensorflow:global_step/sec: 739.271\n",
            "INFO:tensorflow:loss = 22.188711, step = 601 (0.135 sec)\n",
            "INFO:tensorflow:global_step/sec: 745.715\n",
            "INFO:tensorflow:loss = 19.668812, step = 701 (0.134 sec)\n",
            "INFO:tensorflow:global_step/sec: 739.847\n",
            "INFO:tensorflow:loss = 18.959742, step = 801 (0.135 sec)\n",
            "INFO:tensorflow:global_step/sec: 755.407\n",
            "INFO:tensorflow:loss = 18.76021, step = 901 (0.132 sec)\n",
            "INFO:tensorflow:global_step/sec: 748.184\n",
            "INFO:tensorflow:loss = 18.704048, step = 1001 (0.134 sec)\n",
            "INFO:tensorflow:global_step/sec: 733.922\n",
            "INFO:tensorflow:loss = 18.688202, step = 1101 (0.136 sec)\n",
            "INFO:tensorflow:global_step/sec: 121.229\n",
            "INFO:tensorflow:loss = 18.68358, step = 1201 (0.824 sec)\n",
            "INFO:tensorflow:global_step/sec: 719.937\n",
            "INFO:tensorflow:loss = 18.750975, step = 1301 (0.139 sec)\n",
            "INFO:tensorflow:global_step/sec: 738.971\n",
            "INFO:tensorflow:loss = 18.70151, step = 1401 (0.135 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 1500 into /home/mmistroni/tf_logs/rnn-run-20190415193613/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "IN Features are:{'rawdata': <tf.Tensor 'concat:0' shape=(1, 15) dtype=float32>}\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-04-15T19:36:20Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from /home/mmistroni/tf_logs/rnn-run-20190415193613/model.ckpt-1500\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Evaluation [10/100]\n",
            "INFO:tensorflow:Evaluation [20/100]\n",
            "INFO:tensorflow:Evaluation [30/100]\n",
            "INFO:tensorflow:Evaluation [40/100]\n",
            "INFO:tensorflow:Evaluation [50/100]\n",
            "INFO:tensorflow:Evaluation [60/100]\n",
            "INFO:tensorflow:Evaluation [70/100]\n",
            "INFO:tensorflow:Evaluation [80/100]\n",
            "INFO:tensorflow:Evaluation [90/100]\n",
            "INFO:tensorflow:Evaluation [100/100]\n",
            "INFO:tensorflow:Finished evaluation at 2019-04-15-19:36:21\n",
            "INFO:tensorflow:Saving dict for global step 1500: global_step = 1500, loss = 1.4006554, rmse = 1.1834928\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1500: /home/mmistroni/tf_logs/rnn-run-20190415193613/model.ckpt-1500\n",
            "INFO:tensorflow:Performing the final export in the end of training.\n",
            "serving: features=Tensor(\"timeseries:0\", shape=(?, 15), dtype=float32)\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "IN Features are:{'rawdata': <tf.Tensor 'timeseries:0' shape=(?, 15) dtype=float32>}\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:205: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predicted', 'serving_default']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "INFO:tensorflow:Restoring parameters from /home/mmistroni/tf_logs/rnn-run-20190415193613/model.ckpt-1500\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: /home/mmistroni/tf_logs/rnn-run-20190415193613/export/timeseries/temp-b'1555356981'/saved_model.pb\n",
            "INFO:tensorflow:Loss for final step: 18.68766.\n",
            "Xtrain is:{} and of shape:{} <class 'numpy.ndarray'> (9, 15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kMzyPr_u4_At",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h3> Now running some predictions with last 15 days </h3>"
      ]
    },
    {
      "metadata": {
        "id": "n3zgbsMrCbgP",
        "colab_type": "code",
        "outputId": "42a0217a-07c4-4522-fc7c-5a9baf4ed8f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1822
        }
      },
      "cell_type": "code",
      "source": [
        "from datetime import date\n",
        "enddt  = date.today()\n",
        "startdt = enddt - BDay(N_INPUTS-1)\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.INFO)    \n",
        "\n",
        "def _predict_fn(X) :\n",
        "    def _predict():\n",
        "        \"\"\"An input function for training\"\"\"\n",
        "        # Convert the inputs to a Dataset.\n",
        "        X_32 = tf.cast(X, tf.float32)\n",
        "        inputs = tf.concat(X_32, axis=1)\n",
        "        features = {TIMESERIES_COL: inputs}\n",
        "        return features\n",
        "    return _predict\n",
        "\n",
        "def get_prices2(startdate=None, enddate=None):\n",
        "  import pandas_datareader as pdr\n",
        "  from datetime import date, timedelta\n",
        "  print ('--Start:{%s}, end:{%s}', startdate, enddate)\n",
        "  \n",
        "  if not startdate and not enddate:\n",
        "    last_check = date.today() - BDay(SEQ_LEN * 2)\n",
        "    enddate = last_check\n",
        "    startdate = last_check - BDay(122)#timedelta(days=120)\n",
        "  stock_data = pdr.get_data_yahoo('XOM', startdate, enddate)\n",
        "  adjClose = np.stack(stock_data['Close'])\n",
        "  return adjClose\n",
        "\n",
        "\n",
        "prices = get_prices2(startdt, enddt).reshape(-1,N_INPUTS)\n",
        "print ('Prices is of shape:{}', prices.shape)\n",
        "\n",
        "\n",
        "print ('-------- PREDICTING -------')\n",
        "print (type(prices))\n",
        "\n",
        "\n",
        "def _predict_fn(X):\n",
        "    def _predict():\n",
        "        \"\"\"An input function for training\"\"\"\n",
        "        # Convert the inputs to a Dataset.\n",
        "        X_32 = tf.cast(X, tf.float32)\n",
        "        inputs = tf.concat(X_32, axis=1)\n",
        "        features = {TIMESERIES_COL: inputs}\n",
        "        return features\n",
        "        \n",
        "    return _predict \n",
        "\n",
        "\n",
        "acc = []\n",
        "acc += prices[0].tolist()\n",
        "\n",
        "for i in range(0,5):\n",
        "  candidate = np.array(acc[-15:]).reshape(-1,15)\n",
        "  pred = estimator.predict(input_fn = _predict_fn(candidate))\n",
        "  item = next(pred)\n",
        "  print ('Round {} Prediction: on {} \\n{}', i, acc, item)\n",
        "  vals = item['predicted']\n",
        "  print ('{}={}'.format(type(vals), vals.tolist()))\n",
        "  acc += vals.tolist()\n",
        "\n",
        "print('-------------- END OF STORY')\n",
        "from pprint import pprint\n",
        "pprint(acc)\n",
        "#print ('Round 2')\n",
        "#last = acc[-15:]\n",
        "#p2 = np.array(last).reshape(-1, 15)\n",
        "#\n",
        "#pred = estimator.predict(input_fn = _predict_fn(p2))\n",
        "\n",
        "#item = next(pred)\n",
        "#print ('Round 2Prediction on {} \\n{}', last, item)\n",
        "#vals = item['predicted']\n",
        "#print ('{}={}'.format(type(vals), vals.tolist()))\n",
        "#acc += vals.tolist()\n",
        "#print ('----------  Final ----------')\n",
        "#print (acc)\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--Start:{%s}, end:{%s} 2019-03-26 00:00:00 2019-04-15\n",
            "Prices is of shape:{} (1, 15)\n",
            "-------- PREDICTING -------\n",
            "<class 'numpy.ndarray'>\n",
            "WARNING:tensorflow:Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "IN Features are:{'rawdata': <tf.Tensor 'concat:0' shape=(1, 15) dtype=float32>}\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /home/mmistroni/tf_logs/rnn-run-20190415193613/model.ckpt-1500\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "Round {} Prediction: on {} \n",
            "{} 0 [80.95999908447266, 80.33999633789062, 80.73999786376953, 80.80000305175781, 81.7300033569336, 81.37999725341797, 80.9000015258789, 82.05000305175781, 82.48999786376953, 83.0, 81.93000030517578, 81.55999755859375, 81.94999694824219, 80.91999816894531, 80.70999908447266] {'predicted': array([79.431366, 80.00568 , 80.10248 , 79.99581 , 79.950325],\n",
            "      dtype=float32)}\n",
            "<class 'numpy.ndarray'>=[79.43136596679688, 80.00567626953125, 80.10247802734375, 79.99581146240234, 79.95032501220703]\n",
            "WARNING:tensorflow:Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "IN Features are:{'rawdata': <tf.Tensor 'concat:0' shape=(1, 15) dtype=float32>}\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /home/mmistroni/tf_logs/rnn-run-20190415193613/model.ckpt-1500\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "Round {} Prediction: on {} \n",
            "{} 1 [80.95999908447266, 80.33999633789062, 80.73999786376953, 80.80000305175781, 81.7300033569336, 81.37999725341797, 80.9000015258789, 82.05000305175781, 82.48999786376953, 83.0, 81.93000030517578, 81.55999755859375, 81.94999694824219, 80.91999816894531, 80.70999908447266, 79.43136596679688, 80.00567626953125, 80.10247802734375, 79.99581146240234, 79.95032501220703] {'predicted': array([79.431366, 80.00568 , 80.10248 , 79.99581 , 79.950325],\n",
            "      dtype=float32)}\n",
            "<class 'numpy.ndarray'>=[79.43136596679688, 80.00567626953125, 80.10247802734375, 79.99581146240234, 79.95032501220703]\n",
            "WARNING:tensorflow:Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "IN Features are:{'rawdata': <tf.Tensor 'concat:0' shape=(1, 15) dtype=float32>}\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /home/mmistroni/tf_logs/rnn-run-20190415193613/model.ckpt-1500\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "Round {} Prediction: on {} \n",
            "{} 2 [80.95999908447266, 80.33999633789062, 80.73999786376953, 80.80000305175781, 81.7300033569336, 81.37999725341797, 80.9000015258789, 82.05000305175781, 82.48999786376953, 83.0, 81.93000030517578, 81.55999755859375, 81.94999694824219, 80.91999816894531, 80.70999908447266, 79.43136596679688, 80.00567626953125, 80.10247802734375, 79.99581146240234, 79.95032501220703, 79.43136596679688, 80.00567626953125, 80.10247802734375, 79.99581146240234, 79.95032501220703] {'predicted': array([79.431366, 80.00568 , 80.10248 , 79.99581 , 79.950325],\n",
            "      dtype=float32)}\n",
            "<class 'numpy.ndarray'>=[79.43136596679688, 80.00567626953125, 80.10247802734375, 79.99581146240234, 79.95032501220703]\n",
            "WARNING:tensorflow:Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "IN Features are:{'rawdata': <tf.Tensor 'concat:0' shape=(1, 15) dtype=float32>}\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /home/mmistroni/tf_logs/rnn-run-20190415193613/model.ckpt-1500\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "Round {} Prediction: on {} \n",
            "{} 3 [80.95999908447266, 80.33999633789062, 80.73999786376953, 80.80000305175781, 81.7300033569336, 81.37999725341797, 80.9000015258789, 82.05000305175781, 82.48999786376953, 83.0, 81.93000030517578, 81.55999755859375, 81.94999694824219, 80.91999816894531, 80.70999908447266, 79.43136596679688, 80.00567626953125, 80.10247802734375, 79.99581146240234, 79.95032501220703, 79.43136596679688, 80.00567626953125, 80.10247802734375, 79.99581146240234, 79.95032501220703, 79.43136596679688, 80.00567626953125, 80.10247802734375, 79.99581146240234, 79.95032501220703] {'predicted': array([79.431366, 80.00568 , 80.10248 , 79.99581 , 79.950325],\n",
            "      dtype=float32)}\n",
            "<class 'numpy.ndarray'>=[79.43136596679688, 80.00567626953125, 80.10247802734375, 79.99581146240234, 79.95032501220703]\n",
            "WARNING:tensorflow:Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "IN Features are:{'rawdata': <tf.Tensor 'concat:0' shape=(1, 15) dtype=float32>}\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /home/mmistroni/tf_logs/rnn-run-20190415193613/model.ckpt-1500\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "Round {} Prediction: on {} \n",
            "{} 4 [80.95999908447266, 80.33999633789062, 80.73999786376953, 80.80000305175781, 81.7300033569336, 81.37999725341797, 80.9000015258789, 82.05000305175781, 82.48999786376953, 83.0, 81.93000030517578, 81.55999755859375, 81.94999694824219, 80.91999816894531, 80.70999908447266, 79.43136596679688, 80.00567626953125, 80.10247802734375, 79.99581146240234, 79.95032501220703, 79.43136596679688, 80.00567626953125, 80.10247802734375, 79.99581146240234, 79.95032501220703, 79.43136596679688, 80.00567626953125, 80.10247802734375, 79.99581146240234, 79.95032501220703, 79.43136596679688, 80.00567626953125, 80.10247802734375, 79.99581146240234, 79.95032501220703] {'predicted': array([79.431366, 80.00568 , 80.10248 , 79.99581 , 79.950325],\n",
            "      dtype=float32)}\n",
            "<class 'numpy.ndarray'>=[79.43136596679688, 80.00567626953125, 80.10247802734375, 79.99581146240234, 79.95032501220703]\n",
            "-------------- END OF STORY\n",
            "[80.95999908447266,\n",
            " 80.33999633789062,\n",
            " 80.73999786376953,\n",
            " 80.80000305175781,\n",
            " 81.7300033569336,\n",
            " 81.37999725341797,\n",
            " 80.9000015258789,\n",
            " 82.05000305175781,\n",
            " 82.48999786376953,\n",
            " 83.0,\n",
            " 81.93000030517578,\n",
            " 81.55999755859375,\n",
            " 81.94999694824219,\n",
            " 80.91999816894531,\n",
            " 80.70999908447266,\n",
            " 79.43136596679688,\n",
            " 80.00567626953125,\n",
            " 80.10247802734375,\n",
            " 79.99581146240234,\n",
            " 79.95032501220703,\n",
            " 79.43136596679688,\n",
            " 80.00567626953125,\n",
            " 80.10247802734375,\n",
            " 79.99581146240234,\n",
            " 79.95032501220703,\n",
            " 79.43136596679688,\n",
            " 80.00567626953125,\n",
            " 80.10247802734375,\n",
            " 79.99581146240234,\n",
            " 79.95032501220703,\n",
            " 79.43136596679688,\n",
            " 80.00567626953125,\n",
            " 80.10247802734375,\n",
            " 79.99581146240234,\n",
            " 79.95032501220703,\n",
            " 79.43136596679688,\n",
            " 80.00567626953125,\n",
            " 80.10247802734375,\n",
            " 79.99581146240234,\n",
            " 79.95032501220703]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LEMTgvKICpoc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "prI5nJS_S4nf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Installing libraries and downloading data as DataFrame\n"
      ]
    },
    {
      "metadata": {
        "id": "e8SxyWVIxS3L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}