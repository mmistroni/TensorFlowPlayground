{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFTimeSeries.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmistroni/TensorFlowPlayground/blob/master/TFTimeSeries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7j1C2K-pSCvo",
        "colab_type": "code",
        "outputId": "6fa85a5a-2464-459d-a265-cf7f36fbd476",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "!pip install pandas_datareader"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas_datareader in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from pandas_datareader) (2.21.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from pandas_datareader) (4.2.6)\n",
            "Requirement already satisfied: pandas>=0.19.2 in /usr/local/lib/python3.6/dist-packages (from pandas_datareader) (0.24.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from pandas_datareader) (1.11.2)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas_datareader) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas_datareader) (2019.6.16)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas_datareader) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas_datareader) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->pandas_datareader) (2.5.3)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->pandas_datareader) (1.16.4)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->pandas_datareader) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas>=0.19.2->pandas_datareader) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03Y2LC7ZQtOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import tensorflow as tf\n",
        "from datetime import date\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.contrib.learn import ModeKeys\n",
        "import tensorflow.contrib.rnn as rnn\n",
        "from datetime import datetime, date, timedelta\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-Irklu5ENWm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from pandas.tseries.offsets import BDay\n",
        "TIMESERIES_COL = 'rawdata'\n",
        "N_OUTPUTS = 5 # in each sequence, 1-14 are features, and 14-20 is label \n",
        "SEQ_LEN = 20\n",
        "DEFAULTS = 0.0\n",
        "LSTM_SIZE = 5 # number of hidden layers in each of the LSTM cells\n",
        "N_INPUTS = SEQ_LEN - N_OUTPUTS\n",
        "BATCH_SIZE = 20\n",
        "ROOT_DIR = '/home/mmistroni/tf_logs/rnn-run-{}'\n",
        "\n",
        "\n",
        "def get_prices(startdate, enddate, symbol):\n",
        "  import pandas_datareader as pdr\n",
        "  from datetime import date, timedelta\n",
        "  print ('--Start:{%s}, end:{%s}', startdate, enddate)\n",
        "  \n",
        "  stock_data = pdr.get_data_yahoo(symbol, startdate, enddate)[['Close']].pct_change().fillna(0)\n",
        "  adjClose = np.stack(stock_data['Close'])\n",
        "  return adjClose\n",
        "  \n",
        "def create_training_data2(inputData):\n",
        "  print ('Len of input dat ais {}', len(inputData))\n",
        "  return [np.array(inputData[i * SEQ_LEN: (i + 1) * SEQ_LEN]) \n",
        "       for i in range(len(inputData) // SEQ_LEN)]\n",
        "\n",
        "def create_training_data(inputData):\n",
        "  print ('AdjClose is of shape {}', inputData.shape)\n",
        "  return inputData.T.reshape(-1,SEQ_LEN)\n",
        "  \n",
        "  \n",
        "def create_time_series(end_date, numDays=280, symbol='XOM'):\n",
        "  print(\"==== CREATING TIMESERIES GOING BACK 280 DAYS FROM  {}\".format(end_date))\n",
        "  endDate = end_date # training from 20 days ago\n",
        "  startDate = endDate - BDay(numDays)\n",
        "  prices =  get_prices(startDate, endDate, symbol=symbol)\n",
        "  return create_training_data2(prices)\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "whdGmgDC4Fr2",
        "colab": {}
      },
      "source": [
        "\n",
        "def create_train_and_test(end_date, symbol='XOM'):\n",
        "  all_timeseries =  create_time_series(end_date, symbol=symbol) #[create_time_series() for i in range(0, SEQ_LEN * 4)]\n",
        "  all_data = np.stack(all_timeseries)\n",
        "  print('All data shape is{0} and type {1}'.format(all_data.shape,type(all_data)))\n",
        "  X, y = all_data[...,0:-N_OUTPUTS], all_data[...,-N_OUTPUTS:]\n",
        "  print ('X is fo type {0}, y  of type {1}'.format(type(X[0][0]), type(y)))\n",
        "  print ('X.shape is {0}, y shap is {1}'.format(X.shape, y.shape))\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X,\n",
        "                                                      y,\n",
        "                                                      test_size=0.1,\n",
        "                                                      random_state=1)\n",
        "  return X_train, y_train, X_test, y_test\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cennoUsA4jdI",
        "colab_type": "text"
      },
      "source": [
        "<h3> Creating RNN Model </h3>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVMHd20H36gP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# create the inference model\n",
        "def simple_rnn(features, labels, mode, params):\n",
        "  # 0. Reformat input shape to become a sequence\n",
        "  print ('IN Features are:{0}'.format(features))\n",
        "  x = tf.split(features[TIMESERIES_COL], N_INPUTS, 1)\n",
        "  #print 'x={}'.format(x)\n",
        "    \n",
        "  # 1. configure the RNN\n",
        "  lstm_cell = rnn.BasicLSTMCell(LSTM_SIZE, forget_bias=1.0)\n",
        "  outputs, _ = tf.nn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
        "\n",
        "  # slice to keep only the last cell of the RNN\n",
        "  outputs = outputs[-1]\n",
        "  #print 'last outputs={}'.format(outputs)\n",
        "  \n",
        "  # output is result of linear activation of last layer of RNN\n",
        "  weight = tf.Variable(tf.random_normal([LSTM_SIZE, N_OUTPUTS]))\n",
        "  bias = tf.Variable(tf.random_normal([N_OUTPUTS]))\n",
        "  predictions = tf.matmul(outputs, weight) + bias\n",
        "    \n",
        "  # 2. loss function, training/eval ops\n",
        "  if mode == ModeKeys.TRAIN or mode == ModeKeys.EVAL:\n",
        "     loss = tf.losses.mean_squared_error(labels, predictions)\n",
        "     train_op = tf.contrib.layers.optimize_loss(\n",
        "         loss=loss,\n",
        "         global_step=tf.train.get_global_step(),\n",
        "         learning_rate=0.01,\n",
        "         optimizer=\"SGD\") # SGD\n",
        "     eval_metric_ops = {\n",
        "      \"rmse\": tf.metrics.root_mean_squared_error(labels, predictions)\n",
        "     }\n",
        "  else:\n",
        "     loss = None\n",
        "     train_op = None\n",
        "     eval_metric_ops = None\n",
        "  \n",
        "  # 3. Create predictions\n",
        "  predictions_dict = {\"predicted\": predictions}\n",
        "\n",
        "  # 4. Create export outputs  \n",
        "  export_outputs = {\"predicted\": tf.estimator.export.PredictOutput(predictions)}\n",
        "\n",
        "  # 5. return ModelFnOps\n",
        "  return tf.estimator.EstimatorSpec(\n",
        "      mode=mode,\n",
        "      predictions=predictions_dict,\n",
        "      loss=loss,\n",
        "      train_op=train_op,\n",
        "      eval_metric_ops=eval_metric_ops,\n",
        "      export_outputs=export_outputs)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6x2OM2cG4qpj",
        "colab_type": "text"
      },
      "source": [
        "<h3> Creating Serving Function , Train Function and Test Function </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ka_U5ZvZ4W6W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def serving_input_receiver_fn():\n",
        "  feature_placeholders = {\n",
        "    TIMESERIES_COL: tf.placeholder(tf.float32, [None, N_INPUTS])\n",
        "  }\n",
        "\n",
        "  features = {\n",
        "    key: tf.expand_dims(tensor, -1)\n",
        "    for key, tensor in feature_placeholders.items()\n",
        "  }\n",
        "\n",
        "  features[TIMESERIES_COL] = tf.squeeze(features[TIMESERIES_COL], axis=[2], name='timeseries')\n",
        "  \n",
        "  print('serving: features={}'.format(features[TIMESERIES_COL]))\n",
        "\n",
        "  return tf.estimator.export.ServingInputReceiver(features, feature_placeholders)\n",
        "\n",
        "\n",
        "\n",
        "# Creating a TrainFn and a TestFn\n",
        "def _train_fn(X, y, batch_size):\n",
        "    \n",
        "    def _train():\n",
        "        \"\"\"An input function for training\"\"\"\n",
        "        # Convert the inputs to a Dataset.\n",
        "        # TODO need to be refactored according to https://medium.com/google-cloud/how-to-do-time-series-prediction-using-rnns-and-tensorflow-and-cloud-ml-engine-2ad2eeb189e8\n",
        "        # this is not good.\n",
        "        X_32 = tf.cast(X, tf.float32)\n",
        "        y_32 = tf.cast(y, tf.float32)\n",
        "        inputs = tf.concat(X_32, axis=1)\n",
        "        label = tf.concat(y_32, axis=1)\n",
        "        features, labels = {TIMESERIES_COL: inputs}, label\n",
        "        \n",
        "        return features, labels\n",
        "        dataset = tf.data.Dataset.from_tensor_slices(features, labels)\n",
        "        # Shuffle, repeat, and batch the examples.\n",
        "        dataset = dataset.repeat(None).batch(batch_size)\n",
        "        # This will now return batches of features, label\n",
        "        return dataset.make_one_shot_iterator().get_next()\n",
        "    return _train\n",
        "\n",
        "def _test_fn(X, y, batch_size):\n",
        "    def _test():\n",
        "        \"\"\"An input function for training\"\"\"\n",
        "        # Convert the inputs to a Dataset.\n",
        "        X_32 = tf.cast(X, tf.float32)\n",
        "        y_32 = tf.cast(y, tf.float32)\n",
        "        inputs = tf.concat(X_32, axis=1)\n",
        "        label = tf.concat(y_32, axis=1)\n",
        "        \n",
        "        features, labels = {TIMESERIES_COL: inputs}, label\n",
        "        \n",
        "        return features, labels\n",
        "        \n",
        "        dataset = tf.data.Dataset.from_tensor_slices(features, labels)\n",
        "        # Shuffle, repeat, and batch the examples.\n",
        "        dataset = dataset.repeat(1).batch(batch_size)\n",
        "        # This will now return batches of features, label\n",
        "        return dataset.make_one_shot_iterator().get_next()\n",
        "    return _test  \n",
        "\n",
        " \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovYAxd_W4zc7",
        "colab_type": "text"
      },
      "source": [
        "<h3> Creating Experiment Function and running model </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CByxDadW49FB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def experiment_fn(output_dir, X, y, x_tst, y_tst):\n",
        "    # run experiment\n",
        "    train_spec = tf.estimator.TrainSpec(\n",
        "          input_fn=_train_fn(X, y, BATCH_SIZE), max_steps=1500)\n",
        "    exporter = tf.estimator.FinalExporter('timeseries',\n",
        "    serving_input_receiver_fn)\n",
        "    eval_spec = tf.estimator.EvalSpec(\n",
        "            input_fn=_test_fn(x_tst, y_tst, BATCH_SIZE),\n",
        "            exporters=[exporter])\n",
        "    \n",
        "    estimator = tf.estimator.Estimator(model_fn=simple_rnn, model_dir=output_dir)\n",
        "\n",
        "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n",
        "    return estimator\n",
        "\n",
        "\n",
        "def run_model(end_date, symbol='XOM'):  \n",
        "  print('Attempting to generate learning model for {}, using end_date={}'.format(symbol, end_date))\n",
        "  tf.logging.set_verbosity(tf.logging.INFO)    \n",
        "  output_dir = ROOT_DIR.format(datetime.utcnow().strftime('%Y%m%d%H%M%S'))  \n",
        "  X_train, y_train, X_test, y_test = create_train_and_test(end_date, symbol=symbol)\n",
        "  estimator = experiment_fn(output_dir, X_train, y_train, X_test, y_test)\n",
        "  print('Xtrain is:{} and of shape:{}', type(X_train), X_train.shape)\n",
        "  return estimator\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMzyPr_u4_At",
        "colab_type": "text"
      },
      "source": [
        "<h3> SETTING STARTDATE, ENDDATE AND TICKER </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3zgbsMrCbgP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SYMBOL = 'DIS'#'XOM'\n",
        "END_DATE= date.today()\n",
        "START_DATE = END_DATE - BDay(N_INPUTS) # This will be used for predicting future prices. end date will be 15 days ago, start_date 280 days earlier\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "augTdn3oqsK8",
        "colab_type": "text"
      },
      "source": [
        "<h3> Now running model </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEMTgvKICpoc",
        "colab_type": "code",
        "outputId": "f6e919e4-cf40-4661-8adc-aa8858acb1a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print('===================== CONFIGURATION ======================')\n",
        "print('STARTDATE={}'.format(START_DATE))\n",
        "print('ENDDATE={}'.format(END_DATE))\n",
        "print('SYMBOL={}'.format(SYMBOL))\n",
        "print('=== TRAINING MODEL ON PAST 280 DAYS from {}'.format(START_DATE))\n",
        "estimator = run_model(START_DATE, symbol=SYMBOL)\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===================== CONFIGURATION ======================\n",
            "STARTDATE=2019-06-12 00:00:00\n",
            "ENDDATE=2019-07-03\n",
            "SYMBOL=DIS\n",
            "=== TRAINING MODEL ON PAST 280 DAYS from 2019-06-12 00:00:00\n",
            "Attempting to generate learning model for DIS, using end_date=2019-06-12 00:00:00\n",
            "==== CREATING TIMESERIES GOING BACK 280 DAYS FROM  2019-06-12 00:00:00\n",
            "--Start:{%s}, end:{%s} 2018-05-16 00:00:00 2019-06-12 00:00:00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0703 19:36:37.356400 140195635861376 estimator.py:1790] Using default config.\n",
            "I0703 19:36:37.357666 140195635861376 estimator.py:209] Using config: {'_model_dir': '/home/mmistroni/tf_logs/rnn-run-20190703193636', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f818a8def98>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "W0703 19:36:37.358615 140195635861376 model_fn.py:630] Estimator's model_fn (<function simple_rnn at 0x7f818aad39d8>) includes params argument, but params are not passed to Estimator.\n",
            "I0703 19:36:37.364602 140195635861376 estimator_training.py:186] Not using Distribute Coordinator.\n",
            "I0703 19:36:37.366764 140195635861376 training.py:612] Running training and evaluation locally (non-distributed).\n",
            "I0703 19:36:37.368830 140195635861376 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "I0703 19:36:37.391749 140195635861376 estimator.py:1145] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Len of input dat ais {} 270\n",
            "All data shape is(13, 20) and type <class 'numpy.ndarray'>\n",
            "X is fo type <class 'numpy.float64'>, y  of type <class 'numpy.ndarray'>\n",
            "X.shape is (13, 15), y shap is (13, 5)\n",
            "IN Features are:{'rawdata': <tf.Tensor 'concat:0' shape=(11, 15) dtype=float32>}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0703 19:36:38.540808 140195635861376 estimator.py:1147] Done calling model_fn.\n",
            "I0703 19:36:38.543679 140195635861376 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "I0703 19:36:38.737385 140195635861376 monitored_session.py:240] Graph was finalized.\n",
            "I0703 19:36:38.791863 140195635861376 session_manager.py:500] Running local_init_op.\n",
            "I0703 19:36:38.812908 140195635861376 session_manager.py:502] Done running local_init_op.\n",
            "I0703 19:36:39.320550 140195635861376 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /home/mmistroni/tf_logs/rnn-run-20190703193636/model.ckpt.\n",
            "I0703 19:36:39.646717 140195635861376 basic_session_run_hooks.py:262] loss = 0.3158283, step = 1\n",
            "I0703 19:36:40.014417 140195635861376 basic_session_run_hooks.py:692] global_step/sec: 271.756\n",
            "I0703 19:36:40.018138 140195635861376 basic_session_run_hooks.py:260] loss = 0.05768039, step = 101 (0.371 sec)\n",
            "I0703 19:36:40.141987 140195635861376 basic_session_run_hooks.py:692] global_step/sec: 783.97\n",
            "I0703 19:36:40.147337 140195635861376 basic_session_run_hooks.py:260] loss = 0.011582432, step = 201 (0.129 sec)\n",
            "I0703 19:36:40.272511 140195635861376 basic_session_run_hooks.py:692] global_step/sec: 766.021\n",
            "I0703 19:36:40.274352 140195635861376 basic_session_run_hooks.py:260] loss = 0.002560202, step = 301 (0.127 sec)\n",
            "I0703 19:36:40.398970 140195635861376 basic_session_run_hooks.py:692] global_step/sec: 790.847\n",
            "I0703 19:36:40.404063 140195635861376 basic_session_run_hooks.py:260] loss = 0.00066231773, step = 401 (0.130 sec)\n",
            "I0703 19:36:40.525146 140195635861376 basic_session_run_hooks.py:692] global_step/sec: 792.567\n",
            "I0703 19:36:40.529939 140195635861376 basic_session_run_hooks.py:260] loss = 0.000238804, step = 501 (0.126 sec)\n",
            "I0703 19:36:40.655997 140195635861376 basic_session_run_hooks.py:692] global_step/sec: 764.119\n",
            "I0703 19:36:40.660461 140195635861376 basic_session_run_hooks.py:260] loss = 0.00013812771, step = 601 (0.131 sec)\n",
            "I0703 19:36:40.778498 140195635861376 basic_session_run_hooks.py:692] global_step/sec: 816.406\n",
            "I0703 19:36:40.780883 140195635861376 basic_session_run_hooks.py:260] loss = 0.00011221308, step = 701 (0.120 sec)\n",
            "I0703 19:36:40.903240 140195635861376 basic_session_run_hooks.py:692] global_step/sec: 801.763\n",
            "I0703 19:36:40.907603 140195635861376 basic_session_run_hooks.py:260] loss = 0.00010487184, step = 801 (0.127 sec)\n",
            "I0703 19:36:41.034252 140195635861376 basic_session_run_hooks.py:692] global_step/sec: 763.235\n",
            "I0703 19:36:41.036187 140195635861376 basic_session_run_hooks.py:260] loss = 0.00010257345, step = 901 (0.129 sec)\n",
            "I0703 19:36:41.166162 140195635861376 basic_session_run_hooks.py:692] global_step/sec: 758.243\n",
            "I0703 19:36:41.167949 140195635861376 basic_session_run_hooks.py:260] loss = 0.00010178799, step = 1001 (0.132 sec)\n",
            "I0703 19:36:41.287364 140195635861376 basic_session_run_hooks.py:692] global_step/sec: 824.73\n",
            "I0703 19:36:41.289130 140195635861376 basic_session_run_hooks.py:260] loss = 0.00010150096, step = 1101 (0.121 sec)\n",
            "I0703 19:36:41.406420 140195635861376 basic_session_run_hooks.py:692] global_step/sec: 839.991\n",
            "I0703 19:36:41.408974 140195635861376 basic_session_run_hooks.py:260] loss = 0.00010139051, step = 1201 (0.120 sec)\n",
            "I0703 19:36:41.521908 140195635861376 basic_session_run_hooks.py:692] global_step/sec: 866.311\n",
            "I0703 19:36:41.526501 140195635861376 basic_session_run_hooks.py:260] loss = 0.00010134585, step = 1301 (0.117 sec)\n",
            "I0703 19:36:41.646145 140195635861376 basic_session_run_hooks.py:692] global_step/sec: 804.488\n",
            "I0703 19:36:41.647897 140195635861376 basic_session_run_hooks.py:260] loss = 0.00010132644, step = 1401 (0.122 sec)\n",
            "I0703 19:36:41.764889 140195635861376 basic_session_run_hooks.py:606] Saving checkpoints for 1500 into /home/mmistroni/tf_logs/rnn-run-20190703193636/model.ckpt.\n",
            "I0703 19:36:41.865664 140195635861376 estimator.py:1145] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "IN Features are:{'rawdata': <tf.Tensor 'concat:0' shape=(2, 15) dtype=float32>}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0703 19:36:42.937024 140195635861376 estimator.py:1147] Done calling model_fn.\n",
            "I0703 19:36:42.962088 140195635861376 evaluation.py:255] Starting evaluation at 2019-07-03T19:36:42Z\n",
            "I0703 19:36:43.038809 140195635861376 monitored_session.py:240] Graph was finalized.\n",
            "I0703 19:36:43.043889 140195635861376 saver.py:1280] Restoring parameters from /home/mmistroni/tf_logs/rnn-run-20190703193636/model.ckpt-1500\n",
            "I0703 19:36:43.103560 140195635861376 session_manager.py:500] Running local_init_op.\n",
            "I0703 19:36:43.124576 140195635861376 session_manager.py:502] Done running local_init_op.\n",
            "I0703 19:36:43.213216 140195635861376 evaluation.py:167] Evaluation [10/100]\n",
            "I0703 19:36:43.224003 140195635861376 evaluation.py:167] Evaluation [20/100]\n",
            "I0703 19:36:43.234580 140195635861376 evaluation.py:167] Evaluation [30/100]\n",
            "I0703 19:36:43.244093 140195635861376 evaluation.py:167] Evaluation [40/100]\n",
            "I0703 19:36:43.256253 140195635861376 evaluation.py:167] Evaluation [50/100]\n",
            "I0703 19:36:43.265846 140195635861376 evaluation.py:167] Evaluation [60/100]\n",
            "I0703 19:36:43.275460 140195635861376 evaluation.py:167] Evaluation [70/100]\n",
            "I0703 19:36:43.286362 140195635861376 evaluation.py:167] Evaluation [80/100]\n",
            "I0703 19:36:43.296110 140195635861376 evaluation.py:167] Evaluation [90/100]\n",
            "I0703 19:36:43.305663 140195635861376 evaluation.py:167] Evaluation [100/100]\n",
            "I0703 19:36:43.332472 140195635861376 evaluation.py:275] Finished evaluation at 2019-07-03-19:36:43\n",
            "I0703 19:36:43.333559 140195635861376 estimator.py:2039] Saving dict for global step 1500: global_step = 1500, loss = 0.00013073163, rmse = 0.011433794\n",
            "I0703 19:36:43.486894 140195635861376 estimator.py:2099] Saving 'checkpoint_path' summary for global step 1500: /home/mmistroni/tf_logs/rnn-run-20190703193636/model.ckpt-1500\n",
            "I0703 19:36:43.488753 140195635861376 exporter.py:410] Performing the final export in the end of training.\n",
            "I0703 19:36:43.502051 140195635861376 estimator.py:1145] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "serving: features=Tensor(\"timeseries:0\", shape=(?, 15), dtype=float32)\n",
            "IN Features are:{'rawdata': <tf.Tensor 'timeseries:0' shape=(?, 15) dtype=float32>}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0703 19:36:43.949539 140195635861376 estimator.py:1147] Done calling model_fn.\n",
            "I0703 19:36:43.951153 140195635861376 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n",
            "I0703 19:36:43.955806 140195635861376 export_utils.py:170] Signatures INCLUDED in export for Regress: None\n",
            "I0703 19:36:43.957349 140195635861376 export_utils.py:170] Signatures INCLUDED in export for Predict: ['predicted', 'serving_default']\n",
            "I0703 19:36:43.961131 140195635861376 export_utils.py:170] Signatures INCLUDED in export for Train: None\n",
            "I0703 19:36:43.962477 140195635861376 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n",
            "I0703 19:36:43.984742 140195635861376 saver.py:1280] Restoring parameters from /home/mmistroni/tf_logs/rnn-run-20190703193636/model.ckpt-1500\n",
            "I0703 19:36:44.004975 140195635861376 builder_impl.py:661] Assets added to graph.\n",
            "I0703 19:36:44.005910 140195635861376 builder_impl.py:456] No assets to write.\n",
            "I0703 19:36:44.057293 140195635861376 builder_impl.py:421] SavedModel written to: /home/mmistroni/tf_logs/rnn-run-20190703193636/export/timeseries/temp-b'1562182603'/saved_model.pb\n",
            "I0703 19:36:44.076080 140195635861376 estimator.py:368] Loss for final step: 0.000101316946.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Xtrain is:{} and of shape:{} <class 'numpy.ndarray'> (11, 15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bSKL1hdpyVD",
        "colab_type": "text"
      },
      "source": [
        "<h3> Now, after training,  Let's do some predictions for future </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQkN-vTbp6E9",
        "colab_type": "code",
        "outputId": "0d9c20ce-770c-4736-9c6f-7393a7469fbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "source": [
        "from datetime import date\n",
        "from pprint import pprint\n",
        "# going back to last month\n",
        "tf.logging.set_verbosity(tf.logging.INFO)    \n",
        "\n",
        "def _predict_fn(X) :\n",
        "    def _predict():\n",
        "        \"\"\"An input function for training\"\"\"\n",
        "        # Convert the inputs to a Dataset.\n",
        "        X_32 = tf.cast(X, tf.float32)\n",
        "        inputs = tf.concat(X_32, axis=1)\n",
        "        features = {TIMESERIES_COL: inputs}\n",
        "        return features\n",
        "    return _predict\n",
        "\n",
        "  \n",
        "#TODO amend this function, the one above should be reused....\n",
        "def get_prices2(startdate=None, enddate=None, symbol='XOM'):\n",
        "  import pandas_datareader as pdr\n",
        "  from datetime import date, timedelta\n",
        "  print ('--Start:{%s}, end:{%s}', startdate, enddate)\n",
        "  \n",
        "  if not startdate and not enddate:\n",
        "    last_check = date.today() - BDay(SEQ_LEN * 2) \n",
        "    enddate = last_check\n",
        "    startdate = last_check - BDay(122)#timedelta(days=120)\n",
        "  return pdr.get_data_yahoo(symbol, startdate, enddate)[['Close']]\n",
        "\n",
        "\n",
        "print('==== GETTING MOST RECENT PRICES======')\n",
        "stock_data = get_prices2(START_DATE- BDay(1), END_DATE, symbol=SYMBOL)\n",
        "percentage_changes = stock_data.pct_change().fillna(0)\n",
        "#First Price\n",
        "first_price = stock_data.values[0]\n",
        "print('==============First ever price of the series of shape {} is {}'.format(stock_data.shape, first_price ))\n",
        "print(stock_data.head(30))\n",
        "print('=========== PERCENTAGE CHANGES ===========')\n",
        "print(percentage_changes.head(30))\n",
        "\n",
        "\n",
        "\n",
        "prices = np.stack(percentage_changes['Close'])\n",
        "#prices = np.stack(stock_data['Close'])\n",
        "print('===== PRICES ARE===')\n",
        "\n",
        "pprint(prices)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==== GETTING MOST RECENT PRICES======\n",
            "--Start:{%s}, end:{%s} 2019-06-11 00:00:00 2019-07-03\n",
            "==============First ever price of the series of shape (17, 1) is [135.08000183]\n",
            "                 Close\n",
            "Date                  \n",
            "2019-06-11  135.080002\n",
            "2019-06-12  135.720001\n",
            "2019-06-13  141.740005\n",
            "2019-06-14  141.649994\n",
            "2019-06-17  140.970001\n",
            "2019-06-18  139.240005\n",
            "2019-06-19  140.919998\n",
            "2019-06-20  142.020004\n",
            "2019-06-21  140.229996\n",
            "2019-06-24  139.220001\n",
            "2019-06-25  139.940002\n",
            "2019-06-26  140.399994\n",
            "2019-06-27  139.300003\n",
            "2019-06-28  139.639999\n",
            "2019-07-01  141.649994\n",
            "2019-07-02  142.529999\n",
            "2019-07-03  142.979996\n",
            "=========== PERCENTAGE CHANGES ===========\n",
            "               Close\n",
            "Date                \n",
            "2019-06-11  0.000000\n",
            "2019-06-12  0.004738\n",
            "2019-06-13  0.044356\n",
            "2019-06-14 -0.000635\n",
            "2019-06-17 -0.004801\n",
            "2019-06-18 -0.012272\n",
            "2019-06-19  0.012065\n",
            "2019-06-20  0.007806\n",
            "2019-06-21 -0.012604\n",
            "2019-06-24 -0.007202\n",
            "2019-06-25  0.005172\n",
            "2019-06-26  0.003287\n",
            "2019-06-27 -0.007835\n",
            "2019-06-28  0.002441\n",
            "2019-07-01  0.014394\n",
            "2019-07-02  0.006213\n",
            "2019-07-03  0.003157\n",
            "===== PRICES ARE===\n",
            "array([ 0.        ,  0.00473793,  0.04435606, -0.00063505, -0.00480051,\n",
            "       -0.01227208,  0.01206545,  0.00780589, -0.01260392, -0.00720241,\n",
            "        0.00517168,  0.00328706, -0.00783469,  0.00244075,  0.01439412,\n",
            "        0.00621253,  0.00315721])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQiIzVoFEa6u",
        "colab_type": "text"
      },
      "source": [
        "<h3> Now recalculating price percentages to predict </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzaOht5kERuR",
        "colab_type": "code",
        "outputId": "83ee35d9-4394-425a-a757-2b31355b3e85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Reshaping data\n",
        "print ('Prices is of shape:{}', prices.shape)\n",
        "prices = prices.reshape(-1,N_INPUTS) if prices.shape[0] % 15 == 0 else prices[-15:].reshape(-1,N_INPUTS)\n",
        "print ('Reshaped Prices is of shape:{}', prices.shape)\n",
        "print ('-------- PREDICTING -------')\n",
        "print (type(prices))\n",
        "\n",
        "\n",
        "acc = []\n",
        "acc += prices[0].tolist()\n",
        "\n",
        "\n",
        "for i in range(0,10):\n",
        "  # Given last 15 days, predict the next 5\n",
        "  candidate = np.array(acc[-15:]).reshape(-1,15)  # this is the Train #\n",
        "  pred = estimator.predict(input_fn = _predict_fn(candidate))\n",
        "  item = next(pred)\n",
        "  vals = item['predicted'] # this is the predicted\n",
        "  # Next 5 predicted. Now,  we need to retrain the model to add the 5 predicted\n",
        "  # Then, as test data, pick the previous 15 and then predict the next one\n",
        "  \n",
        "  \"\"\"\n",
        "  ATTEMPT TO RETRAIN THE MODEL..\n",
        "    print(\"====== Now adding prediction to current train....\")\n",
        "    print(\"Xtrain of type:{}, candidate of type:{}\".format(type(X_train), type(candidate)))\n",
        "    print(\"SHapes.Train:{}, Candidate:{}\".format(X_train.shape, candidate.shape))\n",
        "    #X_train = np.vstack([X_train , candidate])\n",
        "    #y_train = np.vstack([y_train , vals])\n",
        "    # So Now we have to \n",
        "    # 1. retrain the model\n",
        "    # 2. get the most recent 15 days to \n",
        "  \n",
        "  \"\"\"\n",
        "  print ('Round {} Prediction: on {}={}'.format(i, candidate, vals))\n",
        "  print ('{}={}'.format(type(vals), vals.tolist()))\n",
        "  acc += vals.tolist()\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0703 19:37:18.765938 140195635861376 estimator.py:1000] Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
            "I0703 19:37:18.766930 140195635861376 estimator.py:1145] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Prices is of shape:{} (17,)\n",
            "Reshaped Prices is of shape:{} (1, 15)\n",
            "-------- PREDICTING -------\n",
            "<class 'numpy.ndarray'>\n",
            "IN Features are:{'rawdata': <tf.Tensor 'concat:0' shape=(1, 15) dtype=float32>}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0703 19:37:18.991616 140195635861376 estimator.py:1147] Done calling model_fn.\n",
            "I0703 19:37:19.063185 140195635861376 monitored_session.py:240] Graph was finalized.\n",
            "I0703 19:37:19.068585 140195635861376 saver.py:1280] Restoring parameters from /home/mmistroni/tf_logs/rnn-run-20190703193636/model.ckpt-1500\n",
            "I0703 19:37:19.101164 140195635861376 session_manager.py:500] Running local_init_op.\n",
            "I0703 19:37:19.107667 140195635861376 session_manager.py:502] Done running local_init_op.\n",
            "W0703 19:37:19.174830 140195635861376 estimator.py:1000] Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
            "I0703 19:37:19.175960 140195635861376 estimator.py:1145] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Round 0 Prediction: on [[ 0.04435606 -0.00063505 -0.00480051 -0.01227208  0.01206545  0.00780589\n",
            "  -0.01260392 -0.00720241  0.00517168  0.00328706 -0.00783469  0.00244075\n",
            "   0.01439412  0.00621253  0.00315721]]=[ 6.2403977e-03  4.3793470e-03  5.2854419e-03 -1.8239021e-05\n",
            " -6.8126451e-03]\n",
            "<class 'numpy.ndarray'>=[0.006240397691726685, 0.004379346966743469, 0.005285441875457764, -1.823902130126953e-05, -0.006812645122408867]\n",
            "IN Features are:{'rawdata': <tf.Tensor 'concat:0' shape=(1, 15) dtype=float32>}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0703 19:37:19.419659 140195635861376 estimator.py:1147] Done calling model_fn.\n",
            "I0703 19:37:19.491446 140195635861376 monitored_session.py:240] Graph was finalized.\n",
            "I0703 19:37:19.496734 140195635861376 saver.py:1280] Restoring parameters from /home/mmistroni/tf_logs/rnn-run-20190703193636/model.ckpt-1500\n",
            "I0703 19:37:19.530741 140195635861376 session_manager.py:500] Running local_init_op.\n",
            "I0703 19:37:19.536477 140195635861376 session_manager.py:502] Done running local_init_op.\n",
            "W0703 19:37:19.606058 140195635861376 estimator.py:1000] Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
            "I0703 19:37:19.607410 140195635861376 estimator.py:1145] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Round 1 Prediction: on [[ 7.80589070e-03 -1.26039184e-02 -7.20241416e-03  5.17167946e-03\n",
            "   3.28706193e-03 -7.83469297e-03  2.44074896e-03  1.43941171e-02\n",
            "   6.21253033e-03  3.15720867e-03  6.24039769e-03  4.37934697e-03\n",
            "   5.28544188e-03 -1.82390213e-05 -6.81264512e-03]]=[ 0.00264841  0.00807804  0.00178427  0.0013352  -0.00255535]\n",
            "<class 'numpy.ndarray'>=[0.0026484131813049316, 0.008078038692474365, 0.0017842650413513184, 0.001335199922323227, -0.0025553542654961348]\n",
            "IN Features are:{'rawdata': <tf.Tensor 'concat:0' shape=(1, 15) dtype=float32>}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0703 19:37:19.826451 140195635861376 estimator.py:1147] Done calling model_fn.\n",
            "I0703 19:37:19.908909 140195635861376 monitored_session.py:240] Graph was finalized.\n",
            "I0703 19:37:19.914631 140195635861376 saver.py:1280] Restoring parameters from /home/mmistroni/tf_logs/rnn-run-20190703193636/model.ckpt-1500\n",
            "I0703 19:37:19.955994 140195635861376 session_manager.py:500] Running local_init_op.\n",
            "I0703 19:37:19.965014 140195635861376 session_manager.py:502] Done running local_init_op.\n",
            "W0703 19:37:20.045011 140195635861376 estimator.py:1000] Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
            "I0703 19:37:20.046416 140195635861376 estimator.py:1145] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Round 2 Prediction: on [[-7.83469297e-03  2.44074896e-03  1.43941171e-02  6.21253033e-03\n",
            "   3.15720867e-03  6.24039769e-03  4.37934697e-03  5.28544188e-03\n",
            "  -1.82390213e-05 -6.81264512e-03  2.64841318e-03  8.07803869e-03\n",
            "   1.78426504e-03  1.33519992e-03 -2.55535427e-03]]=[ 0.00328943  0.00762805  0.00257146  0.00157656 -0.0030764 ]\n",
            "<class 'numpy.ndarray'>=[0.00328943133354187, 0.007628053426742554, 0.0025714635848999023, 0.0015765614807605743, -0.003076402936130762]\n",
            "IN Features are:{'rawdata': <tf.Tensor 'concat:0' shape=(1, 15) dtype=float32>}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0703 19:37:20.556002 140195635861376 estimator.py:1147] Done calling model_fn.\n",
            "I0703 19:37:20.621421 140195635861376 monitored_session.py:240] Graph was finalized.\n",
            "I0703 19:37:20.626576 140195635861376 saver.py:1280] Restoring parameters from /home/mmistroni/tf_logs/rnn-run-20190703193636/model.ckpt-1500\n",
            "I0703 19:37:20.657511 140195635861376 session_manager.py:500] Running local_init_op.\n",
            "I0703 19:37:20.662001 140195635861376 session_manager.py:502] Done running local_init_op.\n",
            "W0703 19:37:20.726904 140195635861376 estimator.py:1000] Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
            "I0703 19:37:20.728291 140195635861376 estimator.py:1145] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Round 3 Prediction: on [[ 6.24039769e-03  4.37934697e-03  5.28544188e-03 -1.82390213e-05\n",
            "  -6.81264512e-03  2.64841318e-03  8.07803869e-03  1.78426504e-03\n",
            "   1.33519992e-03 -2.55535427e-03  3.28943133e-03  7.62805343e-03\n",
            "   2.57146358e-03  1.57656148e-03 -3.07640294e-03]]=[ 0.00340325  0.00748514  0.00257868  0.00143409 -0.00325755]\n",
            "<class 'numpy.ndarray'>=[0.0034032464027404785, 0.007485136389732361, 0.0025786757469177246, 0.001434091478586197, -0.0032575521618127823]\n",
            "IN Features are:{'rawdata': <tf.Tensor 'concat:0' shape=(1, 15) dtype=float32>}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0703 19:37:20.949342 140195635861376 estimator.py:1147] Done calling model_fn.\n",
            "I0703 19:37:21.020484 140195635861376 monitored_session.py:240] Graph was finalized.\n",
            "I0703 19:37:21.025530 140195635861376 saver.py:1280] Restoring parameters from /home/mmistroni/tf_logs/rnn-run-20190703193636/model.ckpt-1500\n",
            "I0703 19:37:21.056341 140195635861376 session_manager.py:500] Running local_init_op.\n",
            "I0703 19:37:21.062576 140195635861376 session_manager.py:502] Done running local_init_op.\n",
            "W0703 19:37:21.124923 140195635861376 estimator.py:1000] Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
            "I0703 19:37:21.125939 140195635861376 estimator.py:1145] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Round 4 Prediction: on [[ 0.00264841  0.00807804  0.00178427  0.0013352  -0.00255535  0.00328943\n",
            "   0.00762805  0.00257146  0.00157656 -0.0030764   0.00340325  0.00748514\n",
            "   0.00257868  0.00143409 -0.00325755]]=[ 0.00331822  0.00755914  0.00251949  0.00145131 -0.00316536]\n",
            "<class 'numpy.ndarray'>=[0.003318220376968384, 0.007559135556221008, 0.0025194883346557617, 0.0014513060450553894, -0.003165361937135458]\n",
            "IN Features are:{'rawdata': <tf.Tensor 'concat:0' shape=(1, 15) dtype=float32>}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0703 19:37:21.350624 140195635861376 estimator.py:1147] Done calling model_fn.\n",
            "I0703 19:37:21.422253 140195635861376 monitored_session.py:240] Graph was finalized.\n",
            "I0703 19:37:21.429136 140195635861376 saver.py:1280] Restoring parameters from /home/mmistroni/tf_logs/rnn-run-20190703193636/model.ckpt-1500\n",
            "I0703 19:37:21.459489 140195635861376 session_manager.py:500] Running local_init_op.\n",
            "I0703 19:37:21.466938 140195635861376 session_manager.py:502] Done running local_init_op.\n",
            "W0703 19:37:21.535009 140195635861376 estimator.py:1000] Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
            "I0703 19:37:21.536206 140195635861376 estimator.py:1145] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Round 5 Prediction: on [[ 0.00328943  0.00762805  0.00257146  0.00157656 -0.0030764   0.00340325\n",
            "   0.00748514  0.00257868  0.00143409 -0.00325755  0.00331822  0.00755914\n",
            "   0.00251949  0.00145131 -0.00316536]]=[ 0.00333282  0.00754994  0.00253552  0.00145788 -0.00317662]\n",
            "<class 'numpy.ndarray'>=[0.0033328235149383545, 0.007549941539764404, 0.002535521984100342, 0.0014578849077224731, -0.0031766227912157774]\n",
            "IN Features are:{'rawdata': <tf.Tensor 'concat:0' shape=(1, 15) dtype=float32>}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0703 19:37:21.760687 140195635861376 estimator.py:1147] Done calling model_fn.\n",
            "I0703 19:37:22.013992 140195635861376 monitored_session.py:240] Graph was finalized.\n",
            "I0703 19:37:22.019365 140195635861376 saver.py:1280] Restoring parameters from /home/mmistroni/tf_logs/rnn-run-20190703193636/model.ckpt-1500\n",
            "I0703 19:37:22.047173 140195635861376 session_manager.py:500] Running local_init_op.\n",
            "I0703 19:37:22.059063 140195635861376 session_manager.py:502] Done running local_init_op.\n",
            "W0703 19:37:22.129568 140195635861376 estimator.py:1000] Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
            "I0703 19:37:22.131026 140195635861376 estimator.py:1145] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Round 6 Prediction: on [[ 0.00340325  0.00748514  0.00257868  0.00143409 -0.00325755  0.00331822\n",
            "   0.00755914  0.00251949  0.00145131 -0.00316536  0.00333282  0.00754994\n",
            "   0.00253552  0.00145788 -0.00317662]]=[ 0.00333545  0.00754656  0.00253582  0.00145454 -0.00318083]\n",
            "<class 'numpy.ndarray'>=[0.0033354461193084717, 0.007546558976173401, 0.0025358200073242188, 0.0014545358717441559, -0.0031808295752853155]\n",
            "IN Features are:{'rawdata': <tf.Tensor 'concat:0' shape=(1, 15) dtype=float32>}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0703 19:37:22.354471 140195635861376 estimator.py:1147] Done calling model_fn.\n",
            "I0703 19:37:22.422350 140195635861376 monitored_session.py:240] Graph was finalized.\n",
            "I0703 19:37:22.426964 140195635861376 saver.py:1280] Restoring parameters from /home/mmistroni/tf_logs/rnn-run-20190703193636/model.ckpt-1500\n",
            "I0703 19:37:22.454045 140195635861376 session_manager.py:500] Running local_init_op.\n",
            "I0703 19:37:22.460580 140195635861376 session_manager.py:502] Done running local_init_op.\n",
            "W0703 19:37:22.526489 140195635861376 estimator.py:1000] Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
            "I0703 19:37:22.527571 140195635861376 estimator.py:1145] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Round 7 Prediction: on [[ 0.00331822  0.00755914  0.00251949  0.00145131 -0.00316536  0.00333282\n",
            "   0.00754994  0.00253552  0.00145788 -0.00317662  0.00333545  0.00754656\n",
            "   0.00253582  0.00145454 -0.00318083]]=[ 0.00333354  0.00754826  0.00253439  0.00145495 -0.00317876]\n",
            "<class 'numpy.ndarray'>=[0.003333538770675659, 0.0075482577085494995, 0.0025343894958496094, 0.0014549531042575836, -0.0031787590123713017]\n",
            "IN Features are:{'rawdata': <tf.Tensor 'concat:0' shape=(1, 15) dtype=float32>}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0703 19:37:22.754054 140195635861376 estimator.py:1147] Done calling model_fn.\n",
            "I0703 19:37:22.819294 140195635861376 monitored_session.py:240] Graph was finalized.\n",
            "I0703 19:37:22.825069 140195635861376 saver.py:1280] Restoring parameters from /home/mmistroni/tf_logs/rnn-run-20190703193636/model.ckpt-1500\n",
            "I0703 19:37:22.852775 140195635861376 session_manager.py:500] Running local_init_op.\n",
            "I0703 19:37:22.859030 140195635861376 session_manager.py:502] Done running local_init_op.\n",
            "W0703 19:37:22.926882 140195635861376 estimator.py:1000] Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
            "I0703 19:37:22.928130 140195635861376 estimator.py:1145] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Round 8 Prediction: on [[ 0.00333282  0.00754994  0.00253552  0.00145788 -0.00317662  0.00333545\n",
            "   0.00754656  0.00253582  0.00145454 -0.00318083  0.00333354  0.00754826\n",
            "   0.00253439  0.00145495 -0.00317876]]=[ 0.00333387  0.00754808  0.00253481  0.00145508 -0.00317907]\n",
            "<class 'numpy.ndarray'>=[0.003333866596221924, 0.007548078894615173, 0.002534806728363037, 0.0014550834894180298, -0.0031790693756192923]\n",
            "IN Features are:{'rawdata': <tf.Tensor 'concat:0' shape=(1, 15) dtype=float32>}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0703 19:37:23.157599 140195635861376 estimator.py:1147] Done calling model_fn.\n",
            "I0703 19:37:23.224463 140195635861376 monitored_session.py:240] Graph was finalized.\n",
            "I0703 19:37:23.229152 140195635861376 saver.py:1280] Restoring parameters from /home/mmistroni/tf_logs/rnn-run-20190703193636/model.ckpt-1500\n",
            "I0703 19:37:23.255382 140195635861376 session_manager.py:500] Running local_init_op.\n",
            "I0703 19:37:23.260755 140195635861376 session_manager.py:502] Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Round 9 Prediction: on [[ 0.00333545  0.00754656  0.00253582  0.00145454 -0.00318083  0.00333354\n",
            "   0.00754826  0.00253439  0.00145495 -0.00317876  0.00333387  0.00754808\n",
            "   0.00253481  0.00145508 -0.00317907]]=[ 0.0033339   0.00754803  0.00253481  0.00145499 -0.00317911]\n",
            "<class 'numpy.ndarray'>=[0.0033338963985443115, 0.007548034191131592, 0.002534806728363037, 0.0014549940824508667, -0.0031791063956916332]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zxm7H9jzsEGL",
        "colab_type": "text"
      },
      "source": [
        "<h3> Now visualizing price predictions against date time </h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prI5nJS_S4nf",
        "colab_type": "text"
      },
      "source": [
        "Installing libraries and downloading data as DataFrame\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8SxyWVIxS3L",
        "colab_type": "code",
        "outputId": "5733f165-c002-4d0c-8aa2-711bbe6569c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print('-------------- END OF STORY')\n",
        "from pprint import pprint\n",
        "future_days = len(acc) - 15\n",
        "pprint('Accumlator has length:{}'.format(len(acc)))\n",
        "pprint('We have prediction for the next:{} days'.format(future_days))\n",
        "print(\"calculating business days to zip \")\n",
        "# we got start date, todays - 15\n",
        "# end date is  today + \n",
        "dts = [START_DATE + BDay(offset) for offset in range(0, len(acc))]\n",
        "       \n",
        "print('Start Date:{}={}'.format(dts[0], START_DATE))\n",
        "print('End date:{}'.format(dts[-1]))\n",
        "       \n",
        "zipped = [tpl for tpl in zip(acc, dts)]\n",
        "       \n",
        "       \n",
        "print('===== FULL PREDICTIONS======')\n",
        "pprint(zipped)\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------- END OF STORY\n",
            "'Accumlator has length:65'\n",
            "'We have prediction for the next:50 days'\n",
            "calculating business days to zip \n",
            "Start Date:2019-06-12 00:00:00=2019-06-12 00:00:00\n",
            "End date:2019-09-10 00:00:00\n",
            "===== FULL PREDICTIONS======\n",
            "[(0.044356058195662795, Timestamp('2019-06-12 00:00:00')),\n",
            " (-0.0006350472216118952, Timestamp('2019-06-13 00:00:00')),\n",
            " (-0.00480051327272335, Timestamp('2019-06-14 00:00:00')),\n",
            " (-0.012272084220461776, Timestamp('2019-06-17 00:00:00')),\n",
            " (0.012065445342601011, Timestamp('2019-06-18 00:00:00')),\n",
            " (0.007805890702587526, Timestamp('2019-06-19 00:00:00')),\n",
            " (-0.012603918399324954, Timestamp('2019-06-20 00:00:00')),\n",
            " (-0.007202414159651838, Timestamp('2019-06-21 00:00:00')),\n",
            " (0.005171679459776257, Timestamp('2019-06-24 00:00:00')),\n",
            " (0.0032870619340650276, Timestamp('2019-06-25 00:00:00')),\n",
            " (-0.00783469296684991, Timestamp('2019-06-26 00:00:00')),\n",
            " (0.0024407489622544354, Timestamp('2019-06-27 00:00:00')),\n",
            " (0.014394117127050965, Timestamp('2019-06-28 00:00:00')),\n",
            " (0.006212530326373367, Timestamp('2019-07-01 00:00:00')),\n",
            " (0.0031572086725335513, Timestamp('2019-07-02 00:00:00')),\n",
            " (0.006240397691726685, Timestamp('2019-07-03 00:00:00')),\n",
            " (0.004379346966743469, Timestamp('2019-07-04 00:00:00')),\n",
            " (0.005285441875457764, Timestamp('2019-07-05 00:00:00')),\n",
            " (-1.823902130126953e-05, Timestamp('2019-07-08 00:00:00')),\n",
            " (-0.006812645122408867, Timestamp('2019-07-09 00:00:00')),\n",
            " (0.0026484131813049316, Timestamp('2019-07-10 00:00:00')),\n",
            " (0.008078038692474365, Timestamp('2019-07-11 00:00:00')),\n",
            " (0.0017842650413513184, Timestamp('2019-07-12 00:00:00')),\n",
            " (0.001335199922323227, Timestamp('2019-07-15 00:00:00')),\n",
            " (-0.0025553542654961348, Timestamp('2019-07-16 00:00:00')),\n",
            " (0.00328943133354187, Timestamp('2019-07-17 00:00:00')),\n",
            " (0.007628053426742554, Timestamp('2019-07-18 00:00:00')),\n",
            " (0.0025714635848999023, Timestamp('2019-07-19 00:00:00')),\n",
            " (0.0015765614807605743, Timestamp('2019-07-22 00:00:00')),\n",
            " (-0.003076402936130762, Timestamp('2019-07-23 00:00:00')),\n",
            " (0.0034032464027404785, Timestamp('2019-07-24 00:00:00')),\n",
            " (0.007485136389732361, Timestamp('2019-07-25 00:00:00')),\n",
            " (0.0025786757469177246, Timestamp('2019-07-26 00:00:00')),\n",
            " (0.001434091478586197, Timestamp('2019-07-29 00:00:00')),\n",
            " (-0.0032575521618127823, Timestamp('2019-07-30 00:00:00')),\n",
            " (0.003318220376968384, Timestamp('2019-07-31 00:00:00')),\n",
            " (0.007559135556221008, Timestamp('2019-08-01 00:00:00')),\n",
            " (0.0025194883346557617, Timestamp('2019-08-02 00:00:00')),\n",
            " (0.0014513060450553894, Timestamp('2019-08-05 00:00:00')),\n",
            " (-0.003165361937135458, Timestamp('2019-08-06 00:00:00')),\n",
            " (0.0033328235149383545, Timestamp('2019-08-07 00:00:00')),\n",
            " (0.007549941539764404, Timestamp('2019-08-08 00:00:00')),\n",
            " (0.002535521984100342, Timestamp('2019-08-09 00:00:00')),\n",
            " (0.0014578849077224731, Timestamp('2019-08-12 00:00:00')),\n",
            " (-0.0031766227912157774, Timestamp('2019-08-13 00:00:00')),\n",
            " (0.0033354461193084717, Timestamp('2019-08-14 00:00:00')),\n",
            " (0.007546558976173401, Timestamp('2019-08-15 00:00:00')),\n",
            " (0.0025358200073242188, Timestamp('2019-08-16 00:00:00')),\n",
            " (0.0014545358717441559, Timestamp('2019-08-19 00:00:00')),\n",
            " (-0.0031808295752853155, Timestamp('2019-08-20 00:00:00')),\n",
            " (0.003333538770675659, Timestamp('2019-08-21 00:00:00')),\n",
            " (0.0075482577085494995, Timestamp('2019-08-22 00:00:00')),\n",
            " (0.0025343894958496094, Timestamp('2019-08-23 00:00:00')),\n",
            " (0.0014549531042575836, Timestamp('2019-08-26 00:00:00')),\n",
            " (-0.0031787590123713017, Timestamp('2019-08-27 00:00:00')),\n",
            " (0.003333866596221924, Timestamp('2019-08-28 00:00:00')),\n",
            " (0.007548078894615173, Timestamp('2019-08-29 00:00:00')),\n",
            " (0.002534806728363037, Timestamp('2019-08-30 00:00:00')),\n",
            " (0.0014550834894180298, Timestamp('2019-09-02 00:00:00')),\n",
            " (-0.0031790693756192923, Timestamp('2019-09-03 00:00:00')),\n",
            " (0.0033338963985443115, Timestamp('2019-09-04 00:00:00')),\n",
            " (0.007548034191131592, Timestamp('2019-09-05 00:00:00')),\n",
            " (0.002534806728363037, Timestamp('2019-09-06 00:00:00')),\n",
            " (0.0014549940824508667, Timestamp('2019-09-09 00:00:00')),\n",
            " (-0.0031791063956916332, Timestamp('2019-09-10 00:00:00'))]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2ouepeT_28w",
        "colab_type": "code",
        "outputId": "25a1d1b0-84ab-4c15-90c5-b53ab6c97de0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from functools import reduce\n",
        "final_predictions  = acc\n",
        "#pprint(final_predictions)\n",
        "# Then find the end price by using reduce and entering the first price \n",
        "res = reduce(lambda acc,x: acc * (1+x) ,  final_predictions, first_price)\n",
        "\n",
        "print('Final Price for series{} = {}'.format(zipped[-1], res))\n",
        "\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final Price for series(-0.0031791063956916332, Timestamp('2019-09-10 00:00:00')) = [159.44086624]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7AjEH52vS-6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}