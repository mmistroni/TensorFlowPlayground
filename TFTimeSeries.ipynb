{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFTimeSeries.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmistroni/TensorFlowPlayground/blob/master/TFTimeSeries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7j1C2K-pSCvo",
        "colab_type": "code",
        "outputId": "6fa85a5a-2464-459d-a265-cf7f36fbd476",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "!pip install pandas_datareader"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas_datareader in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from pandas_datareader) (2.21.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from pandas_datareader) (4.2.6)\n",
            "Requirement already satisfied: pandas>=0.19.2 in /usr/local/lib/python3.6/dist-packages (from pandas_datareader) (0.24.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from pandas_datareader) (1.11.2)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas_datareader) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas_datareader) (2019.6.16)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas_datareader) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas_datareader) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->pandas_datareader) (2.5.3)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->pandas_datareader) (1.16.4)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->pandas_datareader) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas>=0.19.2->pandas_datareader) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03Y2LC7ZQtOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import tensorflow as tf\n",
        "from datetime import date\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.contrib.learn import ModeKeys\n",
        "import tensorflow.contrib.rnn as rnn\n",
        "from datetime import datetime, date, timedelta\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-Irklu5ENWm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from pandas.tseries.offsets import BDay\n",
        "TIMESERIES_COL = 'rawdata'\n",
        "N_OUTPUTS = 5 # in each sequence, 1-14 are features, and 14-20 is label \n",
        "SEQ_LEN = 20\n",
        "DEFAULTS = 0.0\n",
        "LSTM_SIZE = 5 # number of hidden layers in each of the LSTM cells\n",
        "N_INPUTS = SEQ_LEN - N_OUTPUTS\n",
        "BATCH_SIZE = 20\n",
        "ROOT_DIR = '/home/mmistroni/tf_logs/rnn-run-{}'\n",
        "\n",
        "\n",
        "def get_prices(startdate, enddate, symbol):\n",
        "  import pandas_datareader as pdr\n",
        "  from datetime import date, timedelta\n",
        "  print ('--Start:{%s}, end:{%s}', startdate, enddate)\n",
        "  \n",
        "  stock_data = pdr.get_data_yahoo(symbol, startdate, enddate)[['Close']].pct_change().fillna(0)\n",
        "  adjClose = np.stack(stock_data['Close'])\n",
        "  return adjClose\n",
        "  \n",
        "def create_training_data2(inputData):\n",
        "  print ('Len of input dat ais {}', len(inputData))\n",
        "  return [np.array(inputData[i * SEQ_LEN: (i + 1) * SEQ_LEN]) \n",
        "       for i in range(len(inputData) // SEQ_LEN)]\n",
        "\n",
        "def create_training_data(inputData):\n",
        "  print ('AdjClose is of shape {}', inputData.shape)\n",
        "  return inputData.T.reshape(-1,SEQ_LEN)\n",
        "  \n",
        "  \n",
        "def create_time_series(end_date, numDays=360, symbol='XOM'):\n",
        "  print(\"==== CREATING TIMESERIES GOING BACK 280 DAYS FROM  {}\".format(end_date))\n",
        "  endDate = end_date # training from 20 days ago\n",
        "  startDate = endDate - BDay(numDays)\n",
        "  prices =  get_prices(startDate, endDate, symbol=symbol)\n",
        "  return create_training_data2(prices)\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "whdGmgDC4Fr2",
        "colab": {}
      },
      "source": [
        "\n",
        "def create_train_and_test(end_date, symbol='XOM',extra_prices=None):\n",
        "  all_timeseries =  create_time_series(end_date, symbol=symbol) #[create_time_series() for i in range(0, SEQ_LEN * 4)]\n",
        "  if extra_prices:\n",
        "    print('ADDING extra prices with size:{}'.format(extra_prices))\n",
        "    all_timeseries = all_timeseries + extra_prices\n",
        "  print(\"Timeseries is of type:{} and has length:{}\".format(type(all_timeseries), len(all_timeseries)))\n",
        "  all_data = np.stack(all_timeseries)\n",
        "  print('All data shape is{0} and type {1}'.format(all_data.shape,type(all_data)))\n",
        "  X, y = all_data[...,0:-N_OUTPUTS], all_data[...,-N_OUTPUTS:]\n",
        "  print ('X is fo type {0}, y  of type {1}'.format(type(X[0][0]), type(y)))\n",
        "  print ('X.shape is {0}, y shap is {1}'.format(X.shape, y.shape))\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X,\n",
        "                                                      y,\n",
        "                                                      test_size=0.1,\n",
        "                                                      random_state=1)\n",
        "  return X_train, y_train, X_test, y_test\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRRxa0F87wog",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e7ba8b70-8e42-4854-cac2-545385fb9dc4"
      },
      "source": [
        "create_train_and_test(date.today())"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==== CREATING TIMESERIES GOING BACK 280 DAYS FROM  2019-07-25\n",
            "--Start:{%s}, end:{%s} 2018-03-08 00:00:00 2019-07-25\n",
            "Len of input dat ais {} 348\n",
            "Timeseries is of type:<class 'list'> and has length:17\n",
            "All data shape is(17, 20) and type <class 'numpy.ndarray'>\n",
            "X is fo type <class 'numpy.float64'>, y  of type <class 'numpy.ndarray'>\n",
            "X.shape is (17, 15), y shap is (17, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-0.00832371, -0.0001166 , -0.00874432,  0.00929194,  0.00757489,\n",
              "         -0.00358544, -0.00661636, -0.00280446,  0.0092571 ,  0.00441199,\n",
              "         -0.02300318, -0.03454802, -0.00269609, -0.00688127,  0.00470177],\n",
              "        [ 0.00470343,  0.01092323,  0.00450217,  0.02356261,  0.02239461,\n",
              "         -0.00538427,  0.00676677, -0.00048883,  0.00281203, -0.00170689,\n",
              "         -0.00708347,  0.01205407, -0.00777831,  0.00624696, -0.02288503],\n",
              "        [-0.00149257,  0.00722474, -0.00432845, -0.00422313,  0.00149685,\n",
              "          0.01332669, -0.01106197,  0.01702713, -0.00146649,  0.01407418,\n",
              "          0.00325847, -0.00974375,  0.00728861,  0.00590938,  0.0026375 ],\n",
              "        [-0.00743107, -0.03831475,  0.04777892,  0.00437067, -0.01116919,\n",
              "          0.00029345,  0.02199736, -0.0153537 ,  0.0368697 ,  0.00520021,\n",
              "          0.00727075,  0.00527481, -0.00510902, -0.00458018, -0.00125494],\n",
              "        [-0.0117249 ,  0.00587079,  0.00085116,  0.00024304,  0.00692335,\n",
              "          0.0091677 , -0.01278995,  0.00121087,  0.00749782, -0.00984275,\n",
              "         -0.00218209, -0.00109338, -0.00255411, -0.00743812,  0.        ],\n",
              "        [-0.01512752,  0.        ,  0.02938422,  0.00467109, -0.00271212,\n",
              "          0.00802894,  0.00899286, -0.00267379,  0.01136218,  0.00252458,\n",
              "         -0.00528832,  0.00721519, -0.01533243,  0.01467775,  0.01710693],\n",
              "        [-0.00368418,  0.02181689,  0.00579006, -0.01942906,  0.00562621,\n",
              "         -0.02104115, -0.00646039,  0.00387642, -0.02005482, -0.0175416 ,\n",
              "          0.0023289 , -0.00438885, -0.00531565,  0.00156407, -0.00091098],\n",
              "        [ 0.        ,  0.00593625,  0.00912018, -0.00943646, -0.0124782 ,\n",
              "          0.0111413 ,  0.00940614, -0.01291269, -0.00215784,  0.01419115,\n",
              "         -0.0205224 , -0.00829933,  0.01522843, -0.0040541 , -0.01207598],\n",
              "        [ 0.0099529 ,  0.0086563 , -0.00554526,  0.01712694,  0.0140974 ,\n",
              "         -0.00952511, -0.00883691,  0.00432676, -0.01018275,  0.01068316,\n",
              "         -0.00091348, -0.01097174,  0.00950873, -0.00405554,  0.00459748],\n",
              "        [-0.0058931 , -0.00013176,  0.00461131, -0.00904921, -0.02342505,\n",
              "          0.00420108, -0.02010793, -0.00619745, -0.00263307, -0.01667368,\n",
              "          0.01568462,  0.02378964, -0.00828907,  0.01822409,  0.00363349],\n",
              "        [ 0.00766528, -0.02668901,  0.01973779,  0.00090932,  0.01816994,\n",
              "          0.00777566,  0.00556542,  0.02163524, -0.02203892, -0.0130933 ,\n",
              "         -0.00956755, -0.01416794,  0.0018291 , -0.00860725,  0.01262834],\n",
              "        [-0.02780553,  0.00888939, -0.0099604 , -0.0061911 ,  0.0224529 ,\n",
              "          0.01142424,  0.01242467,  0.0158671 , -0.00378276,  0.0042871 ,\n",
              "          0.01268449, -0.01589786, -0.01028021, -0.01286016, -0.02292374],\n",
              "        [-0.00904112,  0.00771008,  0.00102017,  0.00203826,  0.01029745,\n",
              "         -0.00553671,  0.01227384,  0.00387497, -0.00149415, -0.01134809,\n",
              "          0.01109996, -0.01434633,  0.00974556,  0.0027576 ,  0.00887499],\n",
              "        [-0.00820693,  0.0014025 ,  0.00448179, -0.00669274,  0.00379007,\n",
              "          0.01090755,  0.01369481,  0.03602619, -0.01448892,  0.01029132,\n",
              "         -0.00436558, -0.00770664, -0.00937329,  0.00162199,  0.0175439 ],\n",
              "        [-0.00281375, -0.01374068, -0.00597084,  0.003629  , -0.00024933,\n",
              "          0.01359437, -0.00664444, -0.0050787 , -0.0112052 , -0.01082851,\n",
              "         -0.00318228, -0.01749451,  0.01377694,  0.00333336,  0.0070278 ]]),\n",
              " array([[ 0.00369462,  0.00429446,  0.00146613, -0.01000366, -0.01614301],\n",
              "        [-0.01943438, -0.00368442,  0.03927572, -0.00319021,  0.00726248],\n",
              "        [ 0.01195743,  0.0022451 ,  0.00412637,  0.01678995, -0.00115472],\n",
              "        [ 0.00055844, -0.00041857,  0.00683972,  0.01192293, -0.01507054],\n",
              "        [ 0.01977888,  0.00698704,  0.00777607, -0.02754036, -0.00219727],\n",
              "        [-0.03796685, -0.00051422, -0.01028943, -0.00194924, -0.00338544],\n",
              "        [-0.00273543, -0.01110238,  0.00132081,  0.00738696, -0.00013097],\n",
              "        [ 0.02472192, -0.0186302 ,  0.02458338, -0.00199939,  0.01535988],\n",
              "        [-0.00065381,  0.0141306 ,  0.00077406,  0.00077346, -0.00708483],\n",
              "        [ 0.0044248 , -0.00093455, -0.01082306,  0.00878024, -0.00441888],\n",
              "        [-0.01818656, -0.02037577, -0.02755269, -0.01694446, -0.03037583],\n",
              "        [-0.00782052,  0.01033729,  0.00984776,  0.00329283, -0.02840192],\n",
              "        [-0.00334527, -0.00360518,  0.01160325, -0.00259002,  0.00556445],\n",
              "        [ 0.01127319,  0.00026225,  0.01888033,  0.0066916 ,  0.00383479],\n",
              "        [ 0.00025383,  0.01433461, -0.01100547,  0.00682854,  0.00979652]]),\n",
              " array([[-0.0105096 , -0.00358158,  0.01710458,  0.00999268,  0.00868727,\n",
              "         -0.00598086, -0.00818292, -0.01104096,  0.00466197, -0.0150201 ,\n",
              "          0.00198359, -0.00148481, -0.00309789, -0.00944679,  0.02120711],\n",
              "        [ 0.00577965, -0.0160166 , -0.00695831,  0.01301302, -0.00765814,\n",
              "          0.00497886,  0.00074319,  0.0115099 , -0.00428247, -0.0058982 ,\n",
              "          0.0142151 ,  0.00536252,  0.00618259, -0.01289156, -0.00451608]]),\n",
              " array([[-0.02015236,  0.0112867 ,  0.01326885,  0.00318201,  0.00927171],\n",
              "        [ 0.00478175, -0.01256862, -0.00333659,  0.00681953,  0.00283255]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cennoUsA4jdI",
        "colab_type": "text"
      },
      "source": [
        "<h3> Creating RNN Model </h3>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVMHd20H36gP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# create the inference model\n",
        "def simple_rnn(features, labels, mode, params):\n",
        "  # 0. Reformat input shape to become a sequence\n",
        "  print ('IN Features are:{0}'.format(features))\n",
        "  x = tf.split(features[TIMESERIES_COL], N_INPUTS, 1)\n",
        "  #print 'x={}'.format(x)\n",
        "    \n",
        "  # 1. configure the RNN\n",
        "  lstm_cell = rnn.BasicLSTMCell(LSTM_SIZE, forget_bias=1.0)\n",
        "  outputs, _ = tf.nn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
        "\n",
        "  # slice to keep only the last cell of the RNN\n",
        "  outputs = outputs[-1]\n",
        "  #print 'last outputs={}'.format(outputs)\n",
        "  \n",
        "  # output is result of linear activation of last layer of RNN\n",
        "  weight = tf.Variable(tf.random_normal([LSTM_SIZE, N_OUTPUTS]))\n",
        "  bias = tf.Variable(tf.random_normal([N_OUTPUTS]))\n",
        "  predictions = tf.matmul(outputs, weight) + bias\n",
        "    \n",
        "  # 2. loss function, training/eval ops\n",
        "  if mode == ModeKeys.TRAIN or mode == ModeKeys.EVAL:\n",
        "     loss = tf.losses.mean_squared_error(labels, predictions)\n",
        "     train_op = tf.contrib.layers.optimize_loss(\n",
        "         loss=loss,\n",
        "         global_step=tf.train.get_global_step(),\n",
        "         learning_rate=0.01,\n",
        "         optimizer=\"SGD\") # SGD\n",
        "     eval_metric_ops = {\n",
        "      \"rmse\": tf.metrics.root_mean_squared_error(labels, predictions)\n",
        "     }\n",
        "  else:\n",
        "     loss = None\n",
        "     train_op = None\n",
        "     eval_metric_ops = None\n",
        "  \n",
        "  # 3. Create predictions\n",
        "  predictions_dict = {\"predicted\": predictions}\n",
        "\n",
        "  # 4. Create export outputs  \n",
        "  export_outputs = {\"predicted\": tf.estimator.export.PredictOutput(predictions)}\n",
        "\n",
        "  # 5. return ModelFnOps\n",
        "  return tf.estimator.EstimatorSpec(\n",
        "      mode=mode,\n",
        "      predictions=predictions_dict,\n",
        "      loss=loss,\n",
        "      train_op=train_op,\n",
        "      eval_metric_ops=eval_metric_ops,\n",
        "      export_outputs=export_outputs)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6x2OM2cG4qpj",
        "colab_type": "text"
      },
      "source": [
        "<h3> Creating Serving Function , Train Function and Test Function </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ka_U5ZvZ4W6W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def serving_input_receiver_fn():\n",
        "  feature_placeholders = {\n",
        "    TIMESERIES_COL: tf.placeholder(tf.float32, [None, N_INPUTS])\n",
        "  }\n",
        "\n",
        "  features = {\n",
        "    key: tf.expand_dims(tensor, -1)\n",
        "    for key, tensor in feature_placeholders.items()\n",
        "  }\n",
        "\n",
        "  features[TIMESERIES_COL] = tf.squeeze(features[TIMESERIES_COL], axis=[2], name='timeseries')\n",
        "  \n",
        "  print('serving: features={}'.format(features[TIMESERIES_COL]))\n",
        "\n",
        "  return tf.estimator.export.ServingInputReceiver(features, feature_placeholders)\n",
        "\n",
        "\n",
        "\n",
        "# Creating a TrainFn and a TestFn\n",
        "def _train_fn(X, y, batch_size):\n",
        "    \n",
        "    def _train():\n",
        "        \"\"\"An input function for training\"\"\"\n",
        "        # Convert the inputs to a Dataset.\n",
        "        # TODO need to be refactored according to https://medium.com/google-cloud/how-to-do-time-series-prediction-using-rnns-and-tensorflow-and-cloud-ml-engine-2ad2eeb189e8\n",
        "        # this is not good.\n",
        "        X_32 = tf.cast(X, tf.float32)\n",
        "        y_32 = tf.cast(y, tf.float32)\n",
        "        inputs = tf.concat(X_32, axis=1)\n",
        "        label = tf.concat(y_32, axis=1)\n",
        "        features, labels = {TIMESERIES_COL: inputs}, label\n",
        "        \n",
        "        return features, labels\n",
        "        dataset = tf.data.Dataset.from_tensor_slices(features, labels)\n",
        "        # Shuffle, repeat, and batch the examples.\n",
        "        dataset = dataset.repeat(None).batch(batch_size)\n",
        "        # This will now return batches of features, label\n",
        "        return dataset.make_one_shot_iterator().get_next()\n",
        "    return _train\n",
        "\n",
        "def _test_fn(X, y, batch_size):\n",
        "    def _test():\n",
        "        \"\"\"An input function for training\"\"\"\n",
        "        # Convert the inputs to a Dataset.\n",
        "        X_32 = tf.cast(X, tf.float32)\n",
        "        y_32 = tf.cast(y, tf.float32)\n",
        "        inputs = tf.concat(X_32, axis=1)\n",
        "        label = tf.concat(y_32, axis=1)\n",
        "        \n",
        "        features, labels = {TIMESERIES_COL: inputs}, label\n",
        "        \n",
        "        return features, labels\n",
        "        \n",
        "        dataset = tf.data.Dataset.from_tensor_slices(features, labels)\n",
        "        # Shuffle, repeat, and batch the examples.\n",
        "        dataset = dataset.repeat(1).batch(batch_size)\n",
        "        # This will now return batches of features, label\n",
        "        return dataset.make_one_shot_iterator().get_next()\n",
        "    return _test  \n",
        "  \n",
        "\n",
        " \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovYAxd_W4zc7",
        "colab_type": "text"
      },
      "source": [
        "<h3> Creating Experiment Function and running model </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CByxDadW49FB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _predict_fn(X) :\n",
        "    def _predict():\n",
        "        \"\"\"An input function for training\"\"\"\n",
        "        # Convert the inputs to a Dataset.\n",
        "        X_32 = tf.cast(X, tf.float32)\n",
        "        inputs = tf.concat(X_32, axis=1)\n",
        "        features = {TIMESERIES_COL: inputs}\n",
        "        return features\n",
        "    return _predict\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def experiment_fn(output_dir, X, y, x_tst, y_tst):\n",
        "    # run experiment\n",
        "    train_spec = tf.estimator.TrainSpec(\n",
        "          input_fn=_train_fn(X, y, BATCH_SIZE), max_steps=1500)\n",
        "    exporter = tf.estimator.FinalExporter('timeseries',\n",
        "    serving_input_receiver_fn)\n",
        "    eval_spec = tf.estimator.EvalSpec(\n",
        "            input_fn=_test_fn(x_tst, y_tst, BATCH_SIZE),\n",
        "            exporters=[exporter])\n",
        "    \n",
        "    estimator = tf.estimator.Estimator(model_fn=simple_rnn, model_dir=output_dir)\n",
        "\n",
        "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n",
        "    return estimator\n",
        "\n",
        "\n",
        "def run_model(end_date, symbol='XOM', extra_prices=None):  \n",
        "  print('Attempting to generate learning model for {}, using end_date={}'.format(symbol, end_date))\n",
        "  tf.logging.set_verbosity(tf.logging.ERROR)    \n",
        "  output_dir = ROOT_DIR.format(datetime.utcnow().strftime('%Y%m%d%H%M%S'))  \n",
        "  X_train, y_train, X_test, y_test = create_train_and_test(end_date, symbol=symbol, extra_prices=extra_prices)\n",
        "  estimator = experiment_fn(output_dir, X_train, y_train, X_test, y_test)\n",
        "  print('Xtrain is:{} and of shape:{}', type(X_train), X_train.shape)\n",
        "  return estimator\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMzyPr_u4_At",
        "colab_type": "text"
      },
      "source": [
        "<h3> SETTING STARTDATE, ENDDATE AND TICKER </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3zgbsMrCbgP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "END_DATE= date.today()\n",
        "START_DATE = END_DATE - BDay(N_INPUTS) # This will be used for predicting future prices. end date will be 15 days ago, start_date 280 days earlier\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "augTdn3oqsK8",
        "colab_type": "text"
      },
      "source": [
        "<h3> Now running model </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEMTgvKICpoc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_estimator(symbol, extra_prices=None):\n",
        "  print('===================== CONFIGURATION FOR {}======================'.format(symbol))\n",
        "  print('STARTDATE={}'.format(START_DATE))\n",
        "  print('ENDDATE={}'.format(END_DATE))\n",
        "  print('SYMBOL={}'.format(symbol))\n",
        "  print('=== TRAINING MODEL ON PAST 280 DAYS from {}'.format(START_DATE))\n",
        "  estimator = run_model(START_DATE, symbol=symbol, extra_prices=extra_prices)\n",
        "  return estimator\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zITl_XzA17jz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bSKL1hdpyVD",
        "colab_type": "text"
      },
      "source": [
        "<h3> Now, after training,  Let's do some predictions for future </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQkN-vTbp6E9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from datetime import date\n",
        "from pprint import pprint\n",
        "# going back to last month\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)    \n",
        "\n",
        "def get_last_20_days(symbol):\n",
        "\n",
        "  def get_prices2(startdate=None, enddate=None, symbol=''):\n",
        "    import pandas_datareader as pdr\n",
        "    from datetime import date, timedelta\n",
        "    print ('--Start:{%s}, end:{%s}', startdate, enddate)\n",
        "\n",
        "    if not startdate and not enddate:\n",
        "      last_check = date.today() - BDay(SEQ_LEN * 2) \n",
        "      enddate = last_check\n",
        "      startdate = last_check - BDay(122)#timedelta(days=120)\n",
        "    return pdr.get_data_yahoo(symbol, startdate, enddate)[['Close']]\n",
        "\n",
        "\n",
        "  print('==== GETTING MOST RECENT PRICES======')\n",
        "  stock_data = get_prices2(START_DATE- BDay(1), END_DATE, symbol=symbol)\n",
        "  percentage_changes = stock_data.pct_change().fillna(0)\n",
        "  #First Price\n",
        "  first_price = stock_data.values[0]\n",
        "  print('==============First ever price of the series of shape {} is {}'.format(stock_data.shape, first_price ))\n",
        "  #print(stock_data.head(30))\n",
        "  #print('=========== PERCENTAGE CHANGES ===========')\n",
        "  #print(percentage_changes.head(30))\n",
        "  prices = np.stack(percentage_changes['Close'])\n",
        "  #prices = np.stack(stock_data['Close'])\n",
        "  print('===== PRICES ARE===')\n",
        "  pprint(prices)\n",
        "  return prices, first_price\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQiIzVoFEa6u",
        "colab_type": "text"
      },
      "source": [
        "<h3> Now recalculating price percentages to predict </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzaOht5kERuR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_predictions(prices, estimator, iterations=8):\n",
        "\n",
        "  print ('Prices is of shape:{}', prices.shape)\n",
        "  prices = prices.reshape(-1,N_INPUTS) if prices.shape[0] % 15 == 0 else prices[-15:].reshape(-1,N_INPUTS)\n",
        "  print ('Reshaped Prices is of shape:{}', prices.shape) \n",
        "  print ('-------- PREDICTING -------')\n",
        "  print (type(prices))\n",
        "  acc = []\n",
        "  acc += prices[0].tolist()\n",
        "  for i in range(0, iterations):\n",
        "    print('Iteration:{}.Accumulator length:{}'.format(i, len(acc)))\n",
        "    # Given last 15 days, predict the next 5. now we  have all data\n",
        "    candidate = np.array(acc[-15:]).reshape(-1,15)  # this is the Train #\n",
        "    \n",
        "    pred = estimator.predict(input_fn = _predict_fn(candidate))\n",
        "    item = next(pred)\n",
        "    vals = item['predicted'] # this is the predicted\n",
        "    \n",
        "    # First iteration has last 15 prices, then we predict the next 5. Now accumulator has 20\n",
        "    # Second iteration,\n",
        "    \"\"\"\n",
        "    Iteration:0.Accumulator length:15, then we predict 5/ so now we have test_data + 20. \n",
        "    Training is done in batches of 20. So we can only retrain when we have at least 15 available to send to the estimator\n",
        "    That means that we can only do it when we have 35. So we can only retrain periodically when we have enough samples. \n",
        "    That means when len(acc) % 35 == 0. so we can take the first 20 to train, and use the next 15 to predict\n",
        "    Iteration:1.Accumulator length:20\n",
        "    Iteration:2.Accumulator length:25\n",
        "    \"\"\"\n",
        "    # So we can only retrain when we have \n",
        "    \n",
        "    # at Iteation 2, we take the last 15. But w\n",
        "    # Next 5 predicted. So now we have 15 -test- + 5 predicted. \n",
        "    # Then, as test data, pick the previous 15 and then predict the next one\n",
        "\n",
        "    \"\"\"\n",
        "    ATTEMPT TO RETRAIN THE MODEL..\n",
        "      print(\"====== Now adding prediction to current train....\")\n",
        "      print(\"Xtrain of type:{}, candidate of type:{}\".format(type(X_train), type(candidate)))\n",
        "      print(\"SHapes.Train:{}, Candidate:{}\".format(X_train.shape, candidate.shape))\n",
        "      \n",
        "      # train again\n",
        "      # need to think this.\n",
        "      #estimator = train_estimator(symbol, acc[-15:] )\n",
        "    \n",
        "      \n",
        "      #X_train = np.vstack([X_train , candidate])\n",
        "      #y_train = np.vstack([y_train , vals])\n",
        "      # So Now we have to \n",
        "      # 1. retrain the model\n",
        "      # 2. get the most recent 15 days to \n",
        "\n",
        "    \"\"\"\n",
        "    print ('Round {} Prediction: on {}={}'.format(i, candidate, vals))\n",
        "    print ('{}={}'.format(type(vals), vals.tolist()))\n",
        "    acc += vals.tolist()\n",
        "  return acc\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zxm7H9jzsEGL",
        "colab_type": "text"
      },
      "source": [
        "<h3> Now visualizing price predictions against date time </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8SxyWVIxS3L",
        "colab_type": "code",
        "outputId": "a2d9efbd-ed4d-4db5-c279-eda48f4565aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def calculate_list_of_prices(idx, first_price, zipped, accumulator):\n",
        "  if idx ==0:\n",
        "    ts = zipped[idx][1]\n",
        "    change = zipped[idx][0]\n",
        "    price = first_price * (1 + change)\n",
        "    accumulator.append((ts, change, price))\n",
        "    return calculate_list_of_prices(idx + 1, first_price, zipped, accumulator)\n",
        "  elif idx < len(zipped):\n",
        "    ts = zipped[idx][1]\n",
        "    _, _, last_price = accumulator[-1]\n",
        "    change =zipped[idx][0]\n",
        "    accumulator.append((ts, change,last_price * (1 + change))) \n",
        "    return calculate_list_of_prices(idx + 1, first_price, zipped, accumulator)\n",
        "  else:\n",
        "    return accumulator\n",
        "  \n",
        "\n",
        "def generate_results(acc, first_price):\n",
        "  print('-------------- END OF STORY.Computing increase from {}'.format(first_price))\n",
        "  from pprint import pprint\n",
        "  future_days = len(acc) - 15\n",
        "  pprint('Accumlator has length:{}'.format(len(acc)))\n",
        "  pprint('We have prediction for the next:{} days'.format(future_days))\n",
        "  print(\"calculating business days to zip \")\n",
        "  # we got start date, todays - 15\n",
        "  # end date is  today + \n",
        "  dts = [START_DATE + BDay(offset) for offset in range(0, len(acc))]\n",
        "  print('Start Date:{}={}'.format(dts[0], START_DATE))\n",
        "  print('End date:{}'.format(dts[-1]))\n",
        "  zipped = [tpl for tpl in zip(acc, dts)]\n",
        "       \n",
        "  print('===== FULL PREDICTIONS======')\n",
        "  #print(zipped)\n",
        "  from functools import reduce\n",
        "  final_predictions  = acc\n",
        "  #pprint(final_predictions)\n",
        "  # Then find the end price by using reduce and entering the first price \n",
        "  res = reduce(lambda acc,x: acc * (1+x) ,  final_predictions, first_price)\n",
        "  print('Final Price for series{} = {}'.format(zipped[-1], res))\n",
        "  \n",
        "  final_prices = calculate_list_of_prices(0, first_price, zipped, [])\n",
        "  print('Final list of prices...')\n",
        "  pprint(final_prices)\n",
        "  return res, final_prices[-3:]\n",
        "\n",
        "ALL_SYMBOLS = ['AMZN',\n",
        "               'AAPL',\n",
        "               'BRK-B',\n",
        "               'CRLBF',\n",
        "               'RUSL',\n",
        "               'XOM',\n",
        "               'JNJ',\n",
        "               'NFLX',\n",
        "               'REMX',\n",
        "               'VZ']\n",
        "\n",
        "results = []\n",
        "for symbol in ALL_SYMBOLS[0:1]:\n",
        "  print('Running predictions for:{}'.format(symbol))\n",
        "  \n",
        "  estimator = train_estimator(symbol)\n",
        "  latest_prices, first_price = get_last_20_days(symbol)\n",
        "  # Reshaping dat3\n",
        "  acc = make_predictions(latest_prices, estimator, iterations=3)\n",
        "  res, final_prices = generate_results(acc, first_price)\n",
        "  #pprint(final_prices)\n",
        "\n",
        "  results.append((symbol, res[0]))\n",
        "from pprint import pprint\n",
        "pprint(results)\n",
        "\n"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running predictions for:AMZN\n",
            "===================== CONFIGURATION FOR AMZN======================\n",
            "STARTDATE=2019-07-04 00:00:00\n",
            "ENDDATE=2019-07-25\n",
            "SYMBOL=AMZN\n",
            "=== TRAINING MODEL ON PAST 280 DAYS from 2019-07-04 00:00:00\n",
            "Attempting to generate learning model for AMZN, using end_date=2019-07-04 00:00:00\n",
            "==== CREATING TIMESERIES GOING BACK 280 DAYS FROM  2019-07-04 00:00:00\n",
            "--Start:{%s}, end:{%s} 2018-02-15 00:00:00 2019-07-04 00:00:00\n",
            "Len of input dat ais {} 347\n",
            "Timeseries is of type:<class 'list'> and has length:17\n",
            "All data shape is(17, 20) and type <class 'numpy.ndarray'>\n",
            "X is fo type <class 'numpy.float64'>, y  of type <class 'numpy.ndarray'>\n",
            "X.shape is (17, 15), y shap is (17, 5)\n",
            "IN Features are:{'rawdata': <tf.Tensor 'concat:0' shape=(15, 15) dtype=float32>}\n",
            "IN Features are:{'rawdata': <tf.Tensor 'concat:0' shape=(2, 15) dtype=float32>}\n",
            "serving: features=Tensor(\"timeseries:0\", shape=(?, 15), dtype=float32)\n",
            "IN Features are:{'rawdata': <tf.Tensor 'timeseries:0' shape=(?, 15) dtype=float32>}\n",
            "Xtrain is:{} and of shape:{} <class 'numpy.ndarray'> (15, 15)\n",
            "==== GETTING MOST RECENT PRICES======\n",
            "--Start:{%s}, end:{%s} 2019-07-03 00:00:00 2019-07-25\n",
            "==============First ever price of the series of shape (16, 1) is [1939.]\n",
            "===== PRICES ARE===\n",
            "array([ 0.        ,  0.00201652,  0.00484321,  0.01842941,  0.01464064,\n",
            "       -0.00809954,  0.00496237,  0.00496767, -0.00548739, -0.00889099,\n",
            "       -0.00709327, -0.00676475,  0.01074562,  0.00446205,  0.00316876,\n",
            "       -0.01348959])\n",
            "Prices is of shape:{} (16,)\n",
            "Reshaped Prices is of shape:{} (1, 15)\n",
            "-------- PREDICTING -------\n",
            "<class 'numpy.ndarray'>\n",
            "Iteration:0.Accumulator length:15\n",
            "IN Features are:{'rawdata': <tf.Tensor 'concat:0' shape=(1, 15) dtype=float32>}\n",
            "Round 0 Prediction: on [[ 0.00201652  0.00484321  0.01842941  0.01464064 -0.00809954  0.00496237\n",
            "   0.00496767 -0.00548739 -0.00889099 -0.00709327 -0.00676475  0.01074562\n",
            "   0.00446205  0.00316876 -0.01348959]]=[ 0.01194558  0.00891462 -0.0054983   0.0033727   0.00637767]\n",
            "<class 'numpy.ndarray'>=[0.011945575475692749, 0.00891461968421936, -0.0054983049631118774, 0.003372699022293091, 0.006377667188644409]\n",
            "Iteration:1.Accumulator length:20\n",
            "IN Features are:{'rawdata': <tf.Tensor 'concat:0' shape=(1, 15) dtype=float32>}\n",
            "Round 1 Prediction: on [[ 0.00496237  0.00496767 -0.00548739 -0.00889099 -0.00709327 -0.00676475\n",
            "   0.01074562  0.00446205  0.00316876 -0.01348959  0.01194558  0.00891462\n",
            "  -0.0054983   0.0033727   0.00637767]]=[ 0.0128454   0.00612843 -0.00664094  0.00436965  0.00688678]\n",
            "<class 'numpy.ndarray'>=[0.012845396995544434, 0.006128430366516113, -0.00664094090461731, 0.004369646310806274, 0.006886780261993408]\n",
            "Iteration:2.Accumulator length:25\n",
            "IN Features are:{'rawdata': <tf.Tensor 'concat:0' shape=(1, 15) dtype=float32>}\n",
            "Round 2 Prediction: on [[-0.00676475  0.01074562  0.00446205  0.00316876 -0.01348959  0.01194558\n",
            "   0.00891462 -0.0054983   0.0033727   0.00637767  0.0128454   0.00612843\n",
            "  -0.00664094  0.00436965  0.00688678]]=[ 0.01546332  0.00425074 -0.00623895  0.00430577  0.00753224]\n",
            "<class 'numpy.ndarray'>=[0.015463322401046753, 0.00425073504447937, -0.006238952279090881, 0.0043057650327682495, 0.007532238960266113]\n",
            "-------------- END OF STORY.Computing increase from [1939.]\n",
            "'Accumlator has length:30'\n",
            "'We have prediction for the next:15 days'\n",
            "calculating business days to zip \n",
            "Start Date:2019-07-04 00:00:00=2019-07-04 00:00:00\n",
            "End date:2019-08-14 00:00:00\n",
            "===== FULL PREDICTIONS======\n",
            "Final Price for series(0.007532238960266113, Timestamp('2019-08-14 00:00:00')) = [2124.40949852]\n",
            "Final list of prices...\n",
            "[(Timestamp('2019-07-04 00:00:00'),\n",
            "  0.002016520979725378,\n",
            "  array([1942.91003418])),\n",
            " (Timestamp('2019-07-05 00:00:00'),\n",
            "  0.004843205266242823,\n",
            "  array([1952.31994629])),\n",
            " (Timestamp('2019-07-08 00:00:00'),\n",
            "  0.01842940887196942,\n",
            "  array([1988.30004883])),\n",
            " (Timestamp('2019-07-09 00:00:00'),\n",
            "  0.014640640062710597,\n",
            "  array([2017.41003418])),\n",
            " (Timestamp('2019-07-10 00:00:00'),\n",
            "  -0.008099537334396723,\n",
            "  array([2001.06994629])),\n",
            " (Timestamp('2019-07-11 00:00:00'), 0.00496237211965167, array([2011.])),\n",
            " (Timestamp('2019-07-12 00:00:00'),\n",
            "  0.0049676729161487465,\n",
            "  array([2020.98999023])),\n",
            " (Timestamp('2019-07-15 00:00:00'),\n",
            "  -0.005487392750038511,\n",
            "  array([2009.90002441])),\n",
            " (Timestamp('2019-07-16 00:00:00'),\n",
            "  -0.00889098706409397,\n",
            "  array([1992.0300293])),\n",
            " (Timestamp('2019-07-17 00:00:00'),\n",
            "  -0.007093269014523784,\n",
            "  array([1977.90002441])),\n",
            " (Timestamp('2019-07-18 00:00:00'),\n",
            "  -0.006764752878132052,\n",
            "  array([1964.52001953])),\n",
            " (Timestamp('2019-07-19 00:00:00'),\n",
            "  0.01074561986728928,\n",
            "  array([1985.63000488])),\n",
            " (Timestamp('2019-07-22 00:00:00'),\n",
            "  0.004462052512187675,\n",
            "  array([1994.48999023])),\n",
            " (Timestamp('2019-07-23 00:00:00'),\n",
            "  0.003168764140366598,\n",
            "  array([2000.81005859])),\n",
            " (Timestamp('2019-07-24 00:00:00'),\n",
            "  -0.013489592472189615,\n",
            "  array([1973.81994629])),\n",
            " (Timestamp('2019-07-25 00:00:00'),\n",
            "  0.011945575475692749,\n",
            "  array([1997.39836143])),\n",
            " (Timestamp('2019-07-26 00:00:00'),\n",
            "  0.00891461968421936,\n",
            "  array([2015.20440818])),\n",
            " (Timestamp('2019-07-29 00:00:00'),\n",
            "  -0.0054983049631118774,\n",
            "  array([2004.12419978])),\n",
            " (Timestamp('2019-07-30 00:00:00'),\n",
            "  0.003372699022293091,\n",
            "  array([2010.88350751])),\n",
            " (Timestamp('2019-07-31 00:00:00'),\n",
            "  0.006377667188644409,\n",
            "  array([2023.70825328])),\n",
            " (Timestamp('2019-08-01 00:00:00'),\n",
            "  0.012845396995544434,\n",
            "  array([2049.7035892])),\n",
            " (Timestamp('2019-08-02 00:00:00'),\n",
            "  0.006128430366516113,\n",
            "  array([2062.26505491])),\n",
            " (Timestamp('2019-08-05 00:00:00'),\n",
            "  -0.00664094090461731,\n",
            "  array([2048.56967455])),\n",
            " (Timestamp('2019-08-06 00:00:00'),\n",
            "  0.004369646310806274,\n",
            "  array([2057.52119948])),\n",
            " (Timestamp('2019-08-07 00:00:00'),\n",
            "  0.006886780261993408,\n",
            "  array([2071.69089586])),\n",
            " (Timestamp('2019-08-08 00:00:00'),\n",
            "  0.015463322401046753,\n",
            "  array([2103.7261201])),\n",
            " (Timestamp('2019-08-09 00:00:00'),\n",
            "  0.00425073504447937,\n",
            "  array([2112.66850244])),\n",
            " (Timestamp('2019-08-12 00:00:00'),\n",
            "  -0.006238952279090881,\n",
            "  array([2099.48766447])),\n",
            " (Timestamp('2019-08-13 00:00:00'),\n",
            "  0.0043057650327682495,\n",
            "  array([2108.52756505])),\n",
            " (Timestamp('2019-08-14 00:00:00'),\n",
            "  0.007532238960266113,\n",
            "  array([2124.40949852]))]\n",
            "[('AMZN', 2124.409498519631)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8vLDVntz3vj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "c4aff729-ac4b-463c-8961-93eaa1d78136"
      },
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame(results, columns=['Symbol', 'MidSeptember Price'])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Symbol</th>\n",
              "      <th>MidSeptember Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AMZN</td>\n",
              "      <td>2334.121761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>258.048772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BRK-B</td>\n",
              "      <td>250.997862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CRLBF</td>\n",
              "      <td>28902.071668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RUSL</td>\n",
              "      <td>58.158867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>XOM</td>\n",
              "      <td>80.919655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>JNJ</td>\n",
              "      <td>153.772188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>NFLX</td>\n",
              "      <td>449.623933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>REMX</td>\n",
              "      <td>15.639161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>VZ</td>\n",
              "      <td>57.572321</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Symbol  MidSeptember Price\n",
              "0   AMZN         2334.121761\n",
              "1   AAPL          258.048772\n",
              "2  BRK-B          250.997862\n",
              "3  CRLBF        28902.071668\n",
              "4   RUSL           58.158867\n",
              "5    XOM           80.919655\n",
              "6    JNJ          153.772188\n",
              "7   NFLX          449.623933\n",
              "8   REMX           15.639161\n",
              "9     VZ           57.572321"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZsJNAp03yFc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "66f5d464-4ca7-47e7-cca0-e31271a8c383"
      },
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame(results, columns=['Symbol', 'MidNovember Price'])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Symbol</th>\n",
              "      <th>MidNovember Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AMZN</td>\n",
              "      <td>3.182895e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>3.309744e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BRK-B</td>\n",
              "      <td>2.865549e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CRLBF</td>\n",
              "      <td>2.931857e+11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RUSL</td>\n",
              "      <td>6.184396e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>XOM</td>\n",
              "      <td>1.214751e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>JNJ</td>\n",
              "      <td>1.822704e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>NFLX</td>\n",
              "      <td>6.197354e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>REMX</td>\n",
              "      <td>1.466988e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>VZ</td>\n",
              "      <td>5.750468e+01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Symbol  MidNovember Price\n",
              "0   AMZN       3.182895e+03\n",
              "1   AAPL       3.309744e+02\n",
              "2  BRK-B       2.865549e+02\n",
              "3  CRLBF       2.931857e+11\n",
              "4   RUSL       6.184396e+01\n",
              "5    XOM       1.214751e+02\n",
              "6    JNJ       1.822704e+02\n",
              "7   NFLX       6.197354e+02\n",
              "8   REMX       1.466988e+01\n",
              "9     VZ       5.750468e+01"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2ouepeT_28w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7AjEH52vS-6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}