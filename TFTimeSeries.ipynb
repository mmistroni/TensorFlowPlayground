{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFTimeSeries.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmistroni/TensorFlowPlayground/blob/master/TFTimeSeries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "7j1C2K-pSCvo",
        "colab_type": "code",
        "outputId": "71f497d2-a49a-4b78-8354-c87f8a31d670",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "cell_type": "code",
      "source": [
        "stock_data.shape[0]\n",
        "print (type(stock_data))\n",
        "adjClose = np.stack(stock_data['Close'])\n",
        "\n",
        "# Since we always want to predict the future, we take the latest 10% of data as the test data.\n",
        "# Split into train / test so that you can use the test to find accuracy.\n",
        "# Train is used to train, and test to predict, to see the accuracy, Then we can use last price today to predict tomorrow, and so on\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title(\"A training instance\", fontsize=14)\n",
        "plt.plot(adjClose)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fc769f92550>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEJCAYAAACaFuz/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fc749237da0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "03Y2LC7ZQtOu",
        "colab_type": "code",
        "outputId": "91653b48-fc9a-41f7-cbe9-f5ef2631e697",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "!pip install pandas_datareader\n",
        "\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas_datareader in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
            "Requirement already satisfied: pandas>=0.19.2 in /usr/local/lib/python3.6/dist-packages (from pandas_datareader) (0.22.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from pandas_datareader) (4.2.5)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from pandas_datareader) (2.18.4)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from pandas_datareader) (1.10.11)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->pandas_datareader) (2018.7)\n",
            "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->pandas_datareader) (2.5.3)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->pandas_datareader) (1.14.6)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas_datareader) (2.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas_datareader) (2018.10.15)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas_datareader) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas_datareader) (1.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2->pandas>=0.19.2->pandas_datareader) (1.11.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "l-Irklu5ENWm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6a6e9192-de6f-444d-b638-f308fffe77dc"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.contrib.learn import ModeKeys\n",
        "import tensorflow.contrib.rnn as rnn\n",
        "from datetime import datetime\n",
        "\n",
        "#tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "#TIMESERIES_COL = '9'\n",
        "TIMESERIES_COL = 'rawdata'\n",
        "N_OUTPUTS = 6  # in each sequence, 1-14 are features, and 14-20 is label \n",
        "SEQ_LEN = 20\n",
        "DEFAULTS = 0.0\n",
        "N_INPUTS = SEQ_LEN - N_OUTPUTS\n",
        "BATCH_SIZE = 20\n",
        "ROOT_DIR = '/home/mmistroni/tf_logs/rnn-run-{}'\n",
        "\n",
        "\n",
        "def get_prices():\n",
        "  import pandas_datareader as pdr\n",
        "  from datetime import date, timedelta\n",
        "  startdate = date.today() - timedelta(days=100)\n",
        "  stock_data = pdr.get_data_yahoo('XOM', startdate, date.today())[-SEQ_LEN:]\n",
        "  adjClose = np.stack(stock_data['Close'])\n",
        "  return adjClose.T\n",
        "  \n",
        "\n",
        "def create_time_series():\n",
        "  return get_prices()\n",
        "  freq = (np.random.random()*0.5) + 0.1  # 0.1 to 0.6\n",
        "  ampl = np.random.random() + 0.5  # 0.5 to 1.5\n",
        "  x = np.sin(np.arange(0,SEQ_LEN) * freq) * ampl\n",
        "  return x\n",
        "\n",
        "prices  = get_prices()\n",
        "print('type of prices:{}', type(prices))\n",
        "print('lenght of prices:{}', len(prices))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "type of prices:{} <class 'numpy.ndarray'>\n",
            "lenght of prices:{} 20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SM998HO2D3bb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1672
        },
        "outputId": "1e6fb377-4532-431e-f4cf-927d8a2ff44c"
      },
      "cell_type": "code",
      "source": [
        "all_timeseries = [create_time_series() for i in range(0, SEQ_LEN * 4)]\n",
        "\n",
        "\n",
        "# We need to stack X numpy array on top of each other and then create a dictionary\n",
        "# for every features\n",
        "column_names = [str(idx) for idx in range(0, SEQ_LEN)]\n",
        "\n",
        "feature_names = column_names[0:-N_OUTPUTS]\n",
        "labels = column_names[-N_OUTPUTS:]\n",
        "all_data = np.stack(all_timeseries)\n",
        "\n",
        "print('All data shape is{0}'.format(all_data.shape))\n",
        "X, y = all_data[...,0:-N_OUTPUTS], all_data[...,-N_OUTPUTS:]\n",
        "\n",
        "print ('X is fo type {0}, y  of type {1}'.format(type(X[0][0]), type(y)))\n",
        "\n",
        "\n",
        "print ('X.shape is {0}, y shap is {1}'.format(X.shape, y.shape))\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,\n",
        "                                                    y,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "features_train = dict((fn,X_train[:, [idx]]) for idx, fn in enumerate(feature_names))\n",
        "labels_train = y_train\n",
        "\n",
        "\n",
        "# Test data\n",
        "features_test = dict((fn,X_test[:, [idx]]) for idx, fn in enumerate(feature_names))\n",
        "labels_test = y_test\n",
        "\n",
        "\n",
        "\n",
        "LSTM_SIZE = 3  # number of hidden layers in each of the LSTM cells\n",
        "\n",
        "# create the inference model\n",
        "def simple_rnn(features, labels, mode, params):\n",
        "  # 0. Reformat input shape to become a sequence\n",
        "  print ('IN Features are:{0}'.format(features))\n",
        "  x = tf.split(features[TIMESERIES_COL], N_INPUTS, 1)\n",
        "  #print 'x={}'.format(x)\n",
        "    \n",
        "  # 1. configure the RNN\n",
        "  lstm_cell = rnn.BasicLSTMCell(LSTM_SIZE, forget_bias=1.0)\n",
        "  outputs, _ = tf.nn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
        "\n",
        "  # slice to keep only the last cell of the RNN\n",
        "  outputs = outputs[-1]\n",
        "  #print 'last outputs={}'.format(outputs)\n",
        "  \n",
        "  # output is result of linear activation of last layer of RNN\n",
        "  weight = tf.Variable(tf.random_normal([LSTM_SIZE, N_OUTPUTS]))\n",
        "  bias = tf.Variable(tf.random_normal([N_OUTPUTS]))\n",
        "  predictions = tf.matmul(outputs, weight) + bias\n",
        "    \n",
        "  # 2. loss function, training/eval ops\n",
        "  if mode == ModeKeys.TRAIN or mode == ModeKeys.EVAL:\n",
        "     loss = tf.losses.mean_squared_error(labels, predictions)\n",
        "     train_op = tf.contrib.layers.optimize_loss(\n",
        "         loss=loss,\n",
        "         global_step=tf.train.get_global_step(),\n",
        "         learning_rate=0.01,\n",
        "         optimizer=\"SGD\")\n",
        "     eval_metric_ops = {\n",
        "      \"rmse\": tf.metrics.root_mean_squared_error(labels, predictions)\n",
        "     }\n",
        "  else:\n",
        "     loss = None\n",
        "     train_op = None\n",
        "     eval_metric_ops = None\n",
        "  \n",
        "  # 3. Create predictions\n",
        "  predictions_dict = {\"predicted\": predictions}\n",
        "\n",
        "  # 4. Create export outputs  \n",
        "  export_outputs = {\"predicted\": tf.estimator.export.PredictOutput(predictions)}\n",
        "\n",
        "  # 5. return ModelFnOps\n",
        "  return tf.estimator.EstimatorSpec(\n",
        "      mode=mode,\n",
        "      predictions=predictions_dict,\n",
        "      loss=loss,\n",
        "      train_op=train_op,\n",
        "      eval_metric_ops=eval_metric_ops,\n",
        "      export_outputs=export_outputs)\n",
        "\n",
        "def serving_input_receiver_fn():\n",
        "  feature_placeholders = {\n",
        "    TIMESERIES_COL: tf.placeholder(tf.float32, [None, N_INPUTS])\n",
        "  }\n",
        "\n",
        "  features = {\n",
        "    key: tf.expand_dims(tensor, -1)\n",
        "    for key, tensor in feature_placeholders.items()\n",
        "  }\n",
        "\n",
        "  features[TIMESERIES_COL] = tf.squeeze(features[TIMESERIES_COL], axis=[2], name='timeseries')\n",
        "  \n",
        "  print('serving: features={}'.format(features[TIMESERIES_COL]))\n",
        "\n",
        "  return tf.estimator.export.ServingInputReceiver(features, feature_placeholders)\n",
        "\n",
        "\n",
        "\n",
        "# Creating a TrainFn and a TestFn\n",
        "def _train_fn(X, y, batch_size):\n",
        "    \n",
        "    def _train():\n",
        "        \"\"\"An input function for training\"\"\"\n",
        "        # Convert the inputs to a Dataset.\n",
        "        # TODO need to be refactored according to https://medium.com/google-cloud/how-to-do-time-series-prediction-using-rnns-and-tensorflow-and-cloud-ml-engine-2ad2eeb189e8\n",
        "        # this is not good.\n",
        "        X_32 = tf.cast(X, tf.float32)\n",
        "        y_32 = tf.cast(y, tf.float32)\n",
        "        inputs = tf.concat(X_32, axis=1)\n",
        "        label = tf.concat(y_32, axis=1)\n",
        "        features, labels = {TIMESERIES_COL: inputs}, label\n",
        "        \n",
        "        return features, labels\n",
        "        dataset = tf.data.Dataset.from_tensor_slices(features, labels)\n",
        "        # Shuffle, repeat, and batch the examples.\n",
        "        dataset = dataset.repeat(None).batch(batch_size)\n",
        "        # This will now return batches of features, label\n",
        "        return dataset.make_one_shot_iterator().get_next()\n",
        "    return _train\n",
        "\n",
        "def _test_fn(X, y, batch_size):\n",
        "    def _test():\n",
        "        \"\"\"An input function for training\"\"\"\n",
        "        # Convert the inputs to a Dataset.\n",
        "        X_32 = tf.cast(X, tf.float32)\n",
        "        y_32 = tf.cast(y, tf.float32)\n",
        "        inputs = tf.concat(X_32, axis=1)\n",
        "        label = tf.concat(y_32, axis=1)\n",
        "        \n",
        "        features, labels = {TIMESERIES_COL: inputs}, label\n",
        "        \n",
        "        return features, labels\n",
        "        \n",
        "        dataset = tf.data.Dataset.from_tensor_slices(features, labels)\n",
        "        # Shuffle, repeat, and batch the examples.\n",
        "        dataset = dataset.repeat(1).batch(batch_size)\n",
        "        # This will now return batches of features, label\n",
        "        return dataset.make_one_shot_iterator().get_next()\n",
        "    return _test  \n",
        "  \n",
        " \n",
        "def experiment_fn(output_dir):\n",
        "    # run experiment\n",
        "    train_spec = tf.estimator.TrainSpec(\n",
        "          input_fn=_train_fn(X_train, y_train, BATCH_SIZE), max_steps=1500)\n",
        "    exporter = tf.estimator.FinalExporter('timeseries',\n",
        "    serving_input_receiver_fn)\n",
        "    eval_spec = tf.estimator.EvalSpec(\n",
        "            input_fn=_test_fn(X_test, y_test, BATCH_SIZE), \n",
        "            exporters=[exporter])\n",
        "    \n",
        "    estimator = tf.estimator.Estimator(model_fn=simple_rnn, model_dir=output_dir)\n",
        "\n",
        "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.INFO)    \n",
        "    \n",
        "output_dir = ROOT_DIR.format(datetime.utcnow().strftime('%Y%m%d%H%M%S'))  \n",
        "  \n",
        "experiment_fn(output_dir)\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All data shape is(80, 20)\n",
            "X is fo type <class 'numpy.float64'>, y  of type <class 'numpy.ndarray'>\n",
            "X.shape is (80, 14), y shap is (80, 6)\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/home/mmistroni/tf_logs/rnn-run-20181127214854', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f66d94b8a90>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function simple_rnn at 0x7f66d8e92e18>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "IN Features are:{'rawdata': <tf.Tensor 'concat:0' shape=(64, 14) dtype=float32>}\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /home/mmistroni/tf_logs/rnn-run-20181127214854/model.ckpt.\n",
            "INFO:tensorflow:loss = 5858.933, step = 1\n",
            "INFO:tensorflow:global_step/sec: 237.855\n",
            "INFO:tensorflow:loss = 3004.184, step = 101 (0.422 sec)\n",
            "INFO:tensorflow:global_step/sec: 642.782\n",
            "INFO:tensorflow:loss = 1540.6833, step = 201 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 643.847\n",
            "INFO:tensorflow:loss = 790.1327, step = 301 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 657.054\n",
            "INFO:tensorflow:loss = 405.21606, step = 401 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 658.975\n",
            "INFO:tensorflow:loss = 207.81335, step = 501 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 634.21\n",
            "INFO:tensorflow:loss = 106.576256, step = 601 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 638.826\n",
            "INFO:tensorflow:loss = 54.65718, step = 701 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 666.535\n",
            "INFO:tensorflow:loss = 28.030752, step = 801 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 640.769\n",
            "INFO:tensorflow:loss = 14.375468, step = 901 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 614.21\n",
            "INFO:tensorflow:loss = 7.3723655, step = 1001 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 635.124\n",
            "INFO:tensorflow:loss = 3.780914, step = 1101 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 626.32\n",
            "INFO:tensorflow:loss = 1.9390383, step = 1201 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 606.179\n",
            "INFO:tensorflow:loss = 0.9944191, step = 1301 (0.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 646.036\n",
            "INFO:tensorflow:loss = 0.5099889, step = 1401 (0.155 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 1500 into /home/mmistroni/tf_logs/rnn-run-20181127214854/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "IN Features are:{'rawdata': <tf.Tensor 'concat:0' shape=(16, 14) dtype=float32>}\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-11-27-21:49:00\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /home/mmistroni/tf_logs/rnn-run-20181127214854/model.ckpt-1500\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Evaluation [10/100]\n",
            "INFO:tensorflow:Evaluation [20/100]\n",
            "INFO:tensorflow:Evaluation [30/100]\n",
            "INFO:tensorflow:Evaluation [40/100]\n",
            "INFO:tensorflow:Evaluation [50/100]\n",
            "INFO:tensorflow:Evaluation [60/100]\n",
            "INFO:tensorflow:Evaluation [70/100]\n",
            "INFO:tensorflow:Evaluation [80/100]\n",
            "INFO:tensorflow:Evaluation [90/100]\n",
            "INFO:tensorflow:Evaluation [100/100]\n",
            "INFO:tensorflow:Finished evaluation at 2018-11-27-21:49:00\n",
            "INFO:tensorflow:Saving dict for global step 1500: global_step = 1500, loss = 0.26155484, rmse = 0.5114245\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1500: /home/mmistroni/tf_logs/rnn-run-20181127214854/model.ckpt-1500\n",
            "INFO:tensorflow:Performing the final export in the end of training.\n",
            "serving: features=Tensor(\"timeseries:0\", shape=(?, 14), dtype=float32)\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "IN Features are:{'rawdata': <tf.Tensor 'timeseries:0' shape=(?, 14) dtype=float32>}\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predicted', 'serving_default']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "INFO:tensorflow:Restoring parameters from /home/mmistroni/tf_logs/rnn-run-20181127214854/model.ckpt-1500\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: /home/mmistroni/tf_logs/rnn-run-20181127214854/export/timeseries/temp-b'1543355341'/saved_model.pb\n",
            "INFO:tensorflow:Loss for final step: 0.2633063.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LEMTgvKICpoc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "prI5nJS_S4nf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Installing libraries and downloading data as DataFrame\n"
      ]
    },
    {
      "metadata": {
        "id": "zwQN5CmUS_pS",
        "colab_type": "code",
        "outputId": "4a0dd9d6-c540-43fe-c5e5-9783968207bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install pandas_datareader"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pandas_datareader\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/5c/ea5b6dcfd0f55c5fb1e37fb45335ec01cceca199b8a79339137f5ed269e0/pandas_datareader-0.7.0-py2.py3-none-any.whl (111kB)\n",
            "\r\u001b[K    9% |                             | 10kB 15.9MB/s eta 0:00:01\r\u001b[K    18% |                          | 20kB 3.0MB/s eta 0:00:01\r\u001b[K    27% |                       | 30kB 3.3MB/s eta 0:00:01\r\u001b[K    36% |                    | 40kB 3.0MB/s eta 0:00:01\r\u001b[K    45% |                 | 51kB 3.4MB/s eta 0:00:01\r\u001b[K    55% |              | 61kB 4.0MB/s eta 0:00:01\r\u001b[K    64% |           | 71kB 3.8MB/s eta 0:00:01\r\u001b[K    73% |        | 81kB 3.7MB/s eta 0:00:01\r\u001b[K    82% |     | 92kB 4.1MB/s eta 0:00:01\r\u001b[K    91% |  | 102kB 4.4MB/s eta 0:00:01\r\u001b[K    100% || 112kB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from pandas_datareader) (2.18.4)\n",
            "Requirement already satisfied: pandas>=0.19.2 in /usr/local/lib/python3.6/dist-packages (from pandas_datareader) (0.22.0)\n",
            "Collecting lxml (from pandas_datareader)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/a4/9eea8035fc7c7670e5eab97f34ff2ef0ddd78a491bf96df5accedb0e63f5/lxml-4.2.5-cp36-cp36m-manylinux1_x86_64.whl (5.8MB)\n",
            "\u001b[K    100% || 5.8MB 4.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from pandas_datareader) (1.10.11)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas_datareader) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas_datareader) (2018.10.15)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas_datareader) (1.22)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas_datareader) (2.6)\n",
            "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->pandas_datareader) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->pandas_datareader) (2018.7)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->pandas_datareader) (1.14.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2->pandas>=0.19.2->pandas_datareader) (1.11.0)\n",
            "Installing collected packages: lxml, pandas-datareader\n",
            "Successfully installed lxml-4.2.5 pandas-datareader-0.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZFt1ZH-GTPV-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas_datareader as pdr\n",
        "from datetime import date, timedelta\n",
        "startdate = date.today() - timedelta(days=100)\n",
        "stock_data = pdr.get_data_yahoo('^GSPC', startdate, date.today())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rIAYARAcTXzf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Creating 10 batches of 10 Items"
      ]
    },
    {
      "metadata": {
        "id": "QeBP_1ykTgeP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "closes = stock_data[['Close']]\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WafXje98Qyiq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def init(hparams):\n",
        "    global SEQ_LEN, DEFAULTS, N_INPUTS\n",
        "    N_OUTPUTS = 3  # in each sequence, 1-9 are features, and 10 is label\n",
        "    SEQ_LEN = 10\n",
        "    DEFAULTS = 0.0\n",
        "    DEFAULTS = [[0.0] for x in range(0, SEQ_LEN)]\n",
        "    N_INPUTS = SEQ_LEN - N_OUTPUTS\n",
        "\n",
        "\n",
        "def linear_model(features, mode, params):\n",
        "    X = features[TIMESERIES_COL]\n",
        "    predictions = tf.layers.dense(X, 1, activation=None)\n",
        "    return predictions\n",
        "\n",
        "\n",
        "def dnn_model(features, mode, params):\n",
        "    X = features[TIMESERIES_COL]\n",
        "    h1 = tf.layers.dense(X, 10, activation=tf.nn.relu)\n",
        "    h2 = tf.layers.dense(h1, 3, activation=tf.nn.relu)\n",
        "    predictions = tf.layers.dense(h2, 1, activation=None)  # linear output: regression\n",
        "    return predictions\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t3E-or7HQ2RF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cnn_model(features, mode, params):\n",
        "    X = tf.reshape(features[TIMESERIES_COL],\n",
        "                   [-1, N_INPUTS, 1])  # as a 1D \"sequence\" with only one time-series observation (height)\n",
        "    c1 = tf.layers.conv1d(X, filters=N_INPUTS // 2,\n",
        "                          kernel_size=3, strides=1,\n",
        "                          padding='same', activation=tf.nn.relu)\n",
        "    p1 = tf.layers.max_pooling1d(c1, pool_size=2, strides=2)\n",
        "\n",
        "    c2 = tf.layers.conv1d(p1, filters=N_INPUTS // 2,\n",
        "                          kernel_size=3, strides=1,\n",
        "                          padding='same', activation=tf.nn.relu)\n",
        "    p2 = tf.layers.max_pooling1d(c2, pool_size=2, strides=2)\n",
        "\n",
        "    outlen = p2.shape[1] * p2.shape[2]\n",
        "    c2flat = tf.reshape(p2, [-1, outlen])\n",
        "    h1 = tf.layers.dense(c2flat, 3, activation=tf.nn.relu)\n",
        "    predictions = tf.layers.dense(h1, 1, activation=None)  # linear output: regression\n",
        "    return predictions\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "01uU1JjqQ5tC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def rnn_model(features, mode, params):\n",
        "    CELL_SIZE = N_INPUTS // 3  # size of the internal state in each of the cells\n",
        "\n",
        "    # 1. dynamic_rnn needs 3D shape: [BATCH_SIZE, N_INPUTS, 1]\n",
        "    x = tf.reshape(features[TIMESERIES_COL], [-1, N_INPUTS, 1])\n",
        "\n",
        "    # 2. configure the RNN\n",
        "    cell = tf.nn.rnn_cell.GRUCell(CELL_SIZE)\n",
        "    outputs, state = tf.nn.dynamic_rnn(cell, x, dtype=tf.float64)\n",
        "\n",
        "    # 3. pass rnn output through a dense layer\n",
        "    h1 = tf.layers.dense(state, N_INPUTS // 2, activation=tf.nn.relu)\n",
        "    predictions = tf.layers.dense(h1, 1, activation=None)  # (?, 1)\n",
        "    return predictions\n",
        "\n",
        "\n",
        "# 2-layer RNN\n",
        "def rnn2_model(features, mode, params):\n",
        "    # dynamic_rnn needs 3D shape: [BATCH_SIZE, N_INPUTS, 1]\n",
        "    x = tf.reshape(features[TIMESERIES_COL], [-1, N_INPUTS, 1])\n",
        "\n",
        "    # 2. configure the RNN\n",
        "    cell1 = tf.nn.rnn_cell.GRUCell(N_INPUTS * 2)\n",
        "    cell2 = tf.nn.rnn_cell.GRUCell(N_INPUTS // 2)\n",
        "    cells = tf.nn.rnn_cell.MultiRNNCell([cell1, cell2])\n",
        "    outputs, state = tf.nn.dynamic_rnn(cells, x, dtype=tf.float32)\n",
        "    # 'state' is now a tuple containing the final state of each cell layer\n",
        "    # we use state[1] below to extract the final state of the final layer\n",
        "    \n",
        "    # 3. pass rnn output through a dense layer\n",
        "    h1 = tf.layers.dense(state[1], cells.output_size // 2, activation=tf.nn.relu)\n",
        "    predictions = tf.layers.dense(h1, 1, activation=None)  # (?, 1)\n",
        "    return predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "34GMRROIQ9wJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def rnnN_model(features, mode, params):\n",
        "    # dynamic_rnn needs 3D shape: [BATCH_SIZE, N_INPUTS, 1]\n",
        "    x = tf.reshape(features[TIMESERIES_COL], [-1, N_INPUTS, 1])\n",
        "\n",
        "    # 2. configure the RNN\n",
        "    cell1 = tf.nn.rnn_cell.GRUCell(N_INPUTS * 2)\n",
        "    cell2 = tf.nn.rnn_cell.GRUCell(N_INPUTS // 2)\n",
        "    cells = tf.nn.rnn_cell.MultiRNNCell([cell1, cell2])\n",
        "    outputs, state = tf.nn.dynamic_rnn(cells, x, dtype=tf.float32)\n",
        "    # 'outputs' contains the state of the final layer for every time step\n",
        "    # not just the last time step (?,N_INPUTS, final cell size)\n",
        "    \n",
        "    # 3. pass state for each time step through a DNN, to get a prediction\n",
        "    # for each time step \n",
        "    h1 = tf.layers.dense(outputs, cells.output_size, activation=tf.nn.relu)\n",
        "    h2 = tf.layers.dense(h1, cells.output_size // 2, activation=tf.nn.relu)\n",
        "    predictions = tf.layers.dense(h2, 1, activation=None)  # (?, N_INPUTS, 1)\n",
        "    predictions = tf.reshape(predictions, [-1, N_INPUTS])\n",
        "    return predictions # return prediction for each time step"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zDTmg52wRDTO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# read data and convert to needed format\n",
        "def read_dataset(filename, mode, batch_size=10):\n",
        "    # What we  need to do here is to somehow pass a 10*10 dataset. and we should not use decode_csv but rather do similar\n",
        "    # to what we have done in the california dtaset\n",
        "    def _input_fn():\n",
        "        def decode_csv(row):\n",
        "            # row is a string tensor containing the contents of one row\n",
        "            features = tf.decode_csv(row, record_defaults=DEFAULTS)  # string tensor -> list of 50 rank 0 float tensors\n",
        "            label = features.pop()  # remove last feature and use as label\n",
        "            features = tf.stack(features)  # list of rank 0 tensors -> single rank 1 tensor\n",
        "            return {TIMESERIES_COL: features}, label\n",
        "\n",
        "        # Create list of file names that match \"glob\" pattern (i.e. data_file_*.csv)\n",
        "        dataset = tf.data.Dataset.list_files(filename)\n",
        "        # Read in data from files\n",
        "        dataset = dataset.flat_map(tf.data.TextLineDataset)\n",
        "        # Parse text lines as comma-separated values (CSV)\n",
        "        dataset = dataset.map(decode_csv)\n",
        "\n",
        "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "            num_epochs = None  # loop indefinitely\n",
        "            dataset = dataset.shuffle(buffer_size=10 * batch_size)\n",
        "        else:\n",
        "            num_epochs = 1  # end-of-input after this\n",
        "\n",
        "        dataset = dataset.repeat(num_epochs).batch(batch_size)\n",
        "        return dataset.make_one_shot_iterator().get_next()\n",
        "\n",
        "    return _input_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Eg3H9IqURH-E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def serving_input_fn():\n",
        "    feature_placeholders = {\n",
        "        TIMESERIES_COL: tf.placeholder(tf.float32, [None, N_INPUTS])\n",
        "    }\n",
        "\n",
        "    features = {\n",
        "        key: tf.expand_dims(tensor, -1)\n",
        "        for key, tensor in feature_placeholders.items()\n",
        "    }\n",
        "    features[TIMESERIES_COL] = tf.squeeze(features[TIMESERIES_COL], axis=[2])\n",
        "\n",
        "    return tf.estimator.export.ServingInputReceiver(features, feature_placeholders)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nb4dc0SmRMoI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def compute_errors(features, labels, predictions):\n",
        "    labels = tf.expand_dims(labels, -1)  # rank 1 -> rank 2 to match rank of predictions\n",
        "\n",
        "    if predictions.shape[1] == 1:\n",
        "        loss = tf.losses.mean_squared_error(labels, predictions)\n",
        "        rmse = tf.metrics.root_mean_squared_error(labels, predictions)\n",
        "        return loss, rmse\n",
        "    else:\n",
        "        # one prediction for every input in sequence\n",
        "        # get 1-N of (x + label)\n",
        "        labelsN = tf.concat([features[TIMESERIES_COL], labels], axis=1)\n",
        "        labelsN = labelsN[:, 1:]\n",
        "        # loss is computed from the last 1/3 of the series\n",
        "        N = (2 * N_INPUTS) // 3\n",
        "        loss = tf.losses.mean_squared_error(labelsN[:, N:], predictions[:, N:])\n",
        "        # rmse is computed from last prediction and last label\n",
        "        lastPred = predictions[:, -1]\n",
        "        rmse = tf.metrics.root_mean_squared_error(labels, lastPred)\n",
        "        return loss, rmse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3RqHjBIiRRLv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# RMSE when predicting same as last value\n",
        "def same_as_last_benchmark(features, labels):\n",
        "    predictions = features[TIMESERIES_COL][:,-1] # last value in input sequence\n",
        "    return tf.metrics.root_mean_squared_error(labels, predictions)\n",
        "\n",
        "\n",
        "# create the inference model\n",
        "def sequence_regressor(features, labels, mode, params):\n",
        "    # 1. run the appropriate model\n",
        "    model_functions = {\n",
        "        'linear': linear_model,\n",
        "        'dnn': dnn_model,\n",
        "        'cnn': cnn_model,\n",
        "        'rnn': rnn_model,\n",
        "        'rnn2': rnn2_model,\n",
        "        'rnnN': rnnN_model}\n",
        "    model_function = model_functions[params['model']]\n",
        "    predictions = model_function(features, mode, params)\n",
        "\n",
        "    # 2. loss function, training/eval ops\n",
        "    loss = None\n",
        "    train_op = None\n",
        "    eval_metric_ops = None\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN or mode == tf.estimator.ModeKeys.EVAL:\n",
        "        loss, rmse = compute_errors(features, labels, predictions)\n",
        "\n",
        "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "            # this is needed for batch normalization, but has no effect otherwise\n",
        "            update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "            with tf.control_dependencies(update_ops):\n",
        "                # 2b. set up training operation\n",
        "                train_op = tf.contrib.layers.optimize_loss(\n",
        "                    loss,\n",
        "                    tf.train.get_global_step(),\n",
        "                    learning_rate=params['learning_rate'],\n",
        "                    optimizer=\"Adam\")\n",
        "\n",
        "        # 2c. eval metric\n",
        "        eval_metric_ops = {\n",
        "            \"RMSE\": rmse,\n",
        "            \"RMSE_same_as_last\": same_as_last_benchmark(features, labels),\n",
        "        }\n",
        "\n",
        "    # 3. Create predictions\n",
        "    if predictions.shape[1] != 1:\n",
        "        predictions = predictions[:, -1]  # last predicted value\n",
        "    predictions_dict = {\"predicted\": predictions}\n",
        "\n",
        "    # 4. return EstimatorSpec\n",
        "    return tf.estimator.EstimatorSpec(\n",
        "        mode=mode,\n",
        "        predictions=predictions_dict,\n",
        "        loss=loss,\n",
        "        train_op=train_op,\n",
        "        eval_metric_ops=eval_metric_ops,\n",
        "        export_outputs={\n",
        "            'predictions': tf.estimator.export.PredictOutput(predictions_dict)}\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qng51S1QRYqe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(output_dir, hparams):\n",
        "    #get_train = read_dataset(hparams['train_data_path'],\n",
        "    #                         tf.estimator.ModeKeys.TRAIN,\n",
        "    #                         hparams['train_batch_size'])\n",
        "    #get_valid = read_dataset(hparams['eval_data_path'],\n",
        "    #                         tf.estimator.ModeKeys.EVAL,\n",
        "    #                         1000)\n",
        "    \n",
        "    get_train = _train_fn(features=features_train,\n",
        "                                    labels=labels_train,\n",
        "                                    batch_size=10)\n",
        "    \n",
        "    get_valid = _test_fn(features=features_test, \n",
        "                                      labels=labels_test,\n",
        "                                      batch_size=10)\n",
        "    \n",
        "    estimator = tf.estimator.Estimator(model_fn=sequence_regressor,\n",
        "                                       params=hparams,\n",
        "                                       config=tf.estimator.RunConfig(\n",
        "                                           save_checkpoints_secs=\n",
        "                                           hparams['min_eval_frequency']),\n",
        "                                       model_dir=output_dir)\n",
        "    train_spec = tf.estimator.TrainSpec(input_fn=get_train,\n",
        "                                        max_steps=hparams['train_steps'])\n",
        "    exporter = tf.estimator.LatestExporter('exporter', serving_input_fn)\n",
        "    eval_spec = tf.estimator.EvalSpec(input_fn=get_valid,\n",
        "                                      steps=None,\n",
        "                                      exporters=exporter,\n",
        "                                      start_delay_secs=hparams['eval_delay_secs'],\n",
        "                                      throttle_secs=hparams['min_eval_frequency'])\n",
        "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vBpeXVfbRcre",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "9272eef1-ccaa-4064-ec37-21b3392f2b19"
      },
      "cell_type": "code",
      "source": [
        "# TODO : Check original example for shape of the data\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "EVAL_INTERVAL = 300\n",
        "TRAIN_STEPS = 10000\n",
        "EVAL_DELAY_SECS = 60\n",
        "ROOT_DIR = '/home/mmistroni/tf_logs/run-{}'\n",
        "hparams = dict(min_eval_frequency=EVAL_INTERVAL, train_steps=TRAIN_STEPS, eval_delay_secs = EVAL_DELAY_SECS, model='dnn')\n",
        "from datetime import datetime\n",
        "train_and_evaluate('/home/mmistroni/tf_logs/timeseries/run-{}-{}'.format(ROOT_DIR.format(datetime.utcnow().strftime('%Y%m%d%H%M%S')),\n",
        "                                                                         hparams['model']), hparams)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-572c1abf2e89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m train_and_evaluate('/home/mmistroni/tf_logs/timeseries/run-{}-{}'.format(ROOT_DIR.format(datetime.utcnow().strftime('%Y%m%d%H%M%S')),\n\u001b[0;32m---> 10\u001b[0;31m                                                                          hparams['model']), hparams)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-f96463799ec2>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(output_dir, hparams)\u001b[0m\n\u001b[1;32m      9\u001b[0m     get_train = _train_fn(features=features_train,\n\u001b[1;32m     10\u001b[0m                                     \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                                     batch_size=10)\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     get_valid = _test_fn(features=features_test, \n",
            "\u001b[0;31mTypeError\u001b[0m: _train_fn() got an unexpected keyword argument 'features'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "e8SxyWVIxS3L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}