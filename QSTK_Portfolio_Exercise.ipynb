{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QSTK-Portfolio-Exercise.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmistroni/TensorFlowPlayground/blob/master/QSTK_Portfolio_Exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAV3TDf5FAEX",
        "colab_type": "text"
      },
      "source": [
        "<h2>Installing required packages </h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rbx9S7UGG_WC",
        "colab_type": "code",
        "outputId": "8e03df7e-5e41-4cf6-9505-9e2aa7bc2343",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "!pip install pandas-datareader"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas-datareader in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from pandas-datareader) (2.21.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from pandas-datareader) (1.11.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from pandas-datareader) (4.2.6)\n",
            "Requirement already satisfied: pandas>=0.19.2 in /usr/local/lib/python3.6/dist-packages (from pandas-datareader) (0.24.2)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas-datareader) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas-datareader) (2019.6.16)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas-datareader) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas-datareader) (1.24.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->pandas-datareader) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->pandas-datareader) (2.5.3)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->pandas-datareader) (1.16.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas>=0.19.2->pandas-datareader) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_WAe-pQHGvH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import urllib\n",
        "import json\n",
        "import pandas as pd\n",
        "from pandas.tseries.offsets import BDay\n",
        "import pandas_datareader.data as dr\n",
        "import numpy as np\n",
        "from datetime import datetime, date\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "from collections import OrderedDict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1sZg1w1IrbA",
        "colab_type": "text"
      },
      "source": [
        "<h3> Computing Sharpe Ratio and Returns </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7bhcaANIvGd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "logger = logging.getLogger(__name__)\n",
        "from math import sqrt\n",
        "\n",
        "def get_prices(ls_symbols, dt_start, dt_end):\n",
        "    dt_timeofday = dt.timedelta(hours=16)\n",
        "    ldt_timestamps = du.getNYSEdays(dt_start, dt_end, dt_timeofday)\n",
        "    #c_dataobj = da.DataAccess('Yahoo')\n",
        "    c_dataobj = da.DataAccess('Yahoo', cachestalltime=0)\n",
        "    ls_keys = ['close']\n",
        "    ldf_data = c_dataobj.get_data(ldt_timestamps, ls_symbols, ls_keys)\n",
        "    return  dict(zip(ls_keys, ldf_data)) # each field is returned as a single dataframe\n",
        "\n",
        "def compute_daily_returns(prices):\n",
        "    na_rets = prices.copy()\n",
        "    return tsu.returnize0(na_rets)\n",
        "\n",
        "def compute_standard_deviations(daily_returns):\n",
        "    return np.std(daily_returns)\n",
        "\n",
        "def normalize_prices(prices):\n",
        "    return prices / prices[0,:]\n",
        "\n",
        "def compute_sharpe_ratio(daily_returns, standard_dev):\n",
        "    \n",
        "    avg = np.average(daily_returns)# / len(daily_returns)\n",
        "    return (sqrt(252) * avg) / standard_dev"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HsGeVdiI572",
        "colab_type": "text"
      },
      "source": [
        "<h3> Compute Statistics </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YMinQF5I93Y",
        "colab_type": "code",
        "outputId": "d27bc588-cb24-461d-bac6-d6a2be50da4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "import pandas as pd\n",
        "from pandas.tseries.offsets import BDay\n",
        "import pandas_datareader.data as dr\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "def get_closes(start, end, symbol):\n",
        "  return dr.DataReader(symbol, 'iex', start, end)['close']\n",
        "\n",
        "\n",
        "def compute_statistics(symbol, prices):\n",
        "  #prices = get_closes(start, end, symbol)\n",
        "  daily_returns = compute_daily_returns(prices)\n",
        "  std_dev  = compute_standard_deviations(daily_returns)\n",
        "  sharpe = compute_sharpe_ratio(daily_returns, std_dev)\n",
        "  total_returns = (prices[-1]*1.0 / prices[0]) -1\n",
        "  \n",
        "  \n",
        "  return {'std_dev' : std_dev,\n",
        "         'sharpe_ratio' : sharpe,\n",
        "         'total_returns' : total_returns,\n",
        "         'symbol': symbol}\n",
        "  \n",
        "\n",
        "end = pd.Timestamp(datetime.now())\n",
        "start = end - BDay(250)\n",
        "symbols =  ['NWVCF', 'TGIFF']\n",
        "           # ['MARA','DPW','TOPS','HAON','HTBX','IMNP','OPGN','SUZBY','ARCO','TRQ','ARTX','PDLI','ENPH','PLPL',\n",
        "           #'DNN','ZYNE','EYEG','FLKS','APHB','PHBI','ENDV']\n",
        "\n",
        "all_dicts = []\n",
        "for sym in symbols:\n",
        "  try:\n",
        "    all_dicts.append((sym, get_closes(start, end, sym)))#compute_statistics(start, end ,sym)) #compute_statistics(sym, start, end))\n",
        "  except Exception as e:\n",
        "    print('Unable to fetch statistics for %s:%s' % (sym, str(e)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unable to fetch statistics for NWVCF:Unable to read URL: https://api.iextrading.com/1.0/stock/market/batch?symbols=NWVCF&types=chart&range=1y\n",
            "Response Text:\n",
            "b'Forbidden'\n",
            "Unable to fetch statistics for TGIFF:Unable to read URL: https://api.iextrading.com/1.0/stock/market/batch?symbols=TGIFF&types=chart&range=1y\n",
            "Response Text:\n",
            "b'Forbidden'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukwXzHSnJbjU",
        "colab_type": "code",
        "outputId": "f719753c-8f84-42dd-b3f4-d94ddb72ee7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "all_df = []\n",
        "for symbol, prices in all_dicts:\n",
        "  all_df.append(compute_statistics(symbol, prices))\n",
        "df = pd.DataFrame(all_df)[['symbol', 'total_returns','std_dev', 'sharpe_ratio']]\n",
        "df"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-e259df4cbcde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msymbol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprices\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mall_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_statistics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'symbol'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'total_returns'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'std_dev'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sharpe_ratio'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2932\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2933\u001b[0m             indexer = self.loc._convert_to_indexer(key, axis=1,\n\u001b[0;32m-> 2934\u001b[0;31m                                                    raise_missing=True)\n\u001b[0m\u001b[1;32m   2935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[1;32m   1352\u001b[0m                 kwargs = {'raise_missing': True if is_setter else\n\u001b[1;32m   1353\u001b[0m                           raise_missing}\n\u001b[0;32m-> 1354\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1355\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         self._validate_read_indexer(keyarr, indexer,\n\u001b[1;32m   1160\u001b[0m                                     \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m                                     raise_missing=raise_missing)\n\u001b[0m\u001b[1;32m   1162\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1244\u001b[0m                 raise KeyError(\n\u001b[1;32m   1245\u001b[0m                     u\"None of [{key}] are in the [{axis}]\".format(\n\u001b[0;32m-> 1246\u001b[0;31m                         key=key, axis=self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[1;32m   1247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m             \u001b[0;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['symbol', 'total_returns', 'std_dev', 'sharpe_ratio'], dtype='object')] are in the [columns]\""
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4p7Ht1mBJ1sQ",
        "colab_type": "text"
      },
      "source": [
        "<h3>Computing Future Earnings </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-qoX9qVJ5LA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import urllib\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def get_future_earnings_df(symbol):\n",
        "\n",
        "  base_url = 'https://us-central1-datascience-projects.cloudfunctions.net/future_earnings/{}'.format(symbol)\n",
        "  res = urllib.request.urlopen(base_url)\n",
        "  json_dict = res.read() #json.load(res)\n",
        "  try:\n",
        "    df = pd.read_json(json_dict)\n",
        "\n",
        "    cons  = df['Consensus'].values\n",
        "    fisc = df['Fiscal'].values\n",
        "    new_cols = ['T+{}'.format(idx) for idx in range(1, len(fisc) + 1)]\n",
        "    \n",
        "    converted = pd.DataFrame([cons], columns=fisc)\n",
        "    converted['symbol'] = symbol\n",
        "    return converted\n",
        "  except Exception as e:\n",
        "    print('exception in retrieving earnings for {}/{}'.format(symbol,str(e)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUu_VtImKQEN",
        "colab_type": "code",
        "outputId": "277f7935-9bea-4cd7-f021-e42d4003bf40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Computing Earnings\n",
        "symbols = \"\"\"AAPL\n",
        "MSFT\n",
        "JNJ\n",
        "XOM\n",
        "JPM\n",
        "AMZN\n",
        "GOOGL\n",
        "T\n",
        "F\n",
        "CVX\n",
        "PG\n",
        "INTC\n",
        "PFE\n",
        "CSCO\n",
        "BRK.B\n",
        "GOOG\n",
        "VZ\n",
        "DIS\n",
        "HD\n",
        "PEP\n",
        "V\n",
        "SPY\n",
        "BAC\n",
        "MRK\n",
        "IBM\n",
        "GE\n",
        "WFC\n",
        "ABBV\n",
        "KO\n",
        "BA\n",
        "\"\"\".split('\\n')\n",
        "\n",
        "all_dfs = [get_future_earnings_df(symbol) for symbol in symbols]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "exception in retrieving earnings for SPY/'Consensus'\n",
            "exception in retrieving earnings for /'Consensus'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8e6GDRBKY3y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "6980ccb8-6d9b-47bc-dd9e-8a9df8d1e4eb"
      },
      "source": [
        "good_ones = filter(lambda df: df is not None, all_dfs)\n",
        "\n",
        "min_shape = min(map(lambda df: df.shape[1], good_ones))\n",
        "col_to_project = good_ones[0].columns[0:min_shape]\n",
        "\n",
        "print ('Cols to project:{}'.format(col_to_project))\n",
        "\n",
        "\n",
        "reduced_df = reduce(lambda acc, item: item if acc is None else acc.append(item), good_ones, None)\n",
        "\n",
        "reduced_df"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-030f54a1d67c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmin_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgood_ones\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcol_to_project\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgood_ones\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmin_shape\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Cols to project:{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_to_project\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'filter' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSJPKY_0KsSR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "a34849cd-6378-4276-f87e-52b461b19728"
      },
      "source": [
        "merged= pd.merge(df, reduced_df, how='left', on='symbol')\n",
        "\n",
        "merged\n",
        "\n",
        "# SAving to csv file\n",
        "merged.to_csv('/tmp/results.csv')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-346584049355>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmerged\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduced_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'symbol'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmerged\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# SAving to csv file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEuH36sqK0BZ",
        "colab_type": "code",
        "outputId": "d6ce99b3-266b-49ce-f65b-1ae9de9804bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# checking the file is there\n",
        "!cat /tmp/results.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cat: /tmp/results.csv: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "empQA9NAK-IP",
        "colab_type": "text"
      },
      "source": [
        "<h3> Computing Moving Average </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qo7SKmFiLF_g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from pandas.tseries.offsets import BDay\n",
        "from datetime import date, datetime\n",
        "end = pd.Timestamp(datetime.now())\n",
        "start = end - BDay(250)\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def get_data(start, end, symbol):\n",
        "  return dr.DataReader(symbol, 'iex', start, end)['close']\n",
        "\n",
        "\n",
        "def get_historical_price(symbol, as_of_date):\n",
        "  # Leveraging Historical\n",
        "  historical_url = 'https://cloud.iexapis.com/stable/stock/{symbol}/chart/date/{cob}?token=sk_98e397d4bee940488e1f48e9b419508f&chartByDay=true'.format(\n",
        "                        symbol=symbol, cob=as_of_date.strftime('%Y%m%d'))\n",
        "  print('Fetching data for {} from:{}'.format(symbol, historical_url))\n",
        "  return requests.get(historical_url).json()\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "def compute_avg(prices):\n",
        "  mapped = map(lambda tpl: tpl[1], prices)\n",
        "  return np.average(mapped) if prices else 0.0\n",
        "\n",
        "\n",
        "def compute_moving_avg(prices, days):\n",
        "  res = [(prices[i][0], prices[i][1],  compute_avg(prices[i-days:i])) for i in range(0, len(prices))]\n",
        "  return res\n",
        "  \n",
        "  \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENxDiNhbLbnk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "from datetime import date, datetime\n",
        "from pandas.tseries.offsets import BDay\n",
        "import pandas as pd\n",
        "import logging\n",
        "from pprint import pprint\n",
        "import pandas_datareader as pdr\n",
        "    \n",
        "    \n",
        "\n",
        "multiline = \\\n",
        "\"\"\"\n",
        "2008-12-03,AAPL,BUY,130\n",
        "2008-12-08,AAPL,SELL,130\n",
        "2008-12-05,IBM,BUY,50\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "class Simulator:\n",
        "  def __init__(self, ticker_dict, initial_cash):\n",
        "    self.ticker_dict = ticker_dict\n",
        "    self.initial_cash = initial_cash\n",
        "    self.cache_list = []\n",
        "    \n",
        "  def simulate(self, trade):\n",
        "    print('Updating with {}'.format(trade))\n",
        "    as_of_dt, ticker, order_type, qty = trade\n",
        "    current_status = self.ticker_dict[ticker] # a listof (asofdate, qty)\n",
        "    market_qty = qty if order_type == 'BUY' else -qty\n",
        "    if not current_status:\n",
        "      current_status.append((as_of_dt.strftime('%Y-%m-%d'), qty ))\n",
        "    else:\n",
        "      prev_dt, prev_qty = current_status[-1]\n",
        "      new_qty = prev_qty + market_qty\n",
        "      print('Appending:{} @{}'.format(new_qty, as_of_dt))\n",
        "      current_status.append((as_of_dt.strftime('%Y-%m-%d'), prev_qty + market_qty))\n",
        "    print('Updating Cash.....')\n",
        "    self.update_cash(ticker, market_qty, as_of_dt)\n",
        "          \n",
        "  def update_cash(self, ticker, qty, as_of_date):\n",
        "    print('fetching {} price asOf:{}'.format(ticker, as_of_date))\n",
        "    price = get_historical_price(ticker, as_of_date)[0]['close']\n",
        "    cash_impact = price * qty * -1\n",
        "    \n",
        "    print('==Updating Cash OBtianed:{} '.format(cash_impact))\n",
        "    \n",
        "    self.initial_cash += cash_impact\n",
        "    self.cache_list.append((as_of_date, self.initial_cash))\n",
        "    \n",
        "  def current_status(self):\n",
        "    return self.ticker_dict\n",
        "  \n",
        "  def current_cash(self):\n",
        "    return self.cache_list\n",
        "  \n",
        "  def get_historical_price(self, symbol , as_of_date):\n",
        "    df =  pdr.get_data_yahoo(symbol, as_of_date, as_of_date)[['Close']]  \n",
        "    if df.shape[0] > 0:\n",
        "      return df.values[0][0]\n",
        "\n",
        "def parse_line(line):\n",
        "  raw_data = line.split(',')\n",
        "  return Order(raw_data)\n",
        "\n",
        "def find_all_tickers(orders):\n",
        "  return set(map(lambda t: t[1], orders))  \n",
        "\n",
        "def find_date_range(dates):\n",
        "  ts = pd.bdate_range(dates[0], dates[-1])\n",
        "  return [d for d in map(lambda t: t.date().strftime('%Y-%m-%d'), ts)]\n",
        "\n",
        "def generate_trade(row):\n",
        "  asOfDate, ticker, orderType, qty = row.split(',')\n",
        "    \n",
        "  return [datetime.strptime(asOfDate, \"%Y-%m-%d\").date(),\n",
        "            ticker, orderType, int(qty)]\n",
        "    \n",
        "def market_sim(initial_cash, orders):\n",
        "  trades = sorted(orders, key=lambda t: t[0])\n",
        "  tickers = find_all_tickers(trades)\n",
        "  symbols_dict = OrderedDict()\n",
        "  for ticker in tickers:\n",
        "    symbols_dict[ticker] = []\n",
        "  \n",
        "  return Simulator(symbols_dict, initial_cash)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C32FH54kLXJ0",
        "colab_type": "text"
      },
      "source": [
        "<h3> Creating Market Simulator </h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsfuYc_TUfWI",
        "colab_type": "text"
      },
      "source": [
        "<h3> Running Simulator </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kt27O4DeLvn4",
        "colab_type": "code",
        "outputId": "fcd0db41-87e1-4c70-a24d-ccd2d880415c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "#  The new website for QuantSoftware is:http://quantsoftware.gatech.edu/MC2-Project-1\n",
        "\n",
        "trade_rows  = [t for t in filter(lambda row:bool(row), map(lambda row: row.strip(), multiline.split('\\n')))]\n",
        "all_trades =  [generate_trade(row) for row in trade_rows]\n",
        "simulator = market_sim(1000000,all_trades)\n",
        "pprint(all_trades)\n",
        "for trade in all_trades:\n",
        "  simulator.simulate(trade)\n",
        "  \n",
        "  \n",
        "  \n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[datetime.date(2008, 12, 3), 'AAPL', 'BUY', 130],\n",
            " [datetime.date(2008, 12, 8), 'AAPL', 'SELL', 130],\n",
            " [datetime.date(2008, 12, 5), 'IBM', 'BUY', 50]]\n",
            "Updating with [datetime.date(2008, 12, 3), 'AAPL', 'BUY', 130]\n",
            "Updating Cash.....\n",
            "fetching AAPL price asOf:2008-12-03\n",
            "Fetching data for AAPL from:https://cloud.iexapis.com/stable/stock/AAPL/chart/date/20081203?token=sk_98e397d4bee940488e1f48e9b419508f&chartByDay=true\n",
            "==Updating Cash OBtianed:-1781.0 \n",
            "Updating with [datetime.date(2008, 12, 8), 'AAPL', 'SELL', 130]\n",
            "Appending:0 @2008-12-08\n",
            "Updating Cash.....\n",
            "fetching AAPL price asOf:2008-12-08\n",
            "Fetching data for AAPL from:https://cloud.iexapis.com/stable/stock/AAPL/chart/date/20081208?token=sk_98e397d4bee940488e1f48e9b419508f&chartByDay=true\n",
            "==Updating Cash OBtianed:1852.5 \n",
            "Updating with [datetime.date(2008, 12, 5), 'IBM', 'BUY', 50]\n",
            "Updating Cash.....\n",
            "fetching IBM price asOf:2008-12-05\n",
            "Fetching data for IBM from:https://cloud.iexapis.com/stable/stock/IBM/chart/date/20081205?token=sk_98e397d4bee940488e1f48e9b419508f&chartByDay=true\n",
            "==Updating Cash OBtianed:-4029.5 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXBOAX7mBvOR",
        "colab_type": "code",
        "outputId": "4b73f149-b8d5-4567-8ffc-0c5b1cd1d728",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# Checking simulator status...\n",
        "print ('------ STATUS---- ')\n",
        "for key, val in simulator.current_status().items():\n",
        "  print('------ {} ------'.format(key))\n",
        "  pprint(val)\n",
        "print('------ CASH -------')\n",
        "pprint(simulator.current_cash())"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------ STATUS---- \n",
            "------ IBM ------\n",
            "[('2008-12-05', 50)]\n",
            "------ AAPL ------\n",
            "[('2008-12-03', 130), ('2008-12-08', 0)]\n",
            "------ CASH -------\n",
            "[(datetime.date(2008, 12, 3), 998219.0),\n",
            " (datetime.date(2008, 12, 8), 1000071.5),\n",
            " (datetime.date(2008, 12, 5), 996042.0)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sU6S0B_Cfqa",
        "colab_type": "text"
      },
      "source": [
        "<h3>CheckingCash</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhZHPbZBCimh",
        "colab_type": "code",
        "outputId": "b3296d98-b181-4159-b0b0-b8630382ee0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(simulator.current_cash())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "996042.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3CAeAY0MiYs",
        "colab_type": "text"
      },
      "source": [
        "<h3>Perfecting the DateRange</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuftePn5RdOx",
        "colab_type": "code",
        "outputId": "1c40db8f-388d-4b7c-de69-1e8cd23e51da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "mapped_dates = map(lambda t: t[0], all_trades)\n",
        "sorted_dates = sorted(mapped_dates, key=lambda x:x)\n",
        "all_dates = find_date_range(sorted_dates)\n",
        "all_dates_df = pd.DataFrame(all_dates, columns=['AsOfDate'])\n",
        "\n",
        "\n",
        "def join_with_all_trades(ticker_items):\n",
        "  print('Creating Df for {}'.format(ticker_items))\n",
        "  symbol_df = pd.DataFrame(ticker_items, columns=['AsOfDate', 'Qty'])\n",
        "  joined = pd.merge(all_dates_df, symbol_df, on='AsOfDate', how='left')\n",
        "  # forward filling\n",
        "  updated =  joined.fillna(method='ffill')\n",
        "  # filling zeroes\n",
        "  return updated.fillna(0)\n",
        "  \n",
        "  \n",
        "all_dfs = [(k, join_with_all_trades(v)) for k,v in simulator.current_status().items()] \n",
        "\n",
        "\n",
        "\n",
        "for symbol, df  in all_dfs:\n",
        "  print('===={}====='.format(symbol))\n",
        "  print(df.head(20))\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#cash = pd.DataFrame(columns=['Cash'], index=date_range)\n",
        "#portfolio = pd.DataFrame(columns=tickers, index=date_range)\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating Df for [('2008-12-05', 50)]\n",
            "Creating Df for [('2008-12-03', 130), ('2008-12-08', 0)]\n",
            "====IBM=====\n",
            "     AsOfDate   Qty\n",
            "0  2008-12-03   0.0\n",
            "1  2008-12-04   0.0\n",
            "2  2008-12-05  50.0\n",
            "3  2008-12-08  50.0\n",
            "====AAPL=====\n",
            "     AsOfDate    Qty\n",
            "0  2008-12-03  130.0\n",
            "1  2008-12-04  130.0\n",
            "2  2008-12-05  130.0\n",
            "3  2008-12-08    0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxwTpcHVMnac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecsUQn0f6fnP",
        "colab_type": "text"
      },
      "source": [
        "<h3>Testing pandas datareader with alpha vantage to see if we can get at least some historical </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSkH5hZW6mhb",
        "colab_type": "code",
        "outputId": "47324959-4a00-41fa-fb15-991aa5109cd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sim = Simulator({}, 1000)\n",
        "sim.get_historical_price('RUSL', date(2019,4,2)).values[0][0]\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39.83000183105469"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5XbuQ_GANAz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}