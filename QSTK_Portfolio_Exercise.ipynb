{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QSTK-Portfolio-Exercise.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmistroni/TensorFlowPlayground/blob/master/QSTK_Portfolio_Exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAV3TDf5FAEX",
        "colab_type": "text"
      },
      "source": [
        "<h2>Installing required packages </h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rbx9S7UGG_WC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "0e0f6fda-230f-43ea-aa0e-e10d84980852"
      },
      "source": [
        "!pip install pandas-datareader"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas-datareader in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
            "Requirement already satisfied: pandas>=0.19.2 in /usr/local/lib/python3.6/dist-packages (from pandas-datareader) (0.24.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from pandas-datareader) (4.2.6)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from pandas-datareader) (2.21.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from pandas-datareader) (1.11.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->pandas-datareader) (1.16.4)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->pandas-datareader) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->pandas-datareader) (2018.9)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas-datareader) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas-datareader) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas-datareader) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas-datareader) (2019.3.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas>=0.19.2->pandas-datareader) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_WAe-pQHGvH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import urllib\n",
        "import json\n",
        "import pandas as pd\n",
        "from pandas.tseries.offsets import BDay\n",
        "import pandas_datareader.data as dr\n",
        "import numpy as np\n",
        "from datetime import datetime, date\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "from collections import OrderedDict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1sZg1w1IrbA",
        "colab_type": "text"
      },
      "source": [
        "<h3> Computing Sharpe Ratio and Returns </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7bhcaANIvGd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "logger = logging.getLogger(__name__)\n",
        "from math import sqrt\n",
        "\n",
        "def get_prices(ls_symbols, dt_start, dt_end):\n",
        "    dt_timeofday = dt.timedelta(hours=16)\n",
        "    ldt_timestamps = du.getNYSEdays(dt_start, dt_end, dt_timeofday)\n",
        "    #c_dataobj = da.DataAccess('Yahoo')\n",
        "    c_dataobj = da.DataAccess('Yahoo', cachestalltime=0)\n",
        "    ls_keys = ['close']\n",
        "    ldf_data = c_dataobj.get_data(ldt_timestamps, ls_symbols, ls_keys)\n",
        "    return  dict(zip(ls_keys, ldf_data)) # each field is returned as a single dataframe\n",
        "\n",
        "def compute_daily_returns(prices):\n",
        "    na_rets = prices.copy()\n",
        "    return tsu.returnize0(na_rets)\n",
        "\n",
        "def compute_standard_deviations(daily_returns):\n",
        "    return np.std(daily_returns)\n",
        "\n",
        "def normalize_prices(prices):\n",
        "    return prices / prices[0,:]\n",
        "\n",
        "def compute_sharpe_ratio(daily_returns, standard_dev):\n",
        "    \n",
        "    avg = np.average(daily_returns)# / len(daily_returns)\n",
        "    return (sqrt(252) * avg) / standard_dev"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HsGeVdiI572",
        "colab_type": "text"
      },
      "source": [
        "<h3> Compute Statistics </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YMinQF5I93Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "be990b2f-4beb-4e41-8c16-a7c7636f291d"
      },
      "source": [
        "import pandas as pd\n",
        "from pandas.tseries.offsets import BDay\n",
        "import pandas_datareader.data as dr\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "def get_closes(start, end, symbol):\n",
        "  return dr.DataReader(symbol, 'iex', start, end)['close']\n",
        "\n",
        "\n",
        "def compute_statistics(symbol, prices):\n",
        "  #prices = get_closes(start, end, symbol)\n",
        "  daily_returns = compute_daily_returns(prices)\n",
        "  std_dev  = compute_standard_deviations(daily_returns)\n",
        "  sharpe = compute_sharpe_ratio(daily_returns, std_dev)\n",
        "  total_returns = (prices[-1]*1.0 / prices[0]) -1\n",
        "  \n",
        "  \n",
        "  return {'std_dev' : std_dev,\n",
        "         'sharpe_ratio' : sharpe,\n",
        "         'total_returns' : total_returns,\n",
        "         'symbol': symbol}\n",
        "  \n",
        "\n",
        "end = pd.Timestamp(datetime.now())\n",
        "start = end - BDay(250)\n",
        "symbols =  ['NWVCF', 'TGIFF']\n",
        "           # ['MARA','DPW','TOPS','HAON','HTBX','IMNP','OPGN','SUZBY','ARCO','TRQ','ARTX','PDLI','ENPH','PLPL',\n",
        "           #'DNN','ZYNE','EYEG','FLKS','APHB','PHBI','ENDV']\n",
        "\n",
        "all_dicts = []\n",
        "for sym in symbols:\n",
        "  try:\n",
        "    all_dicts.append((sym, get_closes(start, end, sym)))#compute_statistics(start, end ,sym)) #compute_statistics(sym, start, end))\n",
        "  except Exception as e:\n",
        "    print('Unable to fetch statistics for %s:%s' % (sym, str(e)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unable to fetch statistics for NWVCF:Unable to read URL: https://api.iextrading.com/1.0/stock/market/batch?symbols=NWVCF&types=chart&range=1y\n",
            "Response Text:\n",
            "b'Forbidden'\n",
            "Unable to fetch statistics for TGIFF:Unable to read URL: https://api.iextrading.com/1.0/stock/market/batch?symbols=TGIFF&types=chart&range=1y\n",
            "Response Text:\n",
            "b'Forbidden'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukwXzHSnJbjU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "42dc1eed-4b85-468b-a91e-b6f617a47cf8"
      },
      "source": [
        "all_df = []\n",
        "for symbol, prices in all_dicts:\n",
        "  all_df.append(compute_statistics(symbol, prices))\n",
        "df = pd.DataFrame(all_df)[['symbol', 'total_returns','std_dev', 'sharpe_ratio']]\n",
        "df"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-e259df4cbcde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msymbol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprices\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mall_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_statistics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'symbol'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'total_returns'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'std_dev'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sharpe_ratio'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2932\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2933\u001b[0m             indexer = self.loc._convert_to_indexer(key, axis=1,\n\u001b[0;32m-> 2934\u001b[0;31m                                                    raise_missing=True)\n\u001b[0m\u001b[1;32m   2935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[1;32m   1352\u001b[0m                 kwargs = {'raise_missing': True if is_setter else\n\u001b[1;32m   1353\u001b[0m                           raise_missing}\n\u001b[0;32m-> 1354\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1355\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         self._validate_read_indexer(keyarr, indexer,\n\u001b[1;32m   1160\u001b[0m                                     \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m                                     raise_missing=raise_missing)\n\u001b[0m\u001b[1;32m   1162\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1244\u001b[0m                 raise KeyError(\n\u001b[1;32m   1245\u001b[0m                     u\"None of [{key}] are in the [{axis}]\".format(\n\u001b[0;32m-> 1246\u001b[0;31m                         key=key, axis=self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[1;32m   1247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m             \u001b[0;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['symbol', 'total_returns', 'std_dev', 'sharpe_ratio'], dtype='object')] are in the [columns]\""
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4p7Ht1mBJ1sQ",
        "colab_type": "text"
      },
      "source": [
        "<h3>Computing Future Earnings </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-qoX9qVJ5LA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import urllib\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def get_future_earnings_df(symbol):\n",
        "\n",
        "  base_url = 'https://us-central1-datascience-projects.cloudfunctions.net/future_earnings/{}'.format(symbol)\n",
        "  res = urllib.request.urlopen(base_url)\n",
        "  json_dict = res.read() #json.load(res)\n",
        "  try:\n",
        "    df = pd.read_json(json_dict)\n",
        "\n",
        "    cons  = df['Consensus'].values\n",
        "    fisc = df['Fiscal'].values\n",
        "    new_cols = ['T+{}'.format(idx) for idx in range(1, len(fisc) + 1)]\n",
        "    \n",
        "    converted = pd.DataFrame([cons], columns=fisc)\n",
        "    converted['symbol'] = symbol\n",
        "    return converted\n",
        "  except Exception as e:\n",
        "    print('exception in retrieving earnings for {}/{}'.format(symbol,str(e)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUu_VtImKQEN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "64e4f8b2-41f2-4e0b-c63a-3c40072cbd12"
      },
      "source": [
        "# Computing Earnings\n",
        "symbols = \"\"\"AAPL\n",
        "MSFT\n",
        "JNJ\n",
        "XOM\n",
        "JPM\n",
        "AMZN\n",
        "GOOGL\n",
        "T\n",
        "F\n",
        "CVX\n",
        "PG\n",
        "INTC\n",
        "PFE\n",
        "CSCO\n",
        "BRK.B\n",
        "GOOG\n",
        "VZ\n",
        "DIS\n",
        "HD\n",
        "PEP\n",
        "V\n",
        "SPY\n",
        "BAC\n",
        "MRK\n",
        "IBM\n",
        "GE\n",
        "WFC\n",
        "ABBV\n",
        "KO\n",
        "BA\n",
        "\"\"\".split('\\n')\n",
        "\n",
        "all_dfs = [get_future_earnings_df(symbol) for symbol in symbols]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "exception in retrieving earnings for SPY/'Consensus'\n",
            "exception in retrieving earnings for /'Consensus'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8e6GDRBKY3y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "good_ones = filter(lambda df: df is not None, all_dfs)\n",
        "\n",
        "min_shape = min(map(lambda df: df.shape[1], good_ones))\n",
        "col_to_project = good_ones[0].columns[0:min_shape]\n",
        "\n",
        "print ('Cols to project:{}'.format(col_to_project))\n",
        "\n",
        "\n",
        "reduced_df = reduce(lambda acc, item: item if acc is None else acc.append(item), good_ones, None)\n",
        "\n",
        "reduced_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSJPKY_0KsSR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "merged= pd.merge(df, reduced_df, how='left', on='symbol')\n",
        "\n",
        "merged\n",
        "\n",
        "# SAving to csv file\n",
        "merged.to_csv('/tmp/results.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEuH36sqK0BZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d6ce99b3-266b-49ce-f65b-1ae9de9804bd"
      },
      "source": [
        "# checking the file is there\n",
        "!cat /tmp/results.csv"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cat: /tmp/results.csv: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "empQA9NAK-IP",
        "colab_type": "text"
      },
      "source": [
        "<h3> Computing Moving Average </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qo7SKmFiLF_g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "d7131c30-1274-40d6-c7c4-029c41ce8d6e"
      },
      "source": [
        "import pandas as pd\n",
        "from datetime import date, datetime\n",
        "end = pd.Timestamp(datetime.now())\n",
        "start = end - BDay(250)\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def get_data(start, end, symbol):\n",
        "  return dr.DataReader(symbol, 'iex', start, end)['close']\n",
        "\n",
        "\n",
        "def compute_avg(prices):\n",
        "  mapped = map(lambda tpl: tpl[1], prices)\n",
        "  return np.average(mapped) if prices else 0.0\n",
        "\n",
        "\n",
        "def compute_moving_avg(prices, days):\n",
        "  res = [(prices[i][0], prices[i][1],  compute_avg(prices[i-days:i])) for i in range(0, len(prices))]\n",
        "  return res\n",
        "  \n",
        "  \n",
        "\n",
        "end = pd.Timestamp(datetime.now())\n",
        "start = end - BDay(400)  \n",
        "res =get_data(start, end, 'AMZN')  \n",
        "\n",
        "all_data = zip(res.index, res)\n",
        "\n",
        "result = compute_moving_avg(all_data, 200)\n",
        "\n",
        "dr.DataReader('AMZN', 'iex', date(2019,1,14), date(2019,1,23))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RemoteDataError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRemoteDataError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-bb29a868c4c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mBDay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'AMZN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mall_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-bb29a868c4c0>\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(start, end, symbol)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mdr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'iex'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'close'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas_datareader/data.py\u001b[0m in \u001b[0;36mDataReader\u001b[0;34m(name, data_source, start, end, retry_count, pause, session, access_key)\u001b[0m\n\u001b[1;32m    320\u001b[0m                               \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                               \u001b[0mretry_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpause\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m                               session=session).read()\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdata_source\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"iex-tops\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas_datareader/iex/daily.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             return self._read_one_data(self.url,\n\u001b[0;32m---> 91\u001b[0;31m                                        self._get_params(self.symbols))\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas_datareader/base.py\u001b[0m in \u001b[0;36m_read_one_data\u001b[0;34m(self, url, params)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;34m\"\"\" read one data from specified URL \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'string'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_url_as_StringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'json'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas_datareader/base.py\u001b[0m in \u001b[0;36m_read_url_as_StringIO\u001b[0;34m(self, url, params)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mOpen\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mand\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \"\"\"\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas_datareader/base.py\u001b[0m in \u001b[0;36m_get_response\u001b[0;34m(self, url, params, headers)\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'\\nResponse Text:\\n{0}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_response_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRemoteDataError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_crumb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRemoteDataError\u001b[0m: Unable to read URL: https://api.iextrading.com/1.0/stock/market/batch?symbols=AMZN&types=chart&range=2y\nResponse Text:\nb'Forbidden'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C32FH54kLXJ0",
        "colab_type": "text"
      },
      "source": [
        "<h3> Creating Market Simulator </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENxDiNhbLbnk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "from datetime import date, datetime\n",
        "from pandas.tseries.offsets import BDay\n",
        "import pandas as pd\n",
        "import logging\n",
        "from pprint import pprint\n",
        "\n",
        "multiline = \\\n",
        "\"\"\"\n",
        "2008-12-03,AAPL,BUY,130\n",
        "2008-12-08,AAPL,SELL,130\n",
        "2008-12-05,IBM,BUY,50\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "class Simulator:\n",
        "  def __init__(self, ticker_dict, initial_cash):\n",
        "    self.ticker_dict = ticker_dict\n",
        "    self.initial_cash = initial_cash\n",
        "    \n",
        "  def simulate(self, trade):\n",
        "    print('Updating with {}'.format(trade))\n",
        "    as_of_dt, ticker, order_type, qty = trade\n",
        "    current_status = self.ticker_dict[ticker] # a listof (asofdate, qty)\n",
        "    market_qty = qty if order_type == 'BUY' else -qty\n",
        "    if not current_status:\n",
        "      current_status.append((as_of_dt.strftime('%Y-%m-%d'), qty ))\n",
        "    else:\n",
        "      prev_dt, prev_qty = current_status[-1]\n",
        "      new_qty = prev_qty + market_qty\n",
        "      print('Appending:{} @{}'.format(new_qty, as_of_dt))\n",
        "      current_status.append((as_of_dt.strftime('%Y-%m-%d'), prev_qty + market_qty))\n",
        "    \n",
        "  def current_status(self):\n",
        "    return self.ticker_dict\n",
        "\n",
        "def parse_line(line):\n",
        "  raw_data = line.split(',')\n",
        "  return Order(raw_data)\n",
        "\n",
        "def find_all_tickers(orders):\n",
        "  return set(map(lambda t: t[1], orders))  \n",
        "\n",
        "def find_date_range(dates):\n",
        "  ts = pd.bdate_range(dates[0], dates[-1])\n",
        "  return [d for d in map(lambda t: t.date().strftime('%Y-%m-%d'), ts)]\n",
        "\n",
        "def generate_trade(row):\n",
        "  asOfDate, ticker, orderType, qty = row.split(',')\n",
        "    \n",
        "  return [datetime.strptime(asOfDate, \"%Y-%m-%d\").date(),\n",
        "            ticker, orderType, int(qty)]\n",
        "    \n",
        "def market_sim(initial_cash, orders):\n",
        "  trades = sorted(orders, key=lambda t: t[0])\n",
        "  tickers = find_all_tickers(trades)\n",
        "  symbols_dict = OrderedDict()\n",
        "  for ticker in tickers:\n",
        "    symbols_dict[ticker] = []\n",
        "  \n",
        "  return Simulator(symbols_dict, initial_cash)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsfuYc_TUfWI",
        "colab_type": "text"
      },
      "source": [
        "<h3> Running Simulator </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kt27O4DeLvn4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "c3e7e728-8d63-465b-872f-f7b0ed11d704"
      },
      "source": [
        "\n",
        "trade_rows  = [t for t in filter(lambda row:bool(row), map(lambda row: row.strip(), multiline.split('\\n')))]\n",
        "all_trades =  [generate_trade(row) for row in trade_rows]\n",
        "simulator = market_sim(1000000,all_trades)\n",
        "pprint(all_trades)\n",
        "for trade in all_trades:\n",
        "  simulator.simulate(trade)\n",
        "  \n",
        "  \n",
        "print ('------ STATUS---- ')\n",
        "for key, val in simulator.current_status().items():\n",
        "  print('------ {} ------'.format(key))\n",
        "  pprint(val)\n",
        "  \n",
        "\n"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[datetime.date(2008, 12, 3), 'AAPL', 'BUY', 130],\n",
            " [datetime.date(2008, 12, 8), 'AAPL', 'SELL', 130],\n",
            " [datetime.date(2008, 12, 5), 'IBM', 'BUY', 50]]\n",
            "Updating with [datetime.date(2008, 12, 3), 'AAPL', 'BUY', 130]\n",
            "Updating with [datetime.date(2008, 12, 8), 'AAPL', 'SELL', 130]\n",
            "Appending:0 @2008-12-08\n",
            "Updating with [datetime.date(2008, 12, 5), 'IBM', 'BUY', 50]\n",
            "------ STATUS---- \n",
            "------ AAPL ------\n",
            "[('2008-12-03', 130), ('2008-12-08', 0)]\n",
            "------ IBM ------\n",
            "[('2008-12-05', 50)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3CAeAY0MiYs",
        "colab_type": "text"
      },
      "source": [
        "<h3>Perfecting the DateRange</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuftePn5RdOx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "d5f7a0b4-0c07-4b9f-f8f9-62d533d15ebd"
      },
      "source": [
        "mapped_dates = map(lambda t: t[0], all_trades)\n",
        "sorted_dates = sorted(mapped_dates, key=lambda x:x)\n",
        "all_dates = find_date_range(sorted_dates)\n",
        "all_dates_df = pd.DataFrame(all_dates, columns=['AsOfDate'])\n",
        "\n",
        "\n",
        "def join_with_all_trades(ticker_items):\n",
        "  print('Creating Df for {}'.format(ticker_items))\n",
        "  symbol_df = pd.DataFrame(ticker_items, columns=['AsOfDate', 'Qty'])\n",
        "  joined = pd.merge(all_dates_df, symbol_df, on='AsOfDate', how='left')\n",
        "  # forward filling\n",
        "  updated =  joined.fillna(method='ffill')\n",
        "  # filling zeroes\n",
        "  return updated.fillna(0)\n",
        "  \n",
        "  \n",
        "all_dfs = [(k, join_with_all_trades(v)) for k,v in simulator.current_status().items()] \n",
        "\n",
        "\n",
        "\n",
        "for symbol, df  in all_dfs:\n",
        "  print('===={}====='.format(symbol))\n",
        "  print(df.head(20))\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#cash = pd.DataFrame(columns=['Cash'], index=date_range)\n",
        "#portfolio = pd.DataFrame(columns=tickers, index=date_range)\n"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating Df for [('2008-12-03', 130), ('2008-12-08', 0)]\n",
            "Creating Df for [('2008-12-05', 50)]\n",
            "====AAPL=====\n",
            "     AsOfDate    Qty\n",
            "0  2008-12-03  130.0\n",
            "1  2008-12-04  130.0\n",
            "2  2008-12-05  130.0\n",
            "3  2008-12-08    0.0\n",
            "====IBM=====\n",
            "     AsOfDate   Qty\n",
            "0  2008-12-03   0.0\n",
            "1  2008-12-04   0.0\n",
            "2  2008-12-05  50.0\n",
            "3  2008-12-08  50.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxwTpcHVMnac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}