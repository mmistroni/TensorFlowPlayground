{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PySpark Colab Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmistroni/TensorFlowPlayground/blob/master/PySpark_Colab_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRJN0dtZbgz3",
        "colab_type": "text"
      },
      "source": [
        "<h3> Installing dependencies</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRWUxU4Lblvd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://www-us.apache.org/dist/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34P4-gJmb86W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5zynArKcC90",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QWU5g5fcK_P",
        "colab_type": "text"
      },
      "source": [
        "<p> ToDO test few runs here, then  store a dataframe of all possible shares for last 2 years and run a correlation between all cols </b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJ24WhRrcGV1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use this link to calculate correlation https://stackoverflow.com/questions/45112976/how-to-use-correlation-in-spark-with-dataframes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IATQYipBerJt",
        "colab_type": "code",
        "outputId": "398a6948-91b2-4ffc-a237-aac690eb0982",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "!pip install pandas-datareader"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas-datareader in /usr/local/lib/python3.6/dist-packages (0.7.4)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from pandas-datareader) (2.21.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from pandas-datareader) (1.11.2)\n",
            "Requirement already satisfied: pandas>=0.19.2 in /usr/local/lib/python3.6/dist-packages (from pandas-datareader) (0.24.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from pandas-datareader) (4.2.6)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas-datareader) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas-datareader) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas-datareader) (2019.6.16)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas-datareader) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->pandas-datareader) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->pandas-datareader) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->pandas-datareader) (1.16.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas>=0.19.2->pandas-datareader) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tX6pv8n_XEAV",
        "colab_type": "text"
      },
      "source": [
        "<h3>Getting IEXApi Token </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HevGu1mIXHQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_iexapi_keys():\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')\n",
        "  with open('gdrive/My Drive/passwords/iexapi.keys') as f:\n",
        "    return f.readlines()[0]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igiM3aVKx70z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "45b6ede6-dbec-429b-9dcd-43d047d3b7b3"
      },
      "source": [
        "import requests\n",
        "import pandas_datareader.data as dr\n",
        "import pandas as pd\n",
        "from datetime import date\n",
        "\n",
        "iexapi_token = get_iexapi_keys()\n",
        "\n",
        "\n",
        "def get_historical_value(symbol):\n",
        "  try: \n",
        "    data = dr.get_data_yahoo(symbol, date(2018,1,1), date(2019,9,19))[['Adj Close']]\n",
        "    return data.rename(columns={'Adj Close' : symbol})\n",
        "    \n",
        "  except Exception as e :\n",
        "    print('Exception for {}={}'.format(symbol, str(e)))\n",
        "    return pd.DataFrame(columns=[symbol])\n",
        "  \n",
        "def get_all_symbols():\n",
        "  all_symbols_data = requests.get('https://cloud.iexapis.com/stable/ref-data/iex/symbols?token={}'.format(iexapi_token)).json()\n",
        "  good_ones = [d['symbol'] for d in all_symbols_data if d['isEnabled']]\n",
        "  return filter(lambda data: bool(data), good_ones)\n",
        "\n",
        "def get_all_etfs():\n",
        "  nyse_symbols = requests.get('https://cloud.iexapis.com/stable/ref-data/exchange/nys/symbols?token={}'.format(iexapi_token)).json()\n",
        "  nas_symbols = requests.get('https://cloud.iexapis.com/stable/ref-data/exchange/nas/symbols?token={}'.format(iexapi_token)).json()\n",
        "  return [d['symbol'] for d in nyse_symbols + nas_symbols if d['type'].lower() == 'et']\n",
        "\n",
        "def get_all_stocks_data():\n",
        "  all_symbols_data =  get_all_etfs()\n",
        "  return map(lambda symbol: get_historical_value(symbol), all_symbols_data)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWphjX7eX0WZ",
        "colab_type": "text"
      },
      "source": [
        "<h3> Comparing shares correlation with VIX via Pandas and Spark </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnaolPCRyWrs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vix = get_historical_value('^VIX')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XL7HqxzP-dZT",
        "colab_type": "code",
        "outputId": "051ff670-4c73-465f-a8c3-854b4b911b6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "\n",
        "all_stocks  = get_all_stocks_data()\n",
        "\n",
        "res= [vals for vals in all_stocks if vals.shape[0] == vix.shape[0]]\n",
        "res.append(vix)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exception for BSML='Date'\n",
            "Exception for BSMM='Date'\n",
            "Exception for BSMN='Date'\n",
            "Exception for BSMO='Date'\n",
            "Exception for BSMP='Date'\n",
            "Exception for BSMQ='Date'\n",
            "Exception for BSMR='Date'\n",
            "Exception for BSMS='Date'\n",
            "Exception for BSMT='Date'\n",
            "Exception for BUG='Date'\n",
            "Exception for GXTG='Date'\n",
            "Exception for HERO='Date'\n",
            "Exception for POTX='Date'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnGqWPHr9z-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# building pandas df\n",
        "all_data = pd.concat(res, axis=1)\n",
        "spark_df = spark.createDataFrame(all_data)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CcinG0yyiUq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_correlation(df):\n",
        "  from pyspark.ml.stat import Correlation\n",
        "  from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "  # convert to vector column first\n",
        "  vector_col = \"corr_features\"\n",
        "  assembler = VectorAssembler(inputCols=df.columns, outputCol=vector_col)\n",
        "  df_vector = assembler.transform(df).select(vector_col)\n",
        "\n",
        "  # get correlation matrix\n",
        "  matrix = Correlation.corr(df_vector, vector_col)\n",
        "  return matrix\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8XLi0FFymx3",
        "colab_type": "code",
        "outputId": "c528ecd1-3c89-4c5c-da08-818913739e9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "columns = spark_df.columns\n",
        "matrix = calculate_correlation(spark_df)\n",
        "matrix.toPandas()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pearson(corr_features)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DenseMatrix([[ 1.        ,  0.43882321,  0.462...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              pearson(corr_features)\n",
              "0  DenseMatrix([[ 1.        ,  0.43882321,  0.462..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvdOxxxLzEAr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert to numpy\n",
        "np_array = matrix.collect()[0][\"pearson({})\".format(\"corr_features\")].toArray()\n",
        "np_array.shape\n",
        "\n",
        "vix_row = np_array[-1:].tolist()[0]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5o8T42pKb1b",
        "colab_type": "code",
        "outputId": "bfb23415-320b-4f27-dfca-30e89ae98b25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "zipped = zip(columns, vix_row)\n",
        "\n",
        "sorted_zip = sorted(zipped, key=lambda tpl:tpl[1], reverse=True)\n",
        "from pprint import pprint\n",
        "pprint(list(sorted_zip)[0:10])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('^VIX', 1.0),\n",
            " ('VIIX', 0.6989994873731028),\n",
            " ('BIS', 0.6202776283699959),\n",
            " ('TVIX', 0.5295657060891832),\n",
            " ('ZBIO', 0.5289476059509456),\n",
            " ('SQQQ', 0.4079530575140182),\n",
            " ('FBZ', 0.12024673536202132),\n",
            " ('EWZS', 0.10604274352221688),\n",
            " ('ISHG', 0.06555273327793446),\n",
            " ('DSLV', 0.06500897256669277)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g45i6smez4_x",
        "colab_type": "code",
        "outputId": "8c1a31a7-d31f-4417-b57d-b4b03ef565ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "df = spark.createDataFrame(data, [\"features\"])\n",
        "\n",
        "r1 = Correlation.corr(df, \"features\").head()\n",
        "print(\"Pearson correlation matrix:\\n\" + str(r1[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pearson correlation matrix:\n",
            "DenseMatrix([[1.        , 0.99963975, 0.99955352, ..., 0.8438303 , 0.84639914,\n",
            "              0.84762431],\n",
            "             [0.99963975, 1.        , 0.99974304, ..., 0.85282955, 0.8553397 ,\n",
            "              0.85659553],\n",
            "             [0.99955352, 0.99974304, 1.        , ..., 0.85123163, 0.85352329,\n",
            "              0.85473836],\n",
            "             ...,\n",
            "             [0.8438303 , 0.85282955, 0.85123163, ..., 1.        , 0.9998867 ,\n",
            "              0.99979739],\n",
            "             [0.84639914, 0.8553397 , 0.85352329, ..., 0.9998867 , 1.        ,\n",
            "              0.99993591],\n",
            "             [0.84762431, 0.85659553, 0.85473836, ..., 0.99979739, 0.99993591,\n",
            "              1.        ]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhR1VTOt0uat",
        "colab_type": "text"
      },
      "source": [
        "<h3> Alternative approach via RDD </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cjtiCOS1ErF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_historical_value_df(symbol):\n",
        "  try: \n",
        "    data = dr.get_data_yahoo(symbol, date(2018,1,1), date(2019,9,19))[['Adj Close']]\n",
        "    pandas_df = data.rename(columns={'Adj Close' : 'adj_close'})['adj_close']\n",
        "    return spark.createDataFrame(pandas_df, FloatType())\n",
        "    \n",
        "  except Exception as e :\n",
        "    print('Excepiton for {}:{}'.format(symbol, str(e)))\n",
        "    return []\n",
        "\n",
        "def calculate_correlation(df1, df2, field1, field2)\n",
        "  firstRDD = df1.select(\"adj_close\").map(lambda r: row.getDouble(0))\n",
        "  val secondRDD: RDD[Double] = yourDF.select(\"field2\").map(row => row.getDouble(0))\n",
        "  val corr = Statistics.corr(firstRDD, secondRDD, \"spearman\")  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nAsl25T1Rhs",
        "colab_type": "code",
        "outputId": "41de0421-48a3-4665-86ce-b0ab72dd2583",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "vix = get_historical_value_df('^VIX')\n",
        "\n",
        "vals = [x for x in map(lambda r: r.asDict(), vix)]\n",
        "from pprint import pprint\n",
        "vals\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-b7a2b00f1e7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_historical_value_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'^VIX'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpprint\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-50-b7a2b00f1e7c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_historical_value_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'^VIX'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpprint\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-50-b7a2b00f1e7c>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(r)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_historical_value_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'^VIX'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpprint\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'Column' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzYf7ea70SQe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}