{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StockAndNewsAPIs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmistroni/TensorFlowPlayground/blob/master/StockAndNewsAPIs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9xnZo-xamUy",
        "colab_type": "code",
        "outputId": "fb0c8aeb-53a3-4131-bb09-bd00a3943ead",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "\n",
        "!pip install pandas-datareader"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas-datareader in /usr/local/lib/python3.6/dist-packages (0.7.4)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from pandas-datareader) (1.11.2)\n",
            "Requirement already satisfied: pandas>=0.19.2 in /usr/local/lib/python3.6/dist-packages (from pandas-datareader) (0.25.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from pandas-datareader) (4.2.6)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from pandas-datareader) (2.21.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->pandas-datareader) (2.6.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->pandas-datareader) (1.17.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->pandas-datareader) (2018.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas-datareader) (2019.9.11)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas-datareader) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas-datareader) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas-datareader) (3.0.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.19.2->pandas-datareader) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giosOkpiMPyt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEJyyYSJaraF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import urllib\n",
        "import json\n",
        "import pandas as pd\n",
        "from pandas.tseries.offsets import BDay\n",
        "import pandas_datareader.data as dr\n",
        "import numpy as np\n",
        "from datetime import datetime, date\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqrFVyKPlrdX",
        "colab_type": "text"
      },
      "source": [
        "<h2>Authenticate User </h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXM3PKNDlvaf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNzEi-rVkF26",
        "colab_type": "text"
      },
      "source": [
        "<h3> Loading Nasdaq and Nyse shares </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuM-PON2bLKH",
        "colab_type": "code",
        "outputId": "a7c2e674-585a-4a60-8f9b-091ea810e3db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!gsutil cp gs://datascience-bucket-mm/nyse-companylist.csv /tmp/nyse.csv\n",
        "!gsutil cp gs://datascience-bucket-mm/nasdaq-companylist.csv /tmp/nyse.csv  \n",
        "  \n",
        "# Print the result to make sure the transfer worked.\n",
        "#!cat /tmp/nyse.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://datascience-bucket-mm/nyse-companylist.csv...\n",
            "/ [1 files][392.3 KiB/392.3 KiB]                                                \n",
            "Operation completed over 1 objects/392.3 KiB.                                    \n",
            "Copying gs://datascience-bucket-mm/nasdaq-companylist.csv...\n",
            "/ [1 files][462.5 KiB/462.5 KiB]                                                \n",
            "Operation completed over 1 objects/462.5 KiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2XGV6H1qGF6",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "<h3>Loading Credentials</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lU0JmFUBNRkR",
        "colab_type": "code",
        "outputId": "e13b2800-3e82-43d7-9352-7d5cfbfe99fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "def get_iexapi_keys():\n",
        "  with open('gdrive/My Drive/passwords/iexapi.keys') as f:\n",
        "    return f.readlines()[0]\n",
        "\n",
        "def get_nlp_service_keys():\n",
        "  with open('gdrive/My Drive/passwords/nlp.keys') as f:\n",
        "    return f.readlines()[0]\n",
        "\n",
        "def get_newsapi_keys():\n",
        "  with open('gdrive/My Drive/passwords/newsapi.keys') as f:\n",
        "    return f.readlines()[0]\n",
        "\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kx2JKDUVNdlh",
        "colab_type": "text"
      },
      "source": [
        "<h3>IEX API CALLS </h3>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e18EfrivqJ_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "\n",
        "token = get_iexapi_keys()\n",
        "\n",
        "def get_statistics(ticker):\n",
        "  base_url = 'https://cloud.iexapis.com/stable/stock/{symbol}/stats?token={token}&format=csv&filter=companyName,symbol,beta,day50MovingAvg,day200MovingAvg,month6ChangePercent,month3ChangePercent,month1ChangePercent'.format(token=token,symbol=ticker)\n",
        "  df = pd.read_csv(base_url)\n",
        "  df['Symbol'] = ticker\n",
        "  return df\n",
        "\n",
        "def get_historical_data(ticker, start, end):\n",
        "  df = get_statistics(ticker)\n",
        "  return df\n",
        "\n",
        "\n",
        "def get_all_stocks():\n",
        "  all_symbols_data = requests.get('https://cloud.iexapis.com/stable/ref-data/iex/symbols?token={token}'.format(token=token)).json()\n",
        "  return [d['symbol'] for d in all_symbols_data if d['isEnabled']and d['type'].lower() == 'cs']\n",
        "\n",
        "def get_all_us_stocks(security_type='cs'):\n",
        "  nyse_symbols = requests.get('https://cloud.iexapis.com/stable/ref-data/exchange/nys/symbols?token={token}'.format(token=token)).json()\n",
        "  #nas_symbols = requests.get('https://cloud.iexapis.com/stable/ref-data/exchange/nas/symbols?token={token}'.format(token=token)).json()\n",
        "  return [d['symbol'] for d in nyse_symbols  if d['type'].lower() == security_type]\n",
        "\n",
        "def get_all_etfs():\n",
        "  stocks= get_all_us_stocks()\n",
        "  return [d['symbol'] for d in stocks if d['type'].lower() == 'et']\n",
        "\n",
        "def get_all_stocks_data():\n",
        "  good_ones = get_all_etfs()\n",
        "  return map(lambda symbol: (symbol, get_historical_value(symbol)), good_ones)\n",
        "\n",
        "\n",
        "def get_all_exchanges():\n",
        "  return requests.get('https://cloud.iexapis.com/stable/ref-data/market/us/exchanges?token={token}'.format(token=token)).json()\n",
        "\n",
        "def get_latest_price(symbol):\n",
        "  base_url = \"https://cloud.iexapis.com/stable/stock/{ticker}/quote?token={token}&format=csv&filter=symbol,close\".format(token=token,ticker=symbol)\n",
        "  import requests\n",
        "  return pd.read_csv(base_url)\n",
        "\n",
        "def get_quote(symbol):\n",
        "  try:\n",
        "    historical_url = 'https://cloud.iexapis.com/stable/stock/{symbol}/quote/latestPrice?token={token}'.format(token=token,symbol=symbol)\n",
        "    return requests.get(historical_url).json()\n",
        "  except:\n",
        "    return -1\n",
        "\n",
        "def get_news(symbol, num_of_news):\n",
        "  try:\n",
        "    news_url = 'https://cloud.iexapis.com/stable//stock/{symbol}/news/last/{last}?token={token}'.format(symbol=symbol, last=num_of_news,\n",
        "                                                                                                        token=token)\n",
        "    return requests.get(news_url).json()\n",
        "  except Exception as e :\n",
        "    print('Excepiton for {}:{}'.format(symbol, str(e)))\n",
        "    return []\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzqkOp1BsG7g",
        "colab_type": "text"
      },
      "source": [
        "<h3> Yahoo API Calls </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bNDGbCNbX6Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.stats import pearsonr\n",
        "import requests\n",
        "\n",
        "def get_latest_price_yahoo(symbol, as_of_date):\n",
        "  try:\n",
        "    return dr.get_data_yahoo(symbol, as_of_date, as_of_date)[['Close']]\n",
        "  except Exception as e :\n",
        "    return pd.DataFrame(columns=['Close'])[['Close']]\n",
        "\n",
        "def get_historical_value(symbol):\n",
        "  try: \n",
        "    data = dr.get_data_yahoo(symbol, date(2018,1,1), date(2019,9,19))[['Adj Close']]\n",
        "    df =  data.rename(columns={'Adj Close' : symbol})\n",
        "    return df\n",
        "  except Exception as e :\n",
        "    return pd.DataFrame(columns=[symbol])   \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lVNnbmlOiUe",
        "colab_type": "text"
      },
      "source": [
        "<h3> Getting Sentiment Analysis from Google </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCwPBOkWsapp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_sentiment_from_google(content):\n",
        "  from google.cloud import language\n",
        "  from google.cloud.language import enums\n",
        "  from google.cloud.language import types\n",
        "\n",
        "  client = language.LanguageServiceClient()\n",
        "  document = types.Document(\n",
        "      content=clean_text,\n",
        "      type=enums.Document.Type.PLAIN_TEXT)\n",
        "\n",
        "  # Detects the sentiment of the text\n",
        "  sentiment = client.analyze_sentiment(document=document).document_sentiment\n",
        "\n",
        "def test_language_api(content):\n",
        "  import httplib2\n",
        "  import sys\n",
        "  from googleapiclient import discovery\n",
        "  from googleapiclient.errors import HttpError\n",
        "\n",
        "  discovery_url = 'https://{api}.googleapis.com/$discovery/rest?version={apiVersion}'\n",
        "\n",
        "  service = discovery.build(\n",
        "      'language', 'v1',\n",
        "      http=httplib2.Http(),\n",
        "      discoveryServiceUrl=discovery_url,\n",
        "      developerKey=get_nlp_service_keys(),\n",
        "  )\n",
        "  service_request = service.documents().annotateText(\n",
        "      body={\n",
        "          'document': {\n",
        "              'type': 'PLAIN_TEXT',\n",
        "              'content': content,\n",
        "          },\n",
        "          'features': {\n",
        "              'extract_syntax': True,\n",
        "              'extractEntities': True,\n",
        "              'extractDocumentSentiment': True,\n",
        "          },\n",
        "          'encodingType': 'UTF16' if sys.maxunicode == 65535 else 'UTF32',\n",
        "      })\n",
        "  try:\n",
        "      response = service_request.execute()\n",
        "  except HttpError as e:\n",
        "      response = {'error': e}\n",
        "  return response\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXSJQ73Am2dC",
        "colab_type": "text"
      },
      "source": [
        "<h3> Reading source data and computing performance </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euF2kHI-n4qf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_date_ranges():\n",
        "  end_date = date.today()\n",
        "  start_date = end_date - BDay(60)\n",
        "  return start_date, end_date\n",
        "\n",
        "def test():\n",
        "  start,end = get_date_ranges()\n",
        "  print('start:{}, end:{}'.format(start_date, end_date))\n",
        "  print(get_historical_data('AMZN', start_date, end_date))\n",
        "  \n",
        "\n",
        "  \n",
        "def get_nyse_df():\n",
        "  return pd.read_csv('/tmp/nyse.csv', header=0)[['Symbol', 'Name', 'Sector', 'industry']]\n",
        "\n",
        "def compute_performance(start_dt, end_dt, ticker):\n",
        "  try:\n",
        "    import time\n",
        "    historical_df =  get_historical_data(ticker, start_dt, end_dt)\n",
        "    latest_df = get_latest_price(ticker)\n",
        "    merged = pd.merge(historical_df, latest_df, how='inner' , left_on=\"Symbol\", right_on=\"symbol\").drop('symbol', axis=1)\n",
        "    return merged\n",
        "  except Exception as e:\n",
        "    print('Exception:{}'.format(str(e)))\n",
        "    print('Unable to find data for {}:{}'.format(ticker,str(e)))\n",
        "    \n",
        "def find_best_performing(start_dt, end_dt):\n",
        "  print('Finding Best Performing Stocks between:{}-{}'.format(start_dt, end_dt))\n",
        "  nyse_df = get_nyse_df()\n",
        "  symbols = nyse_df['Symbol'].values.tolist()\n",
        "  print('Now we have to source data for:{}'.format(len(symbols)))\n",
        "  dfs = (compute_performance(start_dt, end_dt, symbol) for symbol in symbols)\n",
        "  filtered = (df for df in dfs if df is not None)\n",
        "  all_data = pd.concat(filtered)\n",
        "  return pd.merge(nyse_df, all_data, how='inner', on='Symbol' )[['Symbol', 'Name', 'Sector', 'industry', 'companyName','close', \n",
        "       'month1ChangePercent','month3ChangePercent', 'month6ChangePercent',  'day200MovingAvg', 'day50MovingAvg']]\n",
        "\n",
        "  \n",
        "\n",
        "start_dt, end_dt = get_date_ranges()\n",
        "perf_df = find_best_performing(start_dt, end_dt)\n",
        "# Sorting \n",
        "perf_df.sort_values(by=['month1ChangePercent'], inplace=True, ascending=False)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEBMn4Zlkjgf",
        "colab_type": "text"
      },
      "source": [
        "<h3> Group by sector, to find best performers </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BrXBHSsqa9f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res = perf_df[['industry', 'month1ChangePercent','month3ChangePercent', ]].groupby(['industry']).mean().sort_values(by=['month1ChangePercent','month1ChangePercent'], ascending=False)\n",
        "res.head(20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNrTkBIcADGb",
        "colab_type": "text"
      },
      "source": [
        "<p> Testing all stocks in portfolio </p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oildRTtsAIh5",
        "colab_type": "code",
        "outputId": "c04e1905-1c5d-4adb-8a36-8d6d94b48dc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "portfolio_shares = ['ADAC', 'AMBS', 'AMZN', 'AZFL', 'ARSC', 'AAPL', 'APTY',\n",
        "                    'BTCS', 'BRK-B', 'CRNT', 'CRLBF', 'XOM', 'HAON', 'AGEEF',\n",
        "                    'HMNY', 'JNJ', 'LEMIF', 'NXTTF', 'NVCN', 'RNVA', 'TORC',\n",
        "                    'RTRX', 'VALE', 'VZ', 'DGP', 'RUSL', 'REMX', 'TVIX' ]\n",
        "\n",
        "all_shares = get_all_stocks()\n",
        "res = map(lambda symbol:(symbol, symbol in all_shares), shares)\n",
        "invalid = [tpl for tpl in res if not tpl[1]]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "JSONDecodeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-9da56f1dcf79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                     'RTRX', 'VALE', 'VZ', 'DGP', 'RUSL', 'REMX', 'TVIX' ]\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mall_shares\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_all_stocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0msymbol\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_shares\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshares\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtpl\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtpl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtpl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-4e3d56bc2d02>\u001b[0m in \u001b[0;36mget_all_stocks\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_all_stocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0mall_symbols_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://cloud.iexapis.com/stable/ref-data/iex/symbols?token={token}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'symbol'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_symbols_data\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'isEnabled'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;32mand\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mjson\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    895\u001b[0m                     \u001b[0;31m# used.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcomplexjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \"\"\"\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TT-4mE-grwDa",
        "colab_type": "text"
      },
      "source": [
        "<h3> Performance Functions </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksISPaesqPEy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_correlation_all(vix, all_stocks):\n",
        "  all_df = [vix]\n",
        "  res= [vals for _, vals in all_stocks if vals.shape[0] == vix_vals.shape[0]]\n",
        "  res.append(vix)\n",
        "  all_data = pd.concat(res, axis=1)\n",
        "  return all_data.corr('pearson')\n",
        "\n",
        "def calculate_portfolio_correlation(all_stocks):\n",
        "  res= [vals for _, vals in all_stocks if vals.shape[0] > 2]\n",
        "  all_data = pd.concat(res, axis=1)\n",
        "  return all_data.corr('pearson')\n",
        "\n",
        "\n",
        "def calculate_correlation(vix, all_stocks):\n",
        "  result = []\n",
        "  best = 0\n",
        "  for symbol, vals in all_stocks:\n",
        "    if vals.shape[0] == vix.shape[0]:\n",
        "      concats  = pd.concat([vix, vals], axis = 1)\n",
        "      corr_matrix = concats.corr(method='pearson')\n",
        "      corr_with_vix = corr_matrix.loc['^VIX'][1]\n",
        "      if corr_with_vix > 0 and corr_with_vix > best:\n",
        "        print('New Corr with {}:{}'.format(symbol, corr_with_vix))\n",
        "        best = corr_with_vix\n",
        "  return best\n",
        "\n",
        "def _get_most_correlated(result_df):\n",
        "  df = result_df[['^VIX']]\n",
        "  bad_df = df.index.isin(['^VIX'])\n",
        "  return df[~bad_df]\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpVVvwqxGYc5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#vix_vals = get_historical_value('^VIX')\n",
        "\n",
        "all_stocks_data = map(lambda symbol: (symbol, get_historical_value(symbol)), portfolio_shares)\n",
        "best = calculate_portfolio_correlation(all_stocks_data)      \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNX-4-970hiQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res = _get_most_correlated(best)\n",
        "sorted_df = res.sort_values('^VIX', ascending=False)\n",
        "sorted_df.head(10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQ-fsQbw3o53",
        "colab_type": "code",
        "outputId": "6d831c60-9b48-45c7-992d-39a061db5f69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "idx = sorted_df.iloc[0]\n",
        "\n",
        "print(idx.values.tolist()[0])\n",
        "print(sorted_df.index[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.07980534120952935\n",
            "AAME\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEm3C6Br6QpG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sorted_df.index\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVW7bUyf5Ixd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corr_matrix = all_df.corr(method='pearson')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYel6zlO5vWl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corr_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_4hncWYwT19",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prices = map(lambda s: (s, get_quote(s)), all_stocks[0:2000])\n",
        "filtered = [tpl for tpl in prices if tpl[1]  > 800]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZ6e3wCJ8qo0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1o3uRW6bjOTA",
        "colab_type": "text"
      },
      "source": [
        "<h3> Getting All US Stocks </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COGKQLeXjThy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "eaceebbf-cef6-43ab-d9f3-c60ebccb2898"
      },
      "source": [
        "all_stocks = get_all_us_stocks()\n",
        "print('We got to find:{}'.format(len(all_stocks)))\n",
        "all_stocks[0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We got to find:1823\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mN55XgONj1J",
        "colab_type": "text"
      },
      "source": [
        "<h3> REtrieving News </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-WGaL7jNmVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_news = map(lambda ticker : get_news(ticker, 100), all_stocks) # will not work.intraday news. \n",
        "data = list(all_news)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xa9Xh7GAm9G6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fe19f067-9d1e-4705-8951-056de62be058"
      },
      "source": [
        "from datetime import datetime\n",
        "ts = data[-1][0]['datetime']\n",
        "import time\n",
        "print(ts)\n",
        "type(ts)\n",
        "datetime.fromtimestamp(ts/1000).date()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1572994800000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datetime.date(2019, 11, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzgxclZ3s8C6",
        "colab_type": "text"
      },
      "source": [
        "<h3> REtrievign News from News API </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elMSxPNWtA2w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "ed050d82-d185-4641-8067-df130c4f9b3c"
      },
      "source": [
        "# Sample Amazon URL\n",
        "token = get_newsapi_keys()\n",
        "all_news = 'https://newsapi.org/v2/everything?q=Amazon&apiKey={token}'.format(token=token)\n",
        "data = requests.get(all_news).json()\n",
        "res = data['articles']\n",
        "tpl = map(lambda d: (d['source']['name'], d['publishedAt']), res)\n",
        "from pprint import pprint\n",
        "pprint(list(tpl))\n",
        "\n",
        "\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('TechCrunch', '2019-10-29T13:17:42Z'),\n",
            " ('Engadget', '2019-10-20T23:22:00Z'),\n",
            " ('TechCrunch', '2019-10-29T10:00:04Z'),\n",
            " ('Lifehacker.com', '2019-10-18T15:10:00Z'),\n",
            " ('Lifehacker.com', '2019-10-23T18:45:00Z'),\n",
            " ('Engadget', '2019-10-15T06:15:00Z'),\n",
            " ('Engadget', '2019-11-01T16:44:00Z'),\n",
            " ('Engadget', '2019-11-06T17:10:00Z'),\n",
            " ('Engadget', '2019-10-31T21:14:00Z'),\n",
            " ('Engadget', '2019-10-17T21:49:00Z'),\n",
            " ('Engadget', '2019-10-30T19:10:00Z'),\n",
            " ('Engadget', '2019-10-31T13:18:00Z'),\n",
            " ('TechCrunch', '2019-11-02T10:19:49Z'),\n",
            " ('Engadget', '2019-11-13T11:01:00Z'),\n",
            " ('Engadget', '2019-10-16T18:11:00Z'),\n",
            " ('Mashable', '2019-11-06T15:29:54Z'),\n",
            " ('Mashable', '2019-11-12T14:43:57Z'),\n",
            " ('Mashable', '2019-10-29T15:02:23Z'),\n",
            " ('Lifehacker.com', '2019-10-16T18:15:00Z'),\n",
            " ('Lifehacker.com', '2019-10-27T17:13:00Z')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1e-FVJBN8Xc",
        "colab_type": "code",
        "outputId": "87437251-c3de-4c25-9368-abebbec70e99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_language_api(one_news)['documentSentiment']['score']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERdKLZmwm75W",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}